// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.6.1
//   protoc               unknown
// source: chalk/server/v1/builder.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import {
  type CallOptions,
  ChannelCredentials,
  Client,
  type ClientOptions,
  type ClientUnaryCall,
  type handleUnaryCall,
  makeGenericClientConstructor,
  Metadata,
  type ServiceError,
  type UntypedServiceImplementation,
} from "@grpc/grpc-js";
import { Timestamp } from "../../../google/protobuf/timestamp.pb";
import { Graph } from "../../graph/v1/graph.pb";
import { LSP } from "../../lsp/v1/lsp.pb";
import { GKENodePool } from "../../nodepools/v1/gke.pb";
import { KarpenterNodepool } from "../../nodepools/v1/karpenter.pb";
import { Deployment } from "./deployment.pb";
import { LogEntry } from "./log.pb";

export const protobufPackage = "chalk.server.v1";

export enum DeploymentBuildStatus {
  DEPLOYMENT_BUILD_STATUS_UNSPECIFIED = 0,
  DEPLOYMENT_BUILD_STATUS_UNKNOWN = 1,
  DEPLOYMENT_BUILD_STATUS_PENDING = 2,
  DEPLOYMENT_BUILD_STATUS_QUEUED = 3,
  DEPLOYMENT_BUILD_STATUS_WORKING = 4,
  DEPLOYMENT_BUILD_STATUS_SUCCESS = 5,
  DEPLOYMENT_BUILD_STATUS_FAILURE = 6,
  DEPLOYMENT_BUILD_STATUS_INTERNAL_ERROR = 7,
  DEPLOYMENT_BUILD_STATUS_TIMEOUT = 8,
  DEPLOYMENT_BUILD_STATUS_CANCELLED = 9,
  DEPLOYMENT_BUILD_STATUS_EXPIRED = 10,
  DEPLOYMENT_BUILD_STATUS_BOOT_ERRORS = 11,
  UNRECOGNIZED = -1,
}

export function deploymentBuildStatusFromJSON(object: any): DeploymentBuildStatus {
  switch (object) {
    case 0:
    case "DEPLOYMENT_BUILD_STATUS_UNSPECIFIED":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_UNSPECIFIED;
    case 1:
    case "DEPLOYMENT_BUILD_STATUS_UNKNOWN":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_UNKNOWN;
    case 2:
    case "DEPLOYMENT_BUILD_STATUS_PENDING":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_PENDING;
    case 3:
    case "DEPLOYMENT_BUILD_STATUS_QUEUED":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_QUEUED;
    case 4:
    case "DEPLOYMENT_BUILD_STATUS_WORKING":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_WORKING;
    case 5:
    case "DEPLOYMENT_BUILD_STATUS_SUCCESS":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_SUCCESS;
    case 6:
    case "DEPLOYMENT_BUILD_STATUS_FAILURE":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_FAILURE;
    case 7:
    case "DEPLOYMENT_BUILD_STATUS_INTERNAL_ERROR":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_INTERNAL_ERROR;
    case 8:
    case "DEPLOYMENT_BUILD_STATUS_TIMEOUT":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_TIMEOUT;
    case 9:
    case "DEPLOYMENT_BUILD_STATUS_CANCELLED":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_CANCELLED;
    case 10:
    case "DEPLOYMENT_BUILD_STATUS_EXPIRED":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_EXPIRED;
    case 11:
    case "DEPLOYMENT_BUILD_STATUS_BOOT_ERRORS":
      return DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_BOOT_ERRORS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DeploymentBuildStatus.UNRECOGNIZED;
  }
}

export function deploymentBuildStatusToJSON(object: DeploymentBuildStatus): string {
  switch (object) {
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_UNSPECIFIED:
      return "DEPLOYMENT_BUILD_STATUS_UNSPECIFIED";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_UNKNOWN:
      return "DEPLOYMENT_BUILD_STATUS_UNKNOWN";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_PENDING:
      return "DEPLOYMENT_BUILD_STATUS_PENDING";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_QUEUED:
      return "DEPLOYMENT_BUILD_STATUS_QUEUED";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_WORKING:
      return "DEPLOYMENT_BUILD_STATUS_WORKING";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_SUCCESS:
      return "DEPLOYMENT_BUILD_STATUS_SUCCESS";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_FAILURE:
      return "DEPLOYMENT_BUILD_STATUS_FAILURE";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_INTERNAL_ERROR:
      return "DEPLOYMENT_BUILD_STATUS_INTERNAL_ERROR";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_TIMEOUT:
      return "DEPLOYMENT_BUILD_STATUS_TIMEOUT";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_CANCELLED:
      return "DEPLOYMENT_BUILD_STATUS_CANCELLED";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_EXPIRED:
      return "DEPLOYMENT_BUILD_STATUS_EXPIRED";
    case DeploymentBuildStatus.DEPLOYMENT_BUILD_STATUS_BOOT_ERRORS:
      return "DEPLOYMENT_BUILD_STATUS_BOOT_ERRORS";
    case DeploymentBuildStatus.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum BranchScalingState {
  BRANCH_SCALING_STATE_UNSPECIFIED = 0,
  BRANCH_SCALING_STATE_SUCCESS = 1,
  BRANCH_SCALING_STATE_IN_PROGRESS = 2,
  UNRECOGNIZED = -1,
}

export function branchScalingStateFromJSON(object: any): BranchScalingState {
  switch (object) {
    case 0:
    case "BRANCH_SCALING_STATE_UNSPECIFIED":
      return BranchScalingState.BRANCH_SCALING_STATE_UNSPECIFIED;
    case 1:
    case "BRANCH_SCALING_STATE_SUCCESS":
      return BranchScalingState.BRANCH_SCALING_STATE_SUCCESS;
    case 2:
    case "BRANCH_SCALING_STATE_IN_PROGRESS":
      return BranchScalingState.BRANCH_SCALING_STATE_IN_PROGRESS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BranchScalingState.UNRECOGNIZED;
  }
}

export function branchScalingStateToJSON(object: BranchScalingState): string {
  switch (object) {
    case BranchScalingState.BRANCH_SCALING_STATE_UNSPECIFIED:
      return "BRANCH_SCALING_STATE_UNSPECIFIED";
    case BranchScalingState.BRANCH_SCALING_STATE_SUCCESS:
      return "BRANCH_SCALING_STATE_SUCCESS";
    case BranchScalingState.BRANCH_SCALING_STATE_IN_PROGRESS:
      return "BRANCH_SCALING_STATE_IN_PROGRESS";
    case BranchScalingState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface ActivateDeploymentTarget {
  serviceKind: string;
  resourceGroupName: string;
}

export interface ActivateDeploymentRequest {
  existingDeploymentId: string;
  targets: ActivateDeploymentTarget[];
}

export interface ActivateDeploymentResponse {
}

export interface IndexDeploymentRequest {
  existingDeploymentId: string;
}

export interface IndexDeploymentResponse {
}

export interface DeployKubeComponentsRequest {
  existingDeploymentId: string;
  targets: ActivateDeploymentTarget[];
}

export interface DeployKubeComponentsResponse {
}

export interface RebuildDeploymentRequest {
  existingDeploymentId: string;
  newImageTag: string;
  baseImageOverride?: string | undefined;
  enableProfiling: boolean;
}

export interface RebuildDeploymentResponse {
  buildId: string;
}

export interface RedeployDeploymentRequest {
  existingDeploymentId: string;
  enableProfiling: boolean;
  deploymentTags: string[];
  baseImageOverride?: string | undefined;
}

export interface RedeployDeploymentResponse {
  /**
   * don't care about this
   *
   * @deprecated
   */
  buildId: string;
  deploymentId: string;
}

export interface UploadSourceRequest {
  deploymentId: string;
  archive: Uint8Array;
  noPromote: boolean;
  dependencyHash?: string | undefined;
  baseImageOverride?: string | undefined;
  useGrpc: boolean;
  enableProfiling: boolean;
}

export interface UploadSourceResponse {
  status: string;
  progressUrl: string;
}

export interface LintSourceRequest {
  /**
   * optional string dependency_hash = 3;
   *  optional string base_image_override = 4;
   *  string deployment_id = 7;
   */
  archive: Uint8Array;
}

export interface LintSourceResponse {
  graph: Graph | undefined;
  lsp: LSP | undefined;
}

export interface GetDeploymentStepsRequest {
  deploymentId: string;
}

export interface DeploymentBuildStep {
  id: string;
  displayName: string;
  status: DeploymentBuildStatus;
  startTime: Date | undefined;
  endTime: Date | undefined;
}

export interface GetDeploymentStepsResponse {
  steps: DeploymentBuildStep[];
  deployment: Deployment | undefined;
}

export interface GetDeploymentLogsRequest {
  deploymentId: string;
}

export interface GetDeploymentLogsResponse {
  logs: LogEntry[];
}

export interface GetClusterTimescaleDBRequest {
  environmentId: string;
}

export interface GetClusterTimescaleDBResponse {
  id: string;
  /**
   * use specs instead
   *
   * @deprecated
   */
  specsString: string;
  createdAt: Date | undefined;
  updatedAt: Date | undefined;
  specs: ClusterTimescaleSpecs | undefined;
}

export interface GetClusterGatewayRequest {
  environmentId: string;
}

export interface GetClusterGatewayResponse {
  id: string;
  /**
   * use specs instead
   *
   * @deprecated
   */
  specsString: string;
  createdAt: Date | undefined;
  updatedAt: Date | undefined;
  specs: EnvoyGatewaySpecs | undefined;
}

export interface BackgroundPersistence {
  id: string;
  kind: string;
  /**
   * use specs instead
   *
   * @deprecated
   */
  specsString: string;
  createdAt: Date | undefined;
  updatedAt: Date | undefined;
  specs: BackgroundPersistenceDeploymentSpecs | undefined;
}

export interface GetClusterBackgroundPersistenceRequest {
  environmentId: string;
}

export interface GetClusterBackgroundPersistenceResponse {
  backgroundPersistence: BackgroundPersistence | undefined;
}

export interface CreateClusterTimescaleDBRequest {
  /**
   * spelling
   *
   * @deprecated
   */
  environmentId: string[];
  environmentIds: string[];
  /** @deprecated */
  specsString: string;
  specs: ClusterTimescaleSpecs | undefined;
}

export interface KubeResourceConfig {
  cpu: string;
  memory: string;
  ephemeralStorage: string;
  storage: string;
}

export interface ClusterTimescaleSpecs {
  timescaleImage: string;
  databaseName: string;
  databaseReplicas: number;
  storage: string;
  storageClass?: string | undefined;
  namespace: string;
  request?: KubeResourceConfig | undefined;
  limit?: KubeResourceConfig | undefined;
  connectionPoolReplicas: number;
  connectionPoolMaxConnections: string;
  connectionPoolSize: string;
  connectionPoolMode: string;
  backupBucket: string;
  backupIamRoleArn: string;
  secretName: string;
  internal?: boolean | undefined;
  serviceType?: string | undefined;
  postgresParameters: { [key: string]: string };
  includeChalkNodeSelector: boolean;
  backupGcpServiceAccount: string;
  instanceType: string;
}

export interface ClusterTimescaleSpecs_PostgresParametersEntry {
  key: string;
  value: string;
}

export interface CreateClusterTimescaleDBResponse {
}

export interface MigrateClusterTimescaleDBRequest {
  clusterTimescaleId: string;
  migrationImage?: string | undefined;
  environmentIds: string[];
}

export interface MigrateClusterTimescaleDBResponse {
}

export interface CreateClusterGatewayRequest {
  /**
   * spelling
   *
   * @deprecated
   */
  environmentId: string[];
  environmentIds: string[];
  /**
   * use specs instead
   *
   * @deprecated
   */
  specsString: string;
  specs: EnvoyGatewaySpecs | undefined;
}

/** name not necessarily reflective of the actual gateway being used */
export interface EnvoyGatewaySpecs {
  namespace: string;
  gatewayName: string;
  gatewayClassName: string;
  listeners: EnvoyGatewayListener[];
  config?: GatewayProviderConfig | undefined;
  includeChalkNodeSelector: boolean;
  /** Optional IP allowlist for restricting access to the gateway */
  ipAllowlist: string[];
  /** Optional TLS certificate configuration */
  tlsCertificate?: TLSCertificateConfig | undefined;
}

export interface EnvoyGatewayListener {
  port: number;
  protocol: string;
  name: string;
  allowedRoutes: EnvoyGatewayAllowedRoutes | undefined;
}

export interface EnvoyGatewayAllowedRoutes {
  namespaces: EnvoyGatewayAllowedNamespaces | undefined;
}

export interface EnvoyGatewayAllowedNamespaces {
  from: string;
}

export interface GatewayProviderConfig {
  envoy?: EnvoyGatewayProviderConfig | undefined;
  gcp?: GCPGatewayProviderConfig | undefined;
}

export interface EnvoyGatewayProviderConfig {
  timeoutDuration?: string | undefined;
  dnsHostname?: string | undefined;
  replicas?: number | undefined;
  minAvailable?: number | undefined;
}

export interface GCPGatewayProviderConfig {
  dnsHostname: string;
}

/** TLS certificate configuration with extensible design */
export interface TLSCertificateConfig {
  /** Future: TLSLetsEncryptRef letsencrypt_certificate = 2; */
  manualCertificate?: TLSManualCertificateRef | undefined;
}

/** Manual certificate referencing a Kubernetes secret */
export interface TLSManualCertificateRef {
  secretName: string;
  secretNamespace: string;
}

export interface CreateClusterGatewayResponse {
}

export interface CreateClusterBackgroundPersistenceRequest {
  environmentIds: string[];
  /**
   * use specs instead
   *
   * @deprecated
   */
  specsString: string;
  specs: BackgroundPersistenceDeploymentSpecs | undefined;
}

export interface BackgroundPersistenceCommonSpecs {
  namespace: string;
  busWriterImageGo: string;
  busWriterImagePython: string;
  busWriterImageBswl: string;
  serviceAccountName: string;
  busBackend: string;
  secretClient: string;
  bigqueryParquetUploadSubscriptionId: string;
  bigqueryStreamingWriteSubscriptionId: string;
  bigqueryStreamingWriteTopic: string;
  /**
   * spelling;
   *
   * @deprecated
   */
  bigqueryUploadBucket: string;
  /**
   * spelling;
   *
   * @deprecated
   */
  bigqueryUploadTopic: string;
  googleCloudProject: string;
  kafkaDlqTopic: string;
  metricsBusSubscriptionId: string;
  metricsBusTopicId: string;
  operationSubscriptionId: string;
  queryLogResultTopic: string;
  queryLogSubscriptionId: string;
  resultBusMetricsSubscriptionId: string;
  resultBusOfflineStoreSubscriptionId: string;
  resultBusOnlineStoreSubscriptionId: string;
  resultBusTopicId: string;
  usageBusTopicId: string;
  usageEventsSubscriptionId: string;
  bqUploadBucket: string;
  bqUploadTopic: string;
  includeChalkNodeSelector: boolean;
  busWriterImageRust: string;
}

export interface BackgroundPersistenceWriterHpaSpecs {
  hpaPubsubSubscriptionId: string;
  hpaMinReplicas?: number | undefined;
  hpaMaxReplicas?: number | undefined;
  hpaTargetAverageValue?: number | undefined;
}

export interface BackgroundPersistenceWriterSpecs {
  name: string;
  imageOverride: string;
  hpaSpecs?: BackgroundPersistenceWriterHpaSpecs | undefined;
  gkeSpot?: boolean | undefined;
  loadWriterConfigmap?: boolean | undefined;
  version: string;
  request?: KubeResourceConfig | undefined;
  limit?: KubeResourceConfig | undefined;
  busSubscriberType: string;
  defaultReplicaCount: number;
  kafkaConsumerGroupOverride: string;
  maxBatchSize?: number | undefined;
  messageProcessingConcurrency?: number | undefined;
  metadataSqlSslCaCertSecret: string;
  metadataSqlSslClientCertSecret: string;
  metadataSqlSslClientKeySecret: string;
  metadataSqlUriSecret: string;
  offlineStoreInserterDbType: string;
  storageCachePrefix: string;
  usageStoreUri: string;
  resultsWriterSkipProducingFeatureMetrics?: boolean | undefined;
  queryTableWriteDropRatio: string;
}

export interface BackgroundPersistenceDeploymentSpecs {
  commonPersistenceSpecs: BackgroundPersistenceCommonSpecs | undefined;
  apiServerHost: string;
  kafkaSaslSecret: string;
  metadataProvider: string;
  kafkaBootstrapServers: string;
  kafkaSecurityProtocol: string;
  kafkaSaslMechanism: string;
  redisIsClustered: string;
  snowflakeStorageIntegrationName: string;
  redisLightningSupportsHasMany: boolean;
  insecure: boolean;
  writers: BackgroundPersistenceWriterSpecs[];
}

export interface CreateClusterBackgroundPersistenceResponse {
}

export interface GetSearchConfigRequest {
}

export interface GetSearchConfigResponse {
  teamId: string;
  teamApiKey: string;
}

export interface UpdateEnvironmentVariablesRequest {
  environmentVariables: { [key: string]: string };
}

export interface UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry {
  key: string;
  value: string;
}

export interface UpdateEnvironmentVariablesResponse {
}

export interface StartBranchRequest {
}

export interface StartBranchResponse {
  state: BranchScalingState;
}

export interface ScaleBranchRequest {
  replicas: number;
}

export interface ScaleBranchResponse {
  state: BranchScalingState;
}

export interface KafkaTopic {
  name: string;
  partitions: number;
  replication?: number | undefined;
  retentionMs: number;
}

export interface CreateKafkaTopicsRequest {
  topics: KafkaTopic[];
}

export interface CreateKafkaTopicsResponse {
}

export interface GetKafkaTopicsRequest {
}

export interface GetKafkaTopicsResponse {
  topics: KafkaTopic[];
}

export interface GetNodepoolsRequest {
}

export interface GetNodepoolsResponse {
  karpenterNodepools: KarpenterNodepool[];
  gkeNodepools: GKENodePool[];
}

export interface AddNodepoolRequest {
  karpenterNodepool?: KarpenterNodepool | undefined;
  gkeNodepool?: GKENodePool | undefined;
}

export interface AddNodepoolResponse {
  karpenterNodepool?: KarpenterNodepool | undefined;
  gkeNodepool?: GKENodePool | undefined;
}

export interface UpdateNodepoolRequest {
  name: string;
  gkeNodepool?: GKENodePool | undefined;
  karpenterNodepool?: KarpenterNodepool | undefined;
}

export interface UpdateNodepoolResponse {
  karpenterNodepool?: KarpenterNodepool | undefined;
  gkeNodepool?: GKENodePool | undefined;
}

export interface DeleteNodepoolRequest {
  name: string;
}

export interface DeleteNodepoolResponse {
}

export interface GetKarpenterNodepoolsRequest {
}

export interface GetKarpenterNodepoolsResponse {
  nodepools: KarpenterNodepool[];
}

export interface AddKarpenterNodepoolRequest {
  nodepool: KarpenterNodepool | undefined;
}

export interface AddKarpenterNodepoolResponse {
  nodepool: KarpenterNodepool | undefined;
}

export interface UpdateKarpenterNodepoolRequest {
  name: string;
  nodepool: KarpenterNodepool | undefined;
}

export interface UpdateKarpenterNodepoolResponse {
  nodepool: KarpenterNodepool | undefined;
}

export interface DeleteKarpenterNodepoolRequest {
  name: string;
}

export interface DeleteKarpenterNodepoolResponse {
}

export interface GetKarpenterInstallationMetadataRequest {
}

export interface GetKarpenterInstallationMetadataResponse {
  deploymentLabels: { [key: string]: string };
}

export interface GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry {
  key: string;
  value: string;
}

export interface DeploymentTag {
  tag: string;
  weight?: number | undefined;
  deploymentId?: string | undefined;
  mirrorWeight?: number | undefined;
}

export interface GetTagWeightsRequest {
}

export interface GetTagWeightsResponse {
  tags: DeploymentTag[];
}

export interface SetTagWeightsRequest {
  tags: DeploymentTag[];
}

export interface SetTagWeightsResponse {
  tags: DeploymentTag[];
}

function createBaseActivateDeploymentTarget(): ActivateDeploymentTarget {
  return { serviceKind: "", resourceGroupName: "" };
}

export const ActivateDeploymentTarget: MessageFns<ActivateDeploymentTarget> = {
  encode(message: ActivateDeploymentTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.serviceKind !== "") {
      writer.uint32(10).string(message.serviceKind);
    }
    if (message.resourceGroupName !== "") {
      writer.uint32(18).string(message.resourceGroupName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActivateDeploymentTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActivateDeploymentTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.serviceKind = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.resourceGroupName = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActivateDeploymentTarget {
    return {
      serviceKind: isSet(object.serviceKind) ? globalThis.String(object.serviceKind) : "",
      resourceGroupName: isSet(object.resourceGroupName) ? globalThis.String(object.resourceGroupName) : "",
    };
  },

  toJSON(message: ActivateDeploymentTarget): unknown {
    const obj: any = {};
    if (message.serviceKind !== "") {
      obj.serviceKind = message.serviceKind;
    }
    if (message.resourceGroupName !== "") {
      obj.resourceGroupName = message.resourceGroupName;
    }
    return obj;
  },
};

function createBaseActivateDeploymentRequest(): ActivateDeploymentRequest {
  return { existingDeploymentId: "", targets: [] };
}

export const ActivateDeploymentRequest: MessageFns<ActivateDeploymentRequest> = {
  encode(message: ActivateDeploymentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.existingDeploymentId !== "") {
      writer.uint32(10).string(message.existingDeploymentId);
    }
    for (const v of message.targets) {
      ActivateDeploymentTarget.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActivateDeploymentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActivateDeploymentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.existingDeploymentId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.targets.push(ActivateDeploymentTarget.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ActivateDeploymentRequest {
    return {
      existingDeploymentId: isSet(object.existingDeploymentId) ? globalThis.String(object.existingDeploymentId) : "",
      targets: globalThis.Array.isArray(object?.targets)
        ? object.targets.map((e: any) => ActivateDeploymentTarget.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ActivateDeploymentRequest): unknown {
    const obj: any = {};
    if (message.existingDeploymentId !== "") {
      obj.existingDeploymentId = message.existingDeploymentId;
    }
    if (message.targets?.length) {
      obj.targets = message.targets.map((e) => ActivateDeploymentTarget.toJSON(e));
    }
    return obj;
  },
};

function createBaseActivateDeploymentResponse(): ActivateDeploymentResponse {
  return {};
}

export const ActivateDeploymentResponse: MessageFns<ActivateDeploymentResponse> = {
  encode(_: ActivateDeploymentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ActivateDeploymentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseActivateDeploymentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ActivateDeploymentResponse {
    return {};
  },

  toJSON(_: ActivateDeploymentResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseIndexDeploymentRequest(): IndexDeploymentRequest {
  return { existingDeploymentId: "" };
}

export const IndexDeploymentRequest: MessageFns<IndexDeploymentRequest> = {
  encode(message: IndexDeploymentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.existingDeploymentId !== "") {
      writer.uint32(10).string(message.existingDeploymentId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IndexDeploymentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIndexDeploymentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.existingDeploymentId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): IndexDeploymentRequest {
    return {
      existingDeploymentId: isSet(object.existingDeploymentId) ? globalThis.String(object.existingDeploymentId) : "",
    };
  },

  toJSON(message: IndexDeploymentRequest): unknown {
    const obj: any = {};
    if (message.existingDeploymentId !== "") {
      obj.existingDeploymentId = message.existingDeploymentId;
    }
    return obj;
  },
};

function createBaseIndexDeploymentResponse(): IndexDeploymentResponse {
  return {};
}

export const IndexDeploymentResponse: MessageFns<IndexDeploymentResponse> = {
  encode(_: IndexDeploymentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): IndexDeploymentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseIndexDeploymentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): IndexDeploymentResponse {
    return {};
  },

  toJSON(_: IndexDeploymentResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseDeployKubeComponentsRequest(): DeployKubeComponentsRequest {
  return { existingDeploymentId: "", targets: [] };
}

export const DeployKubeComponentsRequest: MessageFns<DeployKubeComponentsRequest> = {
  encode(message: DeployKubeComponentsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.existingDeploymentId !== "") {
      writer.uint32(10).string(message.existingDeploymentId);
    }
    for (const v of message.targets) {
      ActivateDeploymentTarget.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployKubeComponentsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployKubeComponentsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.existingDeploymentId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.targets.push(ActivateDeploymentTarget.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeployKubeComponentsRequest {
    return {
      existingDeploymentId: isSet(object.existingDeploymentId) ? globalThis.String(object.existingDeploymentId) : "",
      targets: globalThis.Array.isArray(object?.targets)
        ? object.targets.map((e: any) => ActivateDeploymentTarget.fromJSON(e))
        : [],
    };
  },

  toJSON(message: DeployKubeComponentsRequest): unknown {
    const obj: any = {};
    if (message.existingDeploymentId !== "") {
      obj.existingDeploymentId = message.existingDeploymentId;
    }
    if (message.targets?.length) {
      obj.targets = message.targets.map((e) => ActivateDeploymentTarget.toJSON(e));
    }
    return obj;
  },
};

function createBaseDeployKubeComponentsResponse(): DeployKubeComponentsResponse {
  return {};
}

export const DeployKubeComponentsResponse: MessageFns<DeployKubeComponentsResponse> = {
  encode(_: DeployKubeComponentsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployKubeComponentsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployKubeComponentsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DeployKubeComponentsResponse {
    return {};
  },

  toJSON(_: DeployKubeComponentsResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseRebuildDeploymentRequest(): RebuildDeploymentRequest {
  return { existingDeploymentId: "", newImageTag: "", baseImageOverride: undefined, enableProfiling: false };
}

export const RebuildDeploymentRequest: MessageFns<RebuildDeploymentRequest> = {
  encode(message: RebuildDeploymentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.existingDeploymentId !== "") {
      writer.uint32(10).string(message.existingDeploymentId);
    }
    if (message.newImageTag !== "") {
      writer.uint32(18).string(message.newImageTag);
    }
    if (message.baseImageOverride !== undefined) {
      writer.uint32(26).string(message.baseImageOverride);
    }
    if (message.enableProfiling !== false) {
      writer.uint32(32).bool(message.enableProfiling);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RebuildDeploymentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRebuildDeploymentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.existingDeploymentId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.newImageTag = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.baseImageOverride = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.enableProfiling = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RebuildDeploymentRequest {
    return {
      existingDeploymentId: isSet(object.existingDeploymentId) ? globalThis.String(object.existingDeploymentId) : "",
      newImageTag: isSet(object.newImageTag) ? globalThis.String(object.newImageTag) : "",
      baseImageOverride: isSet(object.baseImageOverride) ? globalThis.String(object.baseImageOverride) : undefined,
      enableProfiling: isSet(object.enableProfiling) ? globalThis.Boolean(object.enableProfiling) : false,
    };
  },

  toJSON(message: RebuildDeploymentRequest): unknown {
    const obj: any = {};
    if (message.existingDeploymentId !== "") {
      obj.existingDeploymentId = message.existingDeploymentId;
    }
    if (message.newImageTag !== "") {
      obj.newImageTag = message.newImageTag;
    }
    if (message.baseImageOverride !== undefined) {
      obj.baseImageOverride = message.baseImageOverride;
    }
    if (message.enableProfiling !== false) {
      obj.enableProfiling = message.enableProfiling;
    }
    return obj;
  },
};

function createBaseRebuildDeploymentResponse(): RebuildDeploymentResponse {
  return { buildId: "" };
}

export const RebuildDeploymentResponse: MessageFns<RebuildDeploymentResponse> = {
  encode(message: RebuildDeploymentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.buildId !== "") {
      writer.uint32(10).string(message.buildId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RebuildDeploymentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRebuildDeploymentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.buildId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RebuildDeploymentResponse {
    return { buildId: isSet(object.buildId) ? globalThis.String(object.buildId) : "" };
  },

  toJSON(message: RebuildDeploymentResponse): unknown {
    const obj: any = {};
    if (message.buildId !== "") {
      obj.buildId = message.buildId;
    }
    return obj;
  },
};

function createBaseRedeployDeploymentRequest(): RedeployDeploymentRequest {
  return { existingDeploymentId: "", enableProfiling: false, deploymentTags: [], baseImageOverride: undefined };
}

export const RedeployDeploymentRequest: MessageFns<RedeployDeploymentRequest> = {
  encode(message: RedeployDeploymentRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.existingDeploymentId !== "") {
      writer.uint32(10).string(message.existingDeploymentId);
    }
    if (message.enableProfiling !== false) {
      writer.uint32(16).bool(message.enableProfiling);
    }
    for (const v of message.deploymentTags) {
      writer.uint32(26).string(v!);
    }
    if (message.baseImageOverride !== undefined) {
      writer.uint32(34).string(message.baseImageOverride);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedeployDeploymentRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedeployDeploymentRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.existingDeploymentId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.enableProfiling = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.deploymentTags.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.baseImageOverride = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedeployDeploymentRequest {
    return {
      existingDeploymentId: isSet(object.existingDeploymentId) ? globalThis.String(object.existingDeploymentId) : "",
      enableProfiling: isSet(object.enableProfiling) ? globalThis.Boolean(object.enableProfiling) : false,
      deploymentTags: globalThis.Array.isArray(object?.deploymentTags)
        ? object.deploymentTags.map((e: any) => globalThis.String(e))
        : [],
      baseImageOverride: isSet(object.baseImageOverride) ? globalThis.String(object.baseImageOverride) : undefined,
    };
  },

  toJSON(message: RedeployDeploymentRequest): unknown {
    const obj: any = {};
    if (message.existingDeploymentId !== "") {
      obj.existingDeploymentId = message.existingDeploymentId;
    }
    if (message.enableProfiling !== false) {
      obj.enableProfiling = message.enableProfiling;
    }
    if (message.deploymentTags?.length) {
      obj.deploymentTags = message.deploymentTags;
    }
    if (message.baseImageOverride !== undefined) {
      obj.baseImageOverride = message.baseImageOverride;
    }
    return obj;
  },
};

function createBaseRedeployDeploymentResponse(): RedeployDeploymentResponse {
  return { buildId: "", deploymentId: "" };
}

export const RedeployDeploymentResponse: MessageFns<RedeployDeploymentResponse> = {
  encode(message: RedeployDeploymentResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.buildId !== "") {
      writer.uint32(10).string(message.buildId);
    }
    if (message.deploymentId !== "") {
      writer.uint32(18).string(message.deploymentId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedeployDeploymentResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedeployDeploymentResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.buildId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.deploymentId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedeployDeploymentResponse {
    return {
      buildId: isSet(object.buildId) ? globalThis.String(object.buildId) : "",
      deploymentId: isSet(object.deploymentId) ? globalThis.String(object.deploymentId) : "",
    };
  },

  toJSON(message: RedeployDeploymentResponse): unknown {
    const obj: any = {};
    if (message.buildId !== "") {
      obj.buildId = message.buildId;
    }
    if (message.deploymentId !== "") {
      obj.deploymentId = message.deploymentId;
    }
    return obj;
  },
};

function createBaseUploadSourceRequest(): UploadSourceRequest {
  return {
    deploymentId: "",
    archive: new Uint8Array(0),
    noPromote: false,
    dependencyHash: undefined,
    baseImageOverride: undefined,
    useGrpc: false,
    enableProfiling: false,
  };
}

export const UploadSourceRequest: MessageFns<UploadSourceRequest> = {
  encode(message: UploadSourceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deploymentId !== "") {
      writer.uint32(58).string(message.deploymentId);
    }
    if (message.archive.length !== 0) {
      writer.uint32(10).bytes(message.archive);
    }
    if (message.noPromote !== false) {
      writer.uint32(16).bool(message.noPromote);
    }
    if (message.dependencyHash !== undefined) {
      writer.uint32(26).string(message.dependencyHash);
    }
    if (message.baseImageOverride !== undefined) {
      writer.uint32(34).string(message.baseImageOverride);
    }
    if (message.useGrpc !== false) {
      writer.uint32(40).bool(message.useGrpc);
    }
    if (message.enableProfiling !== false) {
      writer.uint32(48).bool(message.enableProfiling);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadSourceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadSourceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.deploymentId = reader.string();
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.archive = reader.bytes();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.noPromote = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.dependencyHash = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.baseImageOverride = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.useGrpc = reader.bool();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.enableProfiling = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadSourceRequest {
    return {
      deploymentId: isSet(object.deploymentId) ? globalThis.String(object.deploymentId) : "",
      archive: isSet(object.archive) ? bytesFromBase64(object.archive) : new Uint8Array(0),
      noPromote: isSet(object.noPromote) ? globalThis.Boolean(object.noPromote) : false,
      dependencyHash: isSet(object.dependencyHash) ? globalThis.String(object.dependencyHash) : undefined,
      baseImageOverride: isSet(object.baseImageOverride) ? globalThis.String(object.baseImageOverride) : undefined,
      useGrpc: isSet(object.useGrpc) ? globalThis.Boolean(object.useGrpc) : false,
      enableProfiling: isSet(object.enableProfiling) ? globalThis.Boolean(object.enableProfiling) : false,
    };
  },

  toJSON(message: UploadSourceRequest): unknown {
    const obj: any = {};
    if (message.deploymentId !== "") {
      obj.deploymentId = message.deploymentId;
    }
    if (message.archive.length !== 0) {
      obj.archive = base64FromBytes(message.archive);
    }
    if (message.noPromote !== false) {
      obj.noPromote = message.noPromote;
    }
    if (message.dependencyHash !== undefined) {
      obj.dependencyHash = message.dependencyHash;
    }
    if (message.baseImageOverride !== undefined) {
      obj.baseImageOverride = message.baseImageOverride;
    }
    if (message.useGrpc !== false) {
      obj.useGrpc = message.useGrpc;
    }
    if (message.enableProfiling !== false) {
      obj.enableProfiling = message.enableProfiling;
    }
    return obj;
  },
};

function createBaseUploadSourceResponse(): UploadSourceResponse {
  return { status: "", progressUrl: "" };
}

export const UploadSourceResponse: MessageFns<UploadSourceResponse> = {
  encode(message: UploadSourceResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== "") {
      writer.uint32(10).string(message.status);
    }
    if (message.progressUrl !== "") {
      writer.uint32(18).string(message.progressUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UploadSourceResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUploadSourceResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.status = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.progressUrl = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UploadSourceResponse {
    return {
      status: isSet(object.status) ? globalThis.String(object.status) : "",
      progressUrl: isSet(object.progressUrl) ? globalThis.String(object.progressUrl) : "",
    };
  },

  toJSON(message: UploadSourceResponse): unknown {
    const obj: any = {};
    if (message.status !== "") {
      obj.status = message.status;
    }
    if (message.progressUrl !== "") {
      obj.progressUrl = message.progressUrl;
    }
    return obj;
  },
};

function createBaseLintSourceRequest(): LintSourceRequest {
  return { archive: new Uint8Array(0) };
}

export const LintSourceRequest: MessageFns<LintSourceRequest> = {
  encode(message: LintSourceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.archive.length !== 0) {
      writer.uint32(10).bytes(message.archive);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LintSourceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLintSourceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.archive = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LintSourceRequest {
    return { archive: isSet(object.archive) ? bytesFromBase64(object.archive) : new Uint8Array(0) };
  },

  toJSON(message: LintSourceRequest): unknown {
    const obj: any = {};
    if (message.archive.length !== 0) {
      obj.archive = base64FromBytes(message.archive);
    }
    return obj;
  },
};

function createBaseLintSourceResponse(): LintSourceResponse {
  return { graph: undefined, lsp: undefined };
}

export const LintSourceResponse: MessageFns<LintSourceResponse> = {
  encode(message: LintSourceResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.graph !== undefined) {
      Graph.encode(message.graph, writer.uint32(10).fork()).join();
    }
    if (message.lsp !== undefined) {
      LSP.encode(message.lsp, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LintSourceResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLintSourceResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.graph = Graph.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.lsp = LSP.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LintSourceResponse {
    return {
      graph: isSet(object.graph) ? Graph.fromJSON(object.graph) : undefined,
      lsp: isSet(object.lsp) ? LSP.fromJSON(object.lsp) : undefined,
    };
  },

  toJSON(message: LintSourceResponse): unknown {
    const obj: any = {};
    if (message.graph !== undefined) {
      obj.graph = Graph.toJSON(message.graph);
    }
    if (message.lsp !== undefined) {
      obj.lsp = LSP.toJSON(message.lsp);
    }
    return obj;
  },
};

function createBaseGetDeploymentStepsRequest(): GetDeploymentStepsRequest {
  return { deploymentId: "" };
}

export const GetDeploymentStepsRequest: MessageFns<GetDeploymentStepsRequest> = {
  encode(message: GetDeploymentStepsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deploymentId !== "") {
      writer.uint32(10).string(message.deploymentId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDeploymentStepsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDeploymentStepsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.deploymentId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDeploymentStepsRequest {
    return { deploymentId: isSet(object.deploymentId) ? globalThis.String(object.deploymentId) : "" };
  },

  toJSON(message: GetDeploymentStepsRequest): unknown {
    const obj: any = {};
    if (message.deploymentId !== "") {
      obj.deploymentId = message.deploymentId;
    }
    return obj;
  },
};

function createBaseDeploymentBuildStep(): DeploymentBuildStep {
  return { id: "", displayName: "", status: 0, startTime: undefined, endTime: undefined };
}

export const DeploymentBuildStep: MessageFns<DeploymentBuildStep> = {
  encode(message: DeploymentBuildStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.status !== 0) {
      writer.uint32(24).int32(message.status);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(34).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeploymentBuildStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeploymentBuildStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeploymentBuildStep {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      status: isSet(object.status) ? deploymentBuildStatusFromJSON(object.status) : 0,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: DeploymentBuildStep): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.status !== 0) {
      obj.status = deploymentBuildStatusToJSON(message.status);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },
};

function createBaseGetDeploymentStepsResponse(): GetDeploymentStepsResponse {
  return { steps: [], deployment: undefined };
}

export const GetDeploymentStepsResponse: MessageFns<GetDeploymentStepsResponse> = {
  encode(message: GetDeploymentStepsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.steps) {
      DeploymentBuildStep.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.deployment !== undefined) {
      Deployment.encode(message.deployment, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDeploymentStepsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDeploymentStepsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.steps.push(DeploymentBuildStep.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.deployment = Deployment.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDeploymentStepsResponse {
    return {
      steps: globalThis.Array.isArray(object?.steps)
        ? object.steps.map((e: any) => DeploymentBuildStep.fromJSON(e))
        : [],
      deployment: isSet(object.deployment) ? Deployment.fromJSON(object.deployment) : undefined,
    };
  },

  toJSON(message: GetDeploymentStepsResponse): unknown {
    const obj: any = {};
    if (message.steps?.length) {
      obj.steps = message.steps.map((e) => DeploymentBuildStep.toJSON(e));
    }
    if (message.deployment !== undefined) {
      obj.deployment = Deployment.toJSON(message.deployment);
    }
    return obj;
  },
};

function createBaseGetDeploymentLogsRequest(): GetDeploymentLogsRequest {
  return { deploymentId: "" };
}

export const GetDeploymentLogsRequest: MessageFns<GetDeploymentLogsRequest> = {
  encode(message: GetDeploymentLogsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deploymentId !== "") {
      writer.uint32(10).string(message.deploymentId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDeploymentLogsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDeploymentLogsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.deploymentId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDeploymentLogsRequest {
    return { deploymentId: isSet(object.deploymentId) ? globalThis.String(object.deploymentId) : "" };
  },

  toJSON(message: GetDeploymentLogsRequest): unknown {
    const obj: any = {};
    if (message.deploymentId !== "") {
      obj.deploymentId = message.deploymentId;
    }
    return obj;
  },
};

function createBaseGetDeploymentLogsResponse(): GetDeploymentLogsResponse {
  return { logs: [] };
}

export const GetDeploymentLogsResponse: MessageFns<GetDeploymentLogsResponse> = {
  encode(message: GetDeploymentLogsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.logs) {
      LogEntry.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDeploymentLogsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDeploymentLogsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.logs.push(LogEntry.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDeploymentLogsResponse {
    return { logs: globalThis.Array.isArray(object?.logs) ? object.logs.map((e: any) => LogEntry.fromJSON(e)) : [] };
  },

  toJSON(message: GetDeploymentLogsResponse): unknown {
    const obj: any = {};
    if (message.logs?.length) {
      obj.logs = message.logs.map((e) => LogEntry.toJSON(e));
    }
    return obj;
  },
};

function createBaseGetClusterTimescaleDBRequest(): GetClusterTimescaleDBRequest {
  return { environmentId: "" };
}

export const GetClusterTimescaleDBRequest: MessageFns<GetClusterTimescaleDBRequest> = {
  encode(message: GetClusterTimescaleDBRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.environmentId !== "") {
      writer.uint32(10).string(message.environmentId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetClusterTimescaleDBRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetClusterTimescaleDBRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.environmentId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetClusterTimescaleDBRequest {
    return { environmentId: isSet(object.environmentId) ? globalThis.String(object.environmentId) : "" };
  },

  toJSON(message: GetClusterTimescaleDBRequest): unknown {
    const obj: any = {};
    if (message.environmentId !== "") {
      obj.environmentId = message.environmentId;
    }
    return obj;
  },
};

function createBaseGetClusterTimescaleDBResponse(): GetClusterTimescaleDBResponse {
  return { id: "", specsString: "", createdAt: undefined, updatedAt: undefined, specs: undefined };
}

export const GetClusterTimescaleDBResponse: MessageFns<GetClusterTimescaleDBResponse> = {
  encode(message: GetClusterTimescaleDBResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.specsString !== "") {
      writer.uint32(18).string(message.specsString);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAt), writer.uint32(26).fork()).join();
    }
    if (message.updatedAt !== undefined) {
      Timestamp.encode(toTimestamp(message.updatedAt), writer.uint32(34).fork()).join();
    }
    if (message.specs !== undefined) {
      ClusterTimescaleSpecs.encode(message.specs, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetClusterTimescaleDBResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetClusterTimescaleDBResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.specsString = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createdAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updatedAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.specs = ClusterTimescaleSpecs.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetClusterTimescaleDBResponse {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      specsString: isSet(object.specsString) ? globalThis.String(object.specsString) : "",
      createdAt: isSet(object.createdAt) ? fromJsonTimestamp(object.createdAt) : undefined,
      updatedAt: isSet(object.updatedAt) ? fromJsonTimestamp(object.updatedAt) : undefined,
      specs: isSet(object.specs) ? ClusterTimescaleSpecs.fromJSON(object.specs) : undefined,
    };
  },

  toJSON(message: GetClusterTimescaleDBResponse): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.specsString !== "") {
      obj.specsString = message.specsString;
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    if (message.updatedAt !== undefined) {
      obj.updatedAt = message.updatedAt.toISOString();
    }
    if (message.specs !== undefined) {
      obj.specs = ClusterTimescaleSpecs.toJSON(message.specs);
    }
    return obj;
  },
};

function createBaseGetClusterGatewayRequest(): GetClusterGatewayRequest {
  return { environmentId: "" };
}

export const GetClusterGatewayRequest: MessageFns<GetClusterGatewayRequest> = {
  encode(message: GetClusterGatewayRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.environmentId !== "") {
      writer.uint32(10).string(message.environmentId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetClusterGatewayRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetClusterGatewayRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.environmentId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetClusterGatewayRequest {
    return { environmentId: isSet(object.environmentId) ? globalThis.String(object.environmentId) : "" };
  },

  toJSON(message: GetClusterGatewayRequest): unknown {
    const obj: any = {};
    if (message.environmentId !== "") {
      obj.environmentId = message.environmentId;
    }
    return obj;
  },
};

function createBaseGetClusterGatewayResponse(): GetClusterGatewayResponse {
  return { id: "", specsString: "", createdAt: undefined, updatedAt: undefined, specs: undefined };
}

export const GetClusterGatewayResponse: MessageFns<GetClusterGatewayResponse> = {
  encode(message: GetClusterGatewayResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.specsString !== "") {
      writer.uint32(18).string(message.specsString);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAt), writer.uint32(26).fork()).join();
    }
    if (message.updatedAt !== undefined) {
      Timestamp.encode(toTimestamp(message.updatedAt), writer.uint32(34).fork()).join();
    }
    if (message.specs !== undefined) {
      EnvoyGatewaySpecs.encode(message.specs, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetClusterGatewayResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetClusterGatewayResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.specsString = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createdAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updatedAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.specs = EnvoyGatewaySpecs.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetClusterGatewayResponse {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      specsString: isSet(object.specsString) ? globalThis.String(object.specsString) : "",
      createdAt: isSet(object.createdAt) ? fromJsonTimestamp(object.createdAt) : undefined,
      updatedAt: isSet(object.updatedAt) ? fromJsonTimestamp(object.updatedAt) : undefined,
      specs: isSet(object.specs) ? EnvoyGatewaySpecs.fromJSON(object.specs) : undefined,
    };
  },

  toJSON(message: GetClusterGatewayResponse): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.specsString !== "") {
      obj.specsString = message.specsString;
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    if (message.updatedAt !== undefined) {
      obj.updatedAt = message.updatedAt.toISOString();
    }
    if (message.specs !== undefined) {
      obj.specs = EnvoyGatewaySpecs.toJSON(message.specs);
    }
    return obj;
  },
};

function createBaseBackgroundPersistence(): BackgroundPersistence {
  return { id: "", kind: "", specsString: "", createdAt: undefined, updatedAt: undefined, specs: undefined };
}

export const BackgroundPersistence: MessageFns<BackgroundPersistence> = {
  encode(message: BackgroundPersistence, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.kind !== "") {
      writer.uint32(18).string(message.kind);
    }
    if (message.specsString !== "") {
      writer.uint32(26).string(message.specsString);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAt), writer.uint32(34).fork()).join();
    }
    if (message.updatedAt !== undefined) {
      Timestamp.encode(toTimestamp(message.updatedAt), writer.uint32(42).fork()).join();
    }
    if (message.specs !== undefined) {
      BackgroundPersistenceDeploymentSpecs.encode(message.specs, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackgroundPersistence {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackgroundPersistence();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.kind = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.specsString = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.createdAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.updatedAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.specs = BackgroundPersistenceDeploymentSpecs.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackgroundPersistence {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      specsString: isSet(object.specsString) ? globalThis.String(object.specsString) : "",
      createdAt: isSet(object.createdAt) ? fromJsonTimestamp(object.createdAt) : undefined,
      updatedAt: isSet(object.updatedAt) ? fromJsonTimestamp(object.updatedAt) : undefined,
      specs: isSet(object.specs) ? BackgroundPersistenceDeploymentSpecs.fromJSON(object.specs) : undefined,
    };
  },

  toJSON(message: BackgroundPersistence): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.specsString !== "") {
      obj.specsString = message.specsString;
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    if (message.updatedAt !== undefined) {
      obj.updatedAt = message.updatedAt.toISOString();
    }
    if (message.specs !== undefined) {
      obj.specs = BackgroundPersistenceDeploymentSpecs.toJSON(message.specs);
    }
    return obj;
  },
};

function createBaseGetClusterBackgroundPersistenceRequest(): GetClusterBackgroundPersistenceRequest {
  return { environmentId: "" };
}

export const GetClusterBackgroundPersistenceRequest: MessageFns<GetClusterBackgroundPersistenceRequest> = {
  encode(message: GetClusterBackgroundPersistenceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.environmentId !== "") {
      writer.uint32(10).string(message.environmentId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetClusterBackgroundPersistenceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetClusterBackgroundPersistenceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.environmentId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetClusterBackgroundPersistenceRequest {
    return { environmentId: isSet(object.environmentId) ? globalThis.String(object.environmentId) : "" };
  },

  toJSON(message: GetClusterBackgroundPersistenceRequest): unknown {
    const obj: any = {};
    if (message.environmentId !== "") {
      obj.environmentId = message.environmentId;
    }
    return obj;
  },
};

function createBaseGetClusterBackgroundPersistenceResponse(): GetClusterBackgroundPersistenceResponse {
  return { backgroundPersistence: undefined };
}

export const GetClusterBackgroundPersistenceResponse: MessageFns<GetClusterBackgroundPersistenceResponse> = {
  encode(message: GetClusterBackgroundPersistenceResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.backgroundPersistence !== undefined) {
      BackgroundPersistence.encode(message.backgroundPersistence, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetClusterBackgroundPersistenceResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetClusterBackgroundPersistenceResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.backgroundPersistence = BackgroundPersistence.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetClusterBackgroundPersistenceResponse {
    return {
      backgroundPersistence: isSet(object.backgroundPersistence)
        ? BackgroundPersistence.fromJSON(object.backgroundPersistence)
        : undefined,
    };
  },

  toJSON(message: GetClusterBackgroundPersistenceResponse): unknown {
    const obj: any = {};
    if (message.backgroundPersistence !== undefined) {
      obj.backgroundPersistence = BackgroundPersistence.toJSON(message.backgroundPersistence);
    }
    return obj;
  },
};

function createBaseCreateClusterTimescaleDBRequest(): CreateClusterTimescaleDBRequest {
  return { environmentId: [], environmentIds: [], specsString: "", specs: undefined };
}

export const CreateClusterTimescaleDBRequest: MessageFns<CreateClusterTimescaleDBRequest> = {
  encode(message: CreateClusterTimescaleDBRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.environmentId) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.environmentIds) {
      writer.uint32(26).string(v!);
    }
    if (message.specsString !== "") {
      writer.uint32(18).string(message.specsString);
    }
    if (message.specs !== undefined) {
      ClusterTimescaleSpecs.encode(message.specs, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateClusterTimescaleDBRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateClusterTimescaleDBRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.environmentId.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.environmentIds.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.specsString = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.specs = ClusterTimescaleSpecs.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateClusterTimescaleDBRequest {
    return {
      environmentId: globalThis.Array.isArray(object?.environmentId)
        ? object.environmentId.map((e: any) => globalThis.String(e))
        : [],
      environmentIds: globalThis.Array.isArray(object?.environmentIds)
        ? object.environmentIds.map((e: any) => globalThis.String(e))
        : [],
      specsString: isSet(object.specsString) ? globalThis.String(object.specsString) : "",
      specs: isSet(object.specs) ? ClusterTimescaleSpecs.fromJSON(object.specs) : undefined,
    };
  },

  toJSON(message: CreateClusterTimescaleDBRequest): unknown {
    const obj: any = {};
    if (message.environmentId?.length) {
      obj.environmentId = message.environmentId;
    }
    if (message.environmentIds?.length) {
      obj.environmentIds = message.environmentIds;
    }
    if (message.specsString !== "") {
      obj.specsString = message.specsString;
    }
    if (message.specs !== undefined) {
      obj.specs = ClusterTimescaleSpecs.toJSON(message.specs);
    }
    return obj;
  },
};

function createBaseKubeResourceConfig(): KubeResourceConfig {
  return { cpu: "", memory: "", ephemeralStorage: "", storage: "" };
}

export const KubeResourceConfig: MessageFns<KubeResourceConfig> = {
  encode(message: KubeResourceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cpu !== "") {
      writer.uint32(10).string(message.cpu);
    }
    if (message.memory !== "") {
      writer.uint32(18).string(message.memory);
    }
    if (message.ephemeralStorage !== "") {
      writer.uint32(26).string(message.ephemeralStorage);
    }
    if (message.storage !== "") {
      writer.uint32(34).string(message.storage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KubeResourceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKubeResourceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cpu = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.memory = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.ephemeralStorage = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.storage = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KubeResourceConfig {
    return {
      cpu: isSet(object.cpu) ? globalThis.String(object.cpu) : "",
      memory: isSet(object.memory) ? globalThis.String(object.memory) : "",
      ephemeralStorage: isSet(object.ephemeralStorage) ? globalThis.String(object.ephemeralStorage) : "",
      storage: isSet(object.storage) ? globalThis.String(object.storage) : "",
    };
  },

  toJSON(message: KubeResourceConfig): unknown {
    const obj: any = {};
    if (message.cpu !== "") {
      obj.cpu = message.cpu;
    }
    if (message.memory !== "") {
      obj.memory = message.memory;
    }
    if (message.ephemeralStorage !== "") {
      obj.ephemeralStorage = message.ephemeralStorage;
    }
    if (message.storage !== "") {
      obj.storage = message.storage;
    }
    return obj;
  },
};

function createBaseClusterTimescaleSpecs(): ClusterTimescaleSpecs {
  return {
    timescaleImage: "",
    databaseName: "",
    databaseReplicas: 0,
    storage: "",
    storageClass: undefined,
    namespace: "",
    request: undefined,
    limit: undefined,
    connectionPoolReplicas: 0,
    connectionPoolMaxConnections: "",
    connectionPoolSize: "",
    connectionPoolMode: "",
    backupBucket: "",
    backupIamRoleArn: "",
    secretName: "",
    internal: undefined,
    serviceType: undefined,
    postgresParameters: {},
    includeChalkNodeSelector: false,
    backupGcpServiceAccount: "",
    instanceType: "",
  };
}

export const ClusterTimescaleSpecs: MessageFns<ClusterTimescaleSpecs> = {
  encode(message: ClusterTimescaleSpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timescaleImage !== "") {
      writer.uint32(10).string(message.timescaleImage);
    }
    if (message.databaseName !== "") {
      writer.uint32(18).string(message.databaseName);
    }
    if (message.databaseReplicas !== 0) {
      writer.uint32(24).int32(message.databaseReplicas);
    }
    if (message.storage !== "") {
      writer.uint32(34).string(message.storage);
    }
    if (message.storageClass !== undefined) {
      writer.uint32(42).string(message.storageClass);
    }
    if (message.namespace !== "") {
      writer.uint32(50).string(message.namespace);
    }
    if (message.request !== undefined) {
      KubeResourceConfig.encode(message.request, writer.uint32(58).fork()).join();
    }
    if (message.limit !== undefined) {
      KubeResourceConfig.encode(message.limit, writer.uint32(66).fork()).join();
    }
    if (message.connectionPoolReplicas !== 0) {
      writer.uint32(72).int32(message.connectionPoolReplicas);
    }
    if (message.connectionPoolMaxConnections !== "") {
      writer.uint32(82).string(message.connectionPoolMaxConnections);
    }
    if (message.connectionPoolSize !== "") {
      writer.uint32(90).string(message.connectionPoolSize);
    }
    if (message.connectionPoolMode !== "") {
      writer.uint32(98).string(message.connectionPoolMode);
    }
    if (message.backupBucket !== "") {
      writer.uint32(106).string(message.backupBucket);
    }
    if (message.backupIamRoleArn !== "") {
      writer.uint32(114).string(message.backupIamRoleArn);
    }
    if (message.secretName !== "") {
      writer.uint32(122).string(message.secretName);
    }
    if (message.internal !== undefined) {
      writer.uint32(128).bool(message.internal);
    }
    if (message.serviceType !== undefined) {
      writer.uint32(138).string(message.serviceType);
    }
    Object.entries(message.postgresParameters).forEach(([key, value]) => {
      ClusterTimescaleSpecs_PostgresParametersEntry.encode({ key: key as any, value }, writer.uint32(146).fork())
        .join();
    });
    if (message.includeChalkNodeSelector !== false) {
      writer.uint32(152).bool(message.includeChalkNodeSelector);
    }
    if (message.backupGcpServiceAccount !== "") {
      writer.uint32(162).string(message.backupGcpServiceAccount);
    }
    if (message.instanceType !== "") {
      writer.uint32(170).string(message.instanceType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterTimescaleSpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterTimescaleSpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.timescaleImage = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.databaseName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.databaseReplicas = reader.int32();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.storage = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.storageClass = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.namespace = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.request = KubeResourceConfig.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.limit = KubeResourceConfig.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.connectionPoolReplicas = reader.int32();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.connectionPoolMaxConnections = reader.string();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.connectionPoolSize = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.connectionPoolMode = reader.string();
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.backupBucket = reader.string();
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.backupIamRoleArn = reader.string();
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.secretName = reader.string();
          continue;
        }
        case 16: {
          if (tag !== 128) {
            break;
          }

          message.internal = reader.bool();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.serviceType = reader.string();
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          const entry18 = ClusterTimescaleSpecs_PostgresParametersEntry.decode(reader, reader.uint32());
          if (entry18.value !== undefined) {
            message.postgresParameters[entry18.key] = entry18.value;
          }
          continue;
        }
        case 19: {
          if (tag !== 152) {
            break;
          }

          message.includeChalkNodeSelector = reader.bool();
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.backupGcpServiceAccount = reader.string();
          continue;
        }
        case 21: {
          if (tag !== 170) {
            break;
          }

          message.instanceType = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterTimescaleSpecs {
    return {
      timescaleImage: isSet(object.timescaleImage) ? globalThis.String(object.timescaleImage) : "",
      databaseName: isSet(object.databaseName) ? globalThis.String(object.databaseName) : "",
      databaseReplicas: isSet(object.databaseReplicas) ? globalThis.Number(object.databaseReplicas) : 0,
      storage: isSet(object.storage) ? globalThis.String(object.storage) : "",
      storageClass: isSet(object.storageClass) ? globalThis.String(object.storageClass) : undefined,
      namespace: isSet(object.namespace) ? globalThis.String(object.namespace) : "",
      request: isSet(object.request) ? KubeResourceConfig.fromJSON(object.request) : undefined,
      limit: isSet(object.limit) ? KubeResourceConfig.fromJSON(object.limit) : undefined,
      connectionPoolReplicas: isSet(object.connectionPoolReplicas)
        ? globalThis.Number(object.connectionPoolReplicas)
        : 0,
      connectionPoolMaxConnections: isSet(object.connectionPoolMaxConnections)
        ? globalThis.String(object.connectionPoolMaxConnections)
        : "",
      connectionPoolSize: isSet(object.connectionPoolSize) ? globalThis.String(object.connectionPoolSize) : "",
      connectionPoolMode: isSet(object.connectionPoolMode) ? globalThis.String(object.connectionPoolMode) : "",
      backupBucket: isSet(object.backupBucket) ? globalThis.String(object.backupBucket) : "",
      backupIamRoleArn: isSet(object.backupIamRoleArn) ? globalThis.String(object.backupIamRoleArn) : "",
      secretName: isSet(object.secretName) ? globalThis.String(object.secretName) : "",
      internal: isSet(object.internal) ? globalThis.Boolean(object.internal) : undefined,
      serviceType: isSet(object.serviceType) ? globalThis.String(object.serviceType) : undefined,
      postgresParameters: isObject(object.postgresParameters)
        ? Object.entries(object.postgresParameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      includeChalkNodeSelector: isSet(object.includeChalkNodeSelector)
        ? globalThis.Boolean(object.includeChalkNodeSelector)
        : false,
      backupGcpServiceAccount: isSet(object.backupGcpServiceAccount)
        ? globalThis.String(object.backupGcpServiceAccount)
        : "",
      instanceType: isSet(object.instanceType) ? globalThis.String(object.instanceType) : "",
    };
  },

  toJSON(message: ClusterTimescaleSpecs): unknown {
    const obj: any = {};
    if (message.timescaleImage !== "") {
      obj.timescaleImage = message.timescaleImage;
    }
    if (message.databaseName !== "") {
      obj.databaseName = message.databaseName;
    }
    if (message.databaseReplicas !== 0) {
      obj.databaseReplicas = Math.round(message.databaseReplicas);
    }
    if (message.storage !== "") {
      obj.storage = message.storage;
    }
    if (message.storageClass !== undefined) {
      obj.storageClass = message.storageClass;
    }
    if (message.namespace !== "") {
      obj.namespace = message.namespace;
    }
    if (message.request !== undefined) {
      obj.request = KubeResourceConfig.toJSON(message.request);
    }
    if (message.limit !== undefined) {
      obj.limit = KubeResourceConfig.toJSON(message.limit);
    }
    if (message.connectionPoolReplicas !== 0) {
      obj.connectionPoolReplicas = Math.round(message.connectionPoolReplicas);
    }
    if (message.connectionPoolMaxConnections !== "") {
      obj.connectionPoolMaxConnections = message.connectionPoolMaxConnections;
    }
    if (message.connectionPoolSize !== "") {
      obj.connectionPoolSize = message.connectionPoolSize;
    }
    if (message.connectionPoolMode !== "") {
      obj.connectionPoolMode = message.connectionPoolMode;
    }
    if (message.backupBucket !== "") {
      obj.backupBucket = message.backupBucket;
    }
    if (message.backupIamRoleArn !== "") {
      obj.backupIamRoleArn = message.backupIamRoleArn;
    }
    if (message.secretName !== "") {
      obj.secretName = message.secretName;
    }
    if (message.internal !== undefined) {
      obj.internal = message.internal;
    }
    if (message.serviceType !== undefined) {
      obj.serviceType = message.serviceType;
    }
    if (message.postgresParameters) {
      const entries = Object.entries(message.postgresParameters);
      if (entries.length > 0) {
        obj.postgresParameters = {};
        entries.forEach(([k, v]) => {
          obj.postgresParameters[k] = v;
        });
      }
    }
    if (message.includeChalkNodeSelector !== false) {
      obj.includeChalkNodeSelector = message.includeChalkNodeSelector;
    }
    if (message.backupGcpServiceAccount !== "") {
      obj.backupGcpServiceAccount = message.backupGcpServiceAccount;
    }
    if (message.instanceType !== "") {
      obj.instanceType = message.instanceType;
    }
    return obj;
  },
};

function createBaseClusterTimescaleSpecs_PostgresParametersEntry(): ClusterTimescaleSpecs_PostgresParametersEntry {
  return { key: "", value: "" };
}

export const ClusterTimescaleSpecs_PostgresParametersEntry: MessageFns<ClusterTimescaleSpecs_PostgresParametersEntry> =
  {
    encode(
      message: ClusterTimescaleSpecs_PostgresParametersEntry,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.key !== "") {
        writer.uint32(10).string(message.key);
      }
      if (message.value !== "") {
        writer.uint32(18).string(message.value);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): ClusterTimescaleSpecs_PostgresParametersEntry {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseClusterTimescaleSpecs_PostgresParametersEntry();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.key = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.value = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): ClusterTimescaleSpecs_PostgresParametersEntry {
      return {
        key: isSet(object.key) ? globalThis.String(object.key) : "",
        value: isSet(object.value) ? globalThis.String(object.value) : "",
      };
    },

    toJSON(message: ClusterTimescaleSpecs_PostgresParametersEntry): unknown {
      const obj: any = {};
      if (message.key !== "") {
        obj.key = message.key;
      }
      if (message.value !== "") {
        obj.value = message.value;
      }
      return obj;
    },
  };

function createBaseCreateClusterTimescaleDBResponse(): CreateClusterTimescaleDBResponse {
  return {};
}

export const CreateClusterTimescaleDBResponse: MessageFns<CreateClusterTimescaleDBResponse> = {
  encode(_: CreateClusterTimescaleDBResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateClusterTimescaleDBResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateClusterTimescaleDBResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CreateClusterTimescaleDBResponse {
    return {};
  },

  toJSON(_: CreateClusterTimescaleDBResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseMigrateClusterTimescaleDBRequest(): MigrateClusterTimescaleDBRequest {
  return { clusterTimescaleId: "", migrationImage: undefined, environmentIds: [] };
}

export const MigrateClusterTimescaleDBRequest: MessageFns<MigrateClusterTimescaleDBRequest> = {
  encode(message: MigrateClusterTimescaleDBRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.clusterTimescaleId !== "") {
      writer.uint32(10).string(message.clusterTimescaleId);
    }
    if (message.migrationImage !== undefined) {
      writer.uint32(18).string(message.migrationImage);
    }
    for (const v of message.environmentIds) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrateClusterTimescaleDBRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrateClusterTimescaleDBRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.clusterTimescaleId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.migrationImage = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.environmentIds.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrateClusterTimescaleDBRequest {
    return {
      clusterTimescaleId: isSet(object.clusterTimescaleId) ? globalThis.String(object.clusterTimescaleId) : "",
      migrationImage: isSet(object.migrationImage) ? globalThis.String(object.migrationImage) : undefined,
      environmentIds: globalThis.Array.isArray(object?.environmentIds)
        ? object.environmentIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: MigrateClusterTimescaleDBRequest): unknown {
    const obj: any = {};
    if (message.clusterTimescaleId !== "") {
      obj.clusterTimescaleId = message.clusterTimescaleId;
    }
    if (message.migrationImage !== undefined) {
      obj.migrationImage = message.migrationImage;
    }
    if (message.environmentIds?.length) {
      obj.environmentIds = message.environmentIds;
    }
    return obj;
  },
};

function createBaseMigrateClusterTimescaleDBResponse(): MigrateClusterTimescaleDBResponse {
  return {};
}

export const MigrateClusterTimescaleDBResponse: MessageFns<MigrateClusterTimescaleDBResponse> = {
  encode(_: MigrateClusterTimescaleDBResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrateClusterTimescaleDBResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrateClusterTimescaleDBResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): MigrateClusterTimescaleDBResponse {
    return {};
  },

  toJSON(_: MigrateClusterTimescaleDBResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseCreateClusterGatewayRequest(): CreateClusterGatewayRequest {
  return { environmentId: [], environmentIds: [], specsString: "", specs: undefined };
}

export const CreateClusterGatewayRequest: MessageFns<CreateClusterGatewayRequest> = {
  encode(message: CreateClusterGatewayRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.environmentId) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.environmentIds) {
      writer.uint32(26).string(v!);
    }
    if (message.specsString !== "") {
      writer.uint32(18).string(message.specsString);
    }
    if (message.specs !== undefined) {
      EnvoyGatewaySpecs.encode(message.specs, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateClusterGatewayRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateClusterGatewayRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.environmentId.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.environmentIds.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.specsString = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.specs = EnvoyGatewaySpecs.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateClusterGatewayRequest {
    return {
      environmentId: globalThis.Array.isArray(object?.environmentId)
        ? object.environmentId.map((e: any) => globalThis.String(e))
        : [],
      environmentIds: globalThis.Array.isArray(object?.environmentIds)
        ? object.environmentIds.map((e: any) => globalThis.String(e))
        : [],
      specsString: isSet(object.specsString) ? globalThis.String(object.specsString) : "",
      specs: isSet(object.specs) ? EnvoyGatewaySpecs.fromJSON(object.specs) : undefined,
    };
  },

  toJSON(message: CreateClusterGatewayRequest): unknown {
    const obj: any = {};
    if (message.environmentId?.length) {
      obj.environmentId = message.environmentId;
    }
    if (message.environmentIds?.length) {
      obj.environmentIds = message.environmentIds;
    }
    if (message.specsString !== "") {
      obj.specsString = message.specsString;
    }
    if (message.specs !== undefined) {
      obj.specs = EnvoyGatewaySpecs.toJSON(message.specs);
    }
    return obj;
  },
};

function createBaseEnvoyGatewaySpecs(): EnvoyGatewaySpecs {
  return {
    namespace: "",
    gatewayName: "",
    gatewayClassName: "",
    listeners: [],
    config: undefined,
    includeChalkNodeSelector: false,
    ipAllowlist: [],
    tlsCertificate: undefined,
  };
}

export const EnvoyGatewaySpecs: MessageFns<EnvoyGatewaySpecs> = {
  encode(message: EnvoyGatewaySpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.namespace !== "") {
      writer.uint32(10).string(message.namespace);
    }
    if (message.gatewayName !== "") {
      writer.uint32(18).string(message.gatewayName);
    }
    if (message.gatewayClassName !== "") {
      writer.uint32(26).string(message.gatewayClassName);
    }
    for (const v of message.listeners) {
      EnvoyGatewayListener.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.config !== undefined) {
      GatewayProviderConfig.encode(message.config, writer.uint32(42).fork()).join();
    }
    if (message.includeChalkNodeSelector !== false) {
      writer.uint32(48).bool(message.includeChalkNodeSelector);
    }
    for (const v of message.ipAllowlist) {
      writer.uint32(58).string(v!);
    }
    if (message.tlsCertificate !== undefined) {
      TLSCertificateConfig.encode(message.tlsCertificate, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EnvoyGatewaySpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvoyGatewaySpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.namespace = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gatewayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.gatewayClassName = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.listeners.push(EnvoyGatewayListener.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.config = GatewayProviderConfig.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.includeChalkNodeSelector = reader.bool();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.ipAllowlist.push(reader.string());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.tlsCertificate = TLSCertificateConfig.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EnvoyGatewaySpecs {
    return {
      namespace: isSet(object.namespace) ? globalThis.String(object.namespace) : "",
      gatewayName: isSet(object.gatewayName) ? globalThis.String(object.gatewayName) : "",
      gatewayClassName: isSet(object.gatewayClassName) ? globalThis.String(object.gatewayClassName) : "",
      listeners: globalThis.Array.isArray(object?.listeners)
        ? object.listeners.map((e: any) => EnvoyGatewayListener.fromJSON(e))
        : [],
      config: isSet(object.config) ? GatewayProviderConfig.fromJSON(object.config) : undefined,
      includeChalkNodeSelector: isSet(object.includeChalkNodeSelector)
        ? globalThis.Boolean(object.includeChalkNodeSelector)
        : false,
      ipAllowlist: globalThis.Array.isArray(object?.ipAllowlist)
        ? object.ipAllowlist.map((e: any) => globalThis.String(e))
        : [],
      tlsCertificate: isSet(object.tlsCertificate) ? TLSCertificateConfig.fromJSON(object.tlsCertificate) : undefined,
    };
  },

  toJSON(message: EnvoyGatewaySpecs): unknown {
    const obj: any = {};
    if (message.namespace !== "") {
      obj.namespace = message.namespace;
    }
    if (message.gatewayName !== "") {
      obj.gatewayName = message.gatewayName;
    }
    if (message.gatewayClassName !== "") {
      obj.gatewayClassName = message.gatewayClassName;
    }
    if (message.listeners?.length) {
      obj.listeners = message.listeners.map((e) => EnvoyGatewayListener.toJSON(e));
    }
    if (message.config !== undefined) {
      obj.config = GatewayProviderConfig.toJSON(message.config);
    }
    if (message.includeChalkNodeSelector !== false) {
      obj.includeChalkNodeSelector = message.includeChalkNodeSelector;
    }
    if (message.ipAllowlist?.length) {
      obj.ipAllowlist = message.ipAllowlist;
    }
    if (message.tlsCertificate !== undefined) {
      obj.tlsCertificate = TLSCertificateConfig.toJSON(message.tlsCertificate);
    }
    return obj;
  },
};

function createBaseEnvoyGatewayListener(): EnvoyGatewayListener {
  return { port: 0, protocol: "", name: "", allowedRoutes: undefined };
}

export const EnvoyGatewayListener: MessageFns<EnvoyGatewayListener> = {
  encode(message: EnvoyGatewayListener, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.port !== 0) {
      writer.uint32(8).int32(message.port);
    }
    if (message.protocol !== "") {
      writer.uint32(18).string(message.protocol);
    }
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    if (message.allowedRoutes !== undefined) {
      EnvoyGatewayAllowedRoutes.encode(message.allowedRoutes, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EnvoyGatewayListener {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvoyGatewayListener();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.port = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.protocol = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.allowedRoutes = EnvoyGatewayAllowedRoutes.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EnvoyGatewayListener {
    return {
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      protocol: isSet(object.protocol) ? globalThis.String(object.protocol) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      allowedRoutes: isSet(object.allowedRoutes) ? EnvoyGatewayAllowedRoutes.fromJSON(object.allowedRoutes) : undefined,
    };
  },

  toJSON(message: EnvoyGatewayListener): unknown {
    const obj: any = {};
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.protocol !== "") {
      obj.protocol = message.protocol;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.allowedRoutes !== undefined) {
      obj.allowedRoutes = EnvoyGatewayAllowedRoutes.toJSON(message.allowedRoutes);
    }
    return obj;
  },
};

function createBaseEnvoyGatewayAllowedRoutes(): EnvoyGatewayAllowedRoutes {
  return { namespaces: undefined };
}

export const EnvoyGatewayAllowedRoutes: MessageFns<EnvoyGatewayAllowedRoutes> = {
  encode(message: EnvoyGatewayAllowedRoutes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.namespaces !== undefined) {
      EnvoyGatewayAllowedNamespaces.encode(message.namespaces, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EnvoyGatewayAllowedRoutes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvoyGatewayAllowedRoutes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.namespaces = EnvoyGatewayAllowedNamespaces.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EnvoyGatewayAllowedRoutes {
    return {
      namespaces: isSet(object.namespaces) ? EnvoyGatewayAllowedNamespaces.fromJSON(object.namespaces) : undefined,
    };
  },

  toJSON(message: EnvoyGatewayAllowedRoutes): unknown {
    const obj: any = {};
    if (message.namespaces !== undefined) {
      obj.namespaces = EnvoyGatewayAllowedNamespaces.toJSON(message.namespaces);
    }
    return obj;
  },
};

function createBaseEnvoyGatewayAllowedNamespaces(): EnvoyGatewayAllowedNamespaces {
  return { from: "" };
}

export const EnvoyGatewayAllowedNamespaces: MessageFns<EnvoyGatewayAllowedNamespaces> = {
  encode(message: EnvoyGatewayAllowedNamespaces, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.from !== "") {
      writer.uint32(10).string(message.from);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EnvoyGatewayAllowedNamespaces {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvoyGatewayAllowedNamespaces();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.from = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EnvoyGatewayAllowedNamespaces {
    return { from: isSet(object.from) ? globalThis.String(object.from) : "" };
  },

  toJSON(message: EnvoyGatewayAllowedNamespaces): unknown {
    const obj: any = {};
    if (message.from !== "") {
      obj.from = message.from;
    }
    return obj;
  },
};

function createBaseGatewayProviderConfig(): GatewayProviderConfig {
  return { envoy: undefined, gcp: undefined };
}

export const GatewayProviderConfig: MessageFns<GatewayProviderConfig> = {
  encode(message: GatewayProviderConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.envoy !== undefined) {
      EnvoyGatewayProviderConfig.encode(message.envoy, writer.uint32(10).fork()).join();
    }
    if (message.gcp !== undefined) {
      GCPGatewayProviderConfig.encode(message.gcp, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GatewayProviderConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGatewayProviderConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.envoy = EnvoyGatewayProviderConfig.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gcp = GCPGatewayProviderConfig.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GatewayProviderConfig {
    return {
      envoy: isSet(object.envoy) ? EnvoyGatewayProviderConfig.fromJSON(object.envoy) : undefined,
      gcp: isSet(object.gcp) ? GCPGatewayProviderConfig.fromJSON(object.gcp) : undefined,
    };
  },

  toJSON(message: GatewayProviderConfig): unknown {
    const obj: any = {};
    if (message.envoy !== undefined) {
      obj.envoy = EnvoyGatewayProviderConfig.toJSON(message.envoy);
    }
    if (message.gcp !== undefined) {
      obj.gcp = GCPGatewayProviderConfig.toJSON(message.gcp);
    }
    return obj;
  },
};

function createBaseEnvoyGatewayProviderConfig(): EnvoyGatewayProviderConfig {
  return { timeoutDuration: undefined, dnsHostname: undefined, replicas: undefined, minAvailable: undefined };
}

export const EnvoyGatewayProviderConfig: MessageFns<EnvoyGatewayProviderConfig> = {
  encode(message: EnvoyGatewayProviderConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.timeoutDuration !== undefined) {
      writer.uint32(10).string(message.timeoutDuration);
    }
    if (message.dnsHostname !== undefined) {
      writer.uint32(18).string(message.dnsHostname);
    }
    if (message.replicas !== undefined) {
      writer.uint32(24).int32(message.replicas);
    }
    if (message.minAvailable !== undefined) {
      writer.uint32(32).int32(message.minAvailable);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EnvoyGatewayProviderConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvoyGatewayProviderConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.timeoutDuration = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dnsHostname = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.replicas = reader.int32();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.minAvailable = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EnvoyGatewayProviderConfig {
    return {
      timeoutDuration: isSet(object.timeoutDuration) ? globalThis.String(object.timeoutDuration) : undefined,
      dnsHostname: isSet(object.dnsHostname) ? globalThis.String(object.dnsHostname) : undefined,
      replicas: isSet(object.replicas) ? globalThis.Number(object.replicas) : undefined,
      minAvailable: isSet(object.minAvailable) ? globalThis.Number(object.minAvailable) : undefined,
    };
  },

  toJSON(message: EnvoyGatewayProviderConfig): unknown {
    const obj: any = {};
    if (message.timeoutDuration !== undefined) {
      obj.timeoutDuration = message.timeoutDuration;
    }
    if (message.dnsHostname !== undefined) {
      obj.dnsHostname = message.dnsHostname;
    }
    if (message.replicas !== undefined) {
      obj.replicas = Math.round(message.replicas);
    }
    if (message.minAvailable !== undefined) {
      obj.minAvailable = Math.round(message.minAvailable);
    }
    return obj;
  },
};

function createBaseGCPGatewayProviderConfig(): GCPGatewayProviderConfig {
  return { dnsHostname: "" };
}

export const GCPGatewayProviderConfig: MessageFns<GCPGatewayProviderConfig> = {
  encode(message: GCPGatewayProviderConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dnsHostname !== "") {
      writer.uint32(10).string(message.dnsHostname);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GCPGatewayProviderConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGCPGatewayProviderConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.dnsHostname = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GCPGatewayProviderConfig {
    return { dnsHostname: isSet(object.dnsHostname) ? globalThis.String(object.dnsHostname) : "" };
  },

  toJSON(message: GCPGatewayProviderConfig): unknown {
    const obj: any = {};
    if (message.dnsHostname !== "") {
      obj.dnsHostname = message.dnsHostname;
    }
    return obj;
  },
};

function createBaseTLSCertificateConfig(): TLSCertificateConfig {
  return { manualCertificate: undefined };
}

export const TLSCertificateConfig: MessageFns<TLSCertificateConfig> = {
  encode(message: TLSCertificateConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.manualCertificate !== undefined) {
      TLSManualCertificateRef.encode(message.manualCertificate, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TLSCertificateConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTLSCertificateConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.manualCertificate = TLSManualCertificateRef.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TLSCertificateConfig {
    return {
      manualCertificate: isSet(object.manualCertificate)
        ? TLSManualCertificateRef.fromJSON(object.manualCertificate)
        : undefined,
    };
  },

  toJSON(message: TLSCertificateConfig): unknown {
    const obj: any = {};
    if (message.manualCertificate !== undefined) {
      obj.manualCertificate = TLSManualCertificateRef.toJSON(message.manualCertificate);
    }
    return obj;
  },
};

function createBaseTLSManualCertificateRef(): TLSManualCertificateRef {
  return { secretName: "", secretNamespace: "" };
}

export const TLSManualCertificateRef: MessageFns<TLSManualCertificateRef> = {
  encode(message: TLSManualCertificateRef, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.secretName !== "") {
      writer.uint32(10).string(message.secretName);
    }
    if (message.secretNamespace !== "") {
      writer.uint32(18).string(message.secretNamespace);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TLSManualCertificateRef {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTLSManualCertificateRef();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.secretName = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.secretNamespace = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TLSManualCertificateRef {
    return {
      secretName: isSet(object.secretName) ? globalThis.String(object.secretName) : "",
      secretNamespace: isSet(object.secretNamespace) ? globalThis.String(object.secretNamespace) : "",
    };
  },

  toJSON(message: TLSManualCertificateRef): unknown {
    const obj: any = {};
    if (message.secretName !== "") {
      obj.secretName = message.secretName;
    }
    if (message.secretNamespace !== "") {
      obj.secretNamespace = message.secretNamespace;
    }
    return obj;
  },
};

function createBaseCreateClusterGatewayResponse(): CreateClusterGatewayResponse {
  return {};
}

export const CreateClusterGatewayResponse: MessageFns<CreateClusterGatewayResponse> = {
  encode(_: CreateClusterGatewayResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateClusterGatewayResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateClusterGatewayResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CreateClusterGatewayResponse {
    return {};
  },

  toJSON(_: CreateClusterGatewayResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseCreateClusterBackgroundPersistenceRequest(): CreateClusterBackgroundPersistenceRequest {
  return { environmentIds: [], specsString: "", specs: undefined };
}

export const CreateClusterBackgroundPersistenceRequest: MessageFns<CreateClusterBackgroundPersistenceRequest> = {
  encode(message: CreateClusterBackgroundPersistenceRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.environmentIds) {
      writer.uint32(10).string(v!);
    }
    if (message.specsString !== "") {
      writer.uint32(18).string(message.specsString);
    }
    if (message.specs !== undefined) {
      BackgroundPersistenceDeploymentSpecs.encode(message.specs, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateClusterBackgroundPersistenceRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateClusterBackgroundPersistenceRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.environmentIds.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.specsString = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.specs = BackgroundPersistenceDeploymentSpecs.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateClusterBackgroundPersistenceRequest {
    return {
      environmentIds: globalThis.Array.isArray(object?.environmentIds)
        ? object.environmentIds.map((e: any) => globalThis.String(e))
        : [],
      specsString: isSet(object.specsString) ? globalThis.String(object.specsString) : "",
      specs: isSet(object.specs) ? BackgroundPersistenceDeploymentSpecs.fromJSON(object.specs) : undefined,
    };
  },

  toJSON(message: CreateClusterBackgroundPersistenceRequest): unknown {
    const obj: any = {};
    if (message.environmentIds?.length) {
      obj.environmentIds = message.environmentIds;
    }
    if (message.specsString !== "") {
      obj.specsString = message.specsString;
    }
    if (message.specs !== undefined) {
      obj.specs = BackgroundPersistenceDeploymentSpecs.toJSON(message.specs);
    }
    return obj;
  },
};

function createBaseBackgroundPersistenceCommonSpecs(): BackgroundPersistenceCommonSpecs {
  return {
    namespace: "",
    busWriterImageGo: "",
    busWriterImagePython: "",
    busWriterImageBswl: "",
    serviceAccountName: "",
    busBackend: "",
    secretClient: "",
    bigqueryParquetUploadSubscriptionId: "",
    bigqueryStreamingWriteSubscriptionId: "",
    bigqueryStreamingWriteTopic: "",
    bigqueryUploadBucket: "",
    bigqueryUploadTopic: "",
    googleCloudProject: "",
    kafkaDlqTopic: "",
    metricsBusSubscriptionId: "",
    metricsBusTopicId: "",
    operationSubscriptionId: "",
    queryLogResultTopic: "",
    queryLogSubscriptionId: "",
    resultBusMetricsSubscriptionId: "",
    resultBusOfflineStoreSubscriptionId: "",
    resultBusOnlineStoreSubscriptionId: "",
    resultBusTopicId: "",
    usageBusTopicId: "",
    usageEventsSubscriptionId: "",
    bqUploadBucket: "",
    bqUploadTopic: "",
    includeChalkNodeSelector: false,
    busWriterImageRust: "",
  };
}

export const BackgroundPersistenceCommonSpecs: MessageFns<BackgroundPersistenceCommonSpecs> = {
  encode(message: BackgroundPersistenceCommonSpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.namespace !== "") {
      writer.uint32(10).string(message.namespace);
    }
    if (message.busWriterImageGo !== "") {
      writer.uint32(18).string(message.busWriterImageGo);
    }
    if (message.busWriterImagePython !== "") {
      writer.uint32(26).string(message.busWriterImagePython);
    }
    if (message.busWriterImageBswl !== "") {
      writer.uint32(34).string(message.busWriterImageBswl);
    }
    if (message.serviceAccountName !== "") {
      writer.uint32(42).string(message.serviceAccountName);
    }
    if (message.busBackend !== "") {
      writer.uint32(50).string(message.busBackend);
    }
    if (message.secretClient !== "") {
      writer.uint32(58).string(message.secretClient);
    }
    if (message.bigqueryParquetUploadSubscriptionId !== "") {
      writer.uint32(66).string(message.bigqueryParquetUploadSubscriptionId);
    }
    if (message.bigqueryStreamingWriteSubscriptionId !== "") {
      writer.uint32(74).string(message.bigqueryStreamingWriteSubscriptionId);
    }
    if (message.bigqueryStreamingWriteTopic !== "") {
      writer.uint32(82).string(message.bigqueryStreamingWriteTopic);
    }
    if (message.bigqueryUploadBucket !== "") {
      writer.uint32(90).string(message.bigqueryUploadBucket);
    }
    if (message.bigqueryUploadTopic !== "") {
      writer.uint32(98).string(message.bigqueryUploadTopic);
    }
    if (message.googleCloudProject !== "") {
      writer.uint32(106).string(message.googleCloudProject);
    }
    if (message.kafkaDlqTopic !== "") {
      writer.uint32(114).string(message.kafkaDlqTopic);
    }
    if (message.metricsBusSubscriptionId !== "") {
      writer.uint32(122).string(message.metricsBusSubscriptionId);
    }
    if (message.metricsBusTopicId !== "") {
      writer.uint32(130).string(message.metricsBusTopicId);
    }
    if (message.operationSubscriptionId !== "") {
      writer.uint32(138).string(message.operationSubscriptionId);
    }
    if (message.queryLogResultTopic !== "") {
      writer.uint32(146).string(message.queryLogResultTopic);
    }
    if (message.queryLogSubscriptionId !== "") {
      writer.uint32(154).string(message.queryLogSubscriptionId);
    }
    if (message.resultBusMetricsSubscriptionId !== "") {
      writer.uint32(162).string(message.resultBusMetricsSubscriptionId);
    }
    if (message.resultBusOfflineStoreSubscriptionId !== "") {
      writer.uint32(170).string(message.resultBusOfflineStoreSubscriptionId);
    }
    if (message.resultBusOnlineStoreSubscriptionId !== "") {
      writer.uint32(178).string(message.resultBusOnlineStoreSubscriptionId);
    }
    if (message.resultBusTopicId !== "") {
      writer.uint32(186).string(message.resultBusTopicId);
    }
    if (message.usageBusTopicId !== "") {
      writer.uint32(194).string(message.usageBusTopicId);
    }
    if (message.usageEventsSubscriptionId !== "") {
      writer.uint32(202).string(message.usageEventsSubscriptionId);
    }
    if (message.bqUploadBucket !== "") {
      writer.uint32(210).string(message.bqUploadBucket);
    }
    if (message.bqUploadTopic !== "") {
      writer.uint32(218).string(message.bqUploadTopic);
    }
    if (message.includeChalkNodeSelector !== false) {
      writer.uint32(224).bool(message.includeChalkNodeSelector);
    }
    if (message.busWriterImageRust !== "") {
      writer.uint32(234).string(message.busWriterImageRust);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackgroundPersistenceCommonSpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackgroundPersistenceCommonSpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.namespace = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.busWriterImageGo = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.busWriterImagePython = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.busWriterImageBswl = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.serviceAccountName = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.busBackend = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.secretClient = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.bigqueryParquetUploadSubscriptionId = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.bigqueryStreamingWriteSubscriptionId = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.bigqueryStreamingWriteTopic = reader.string();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.bigqueryUploadBucket = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.bigqueryUploadTopic = reader.string();
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.googleCloudProject = reader.string();
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.kafkaDlqTopic = reader.string();
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.metricsBusSubscriptionId = reader.string();
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.metricsBusTopicId = reader.string();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.operationSubscriptionId = reader.string();
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.queryLogResultTopic = reader.string();
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.queryLogSubscriptionId = reader.string();
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.resultBusMetricsSubscriptionId = reader.string();
          continue;
        }
        case 21: {
          if (tag !== 170) {
            break;
          }

          message.resultBusOfflineStoreSubscriptionId = reader.string();
          continue;
        }
        case 22: {
          if (tag !== 178) {
            break;
          }

          message.resultBusOnlineStoreSubscriptionId = reader.string();
          continue;
        }
        case 23: {
          if (tag !== 186) {
            break;
          }

          message.resultBusTopicId = reader.string();
          continue;
        }
        case 24: {
          if (tag !== 194) {
            break;
          }

          message.usageBusTopicId = reader.string();
          continue;
        }
        case 25: {
          if (tag !== 202) {
            break;
          }

          message.usageEventsSubscriptionId = reader.string();
          continue;
        }
        case 26: {
          if (tag !== 210) {
            break;
          }

          message.bqUploadBucket = reader.string();
          continue;
        }
        case 27: {
          if (tag !== 218) {
            break;
          }

          message.bqUploadTopic = reader.string();
          continue;
        }
        case 28: {
          if (tag !== 224) {
            break;
          }

          message.includeChalkNodeSelector = reader.bool();
          continue;
        }
        case 29: {
          if (tag !== 234) {
            break;
          }

          message.busWriterImageRust = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackgroundPersistenceCommonSpecs {
    return {
      namespace: isSet(object.namespace) ? globalThis.String(object.namespace) : "",
      busWriterImageGo: isSet(object.busWriterImageGo) ? globalThis.String(object.busWriterImageGo) : "",
      busWriterImagePython: isSet(object.busWriterImagePython) ? globalThis.String(object.busWriterImagePython) : "",
      busWriterImageBswl: isSet(object.busWriterImageBswl) ? globalThis.String(object.busWriterImageBswl) : "",
      serviceAccountName: isSet(object.serviceAccountName) ? globalThis.String(object.serviceAccountName) : "",
      busBackend: isSet(object.busBackend) ? globalThis.String(object.busBackend) : "",
      secretClient: isSet(object.secretClient) ? globalThis.String(object.secretClient) : "",
      bigqueryParquetUploadSubscriptionId: isSet(object.bigqueryParquetUploadSubscriptionId)
        ? globalThis.String(object.bigqueryParquetUploadSubscriptionId)
        : "",
      bigqueryStreamingWriteSubscriptionId: isSet(object.bigqueryStreamingWriteSubscriptionId)
        ? globalThis.String(object.bigqueryStreamingWriteSubscriptionId)
        : "",
      bigqueryStreamingWriteTopic: isSet(object.bigqueryStreamingWriteTopic)
        ? globalThis.String(object.bigqueryStreamingWriteTopic)
        : "",
      bigqueryUploadBucket: isSet(object.bigqueryUploadBucket) ? globalThis.String(object.bigqueryUploadBucket) : "",
      bigqueryUploadTopic: isSet(object.bigqueryUploadTopic) ? globalThis.String(object.bigqueryUploadTopic) : "",
      googleCloudProject: isSet(object.googleCloudProject) ? globalThis.String(object.googleCloudProject) : "",
      kafkaDlqTopic: isSet(object.kafkaDlqTopic) ? globalThis.String(object.kafkaDlqTopic) : "",
      metricsBusSubscriptionId: isSet(object.metricsBusSubscriptionId)
        ? globalThis.String(object.metricsBusSubscriptionId)
        : "",
      metricsBusTopicId: isSet(object.metricsBusTopicId) ? globalThis.String(object.metricsBusTopicId) : "",
      operationSubscriptionId: isSet(object.operationSubscriptionId)
        ? globalThis.String(object.operationSubscriptionId)
        : "",
      queryLogResultTopic: isSet(object.queryLogResultTopic) ? globalThis.String(object.queryLogResultTopic) : "",
      queryLogSubscriptionId: isSet(object.queryLogSubscriptionId)
        ? globalThis.String(object.queryLogSubscriptionId)
        : "",
      resultBusMetricsSubscriptionId: isSet(object.resultBusMetricsSubscriptionId)
        ? globalThis.String(object.resultBusMetricsSubscriptionId)
        : "",
      resultBusOfflineStoreSubscriptionId: isSet(object.resultBusOfflineStoreSubscriptionId)
        ? globalThis.String(object.resultBusOfflineStoreSubscriptionId)
        : "",
      resultBusOnlineStoreSubscriptionId: isSet(object.resultBusOnlineStoreSubscriptionId)
        ? globalThis.String(object.resultBusOnlineStoreSubscriptionId)
        : "",
      resultBusTopicId: isSet(object.resultBusTopicId) ? globalThis.String(object.resultBusTopicId) : "",
      usageBusTopicId: isSet(object.usageBusTopicId) ? globalThis.String(object.usageBusTopicId) : "",
      usageEventsSubscriptionId: isSet(object.usageEventsSubscriptionId)
        ? globalThis.String(object.usageEventsSubscriptionId)
        : "",
      bqUploadBucket: isSet(object.bqUploadBucket) ? globalThis.String(object.bqUploadBucket) : "",
      bqUploadTopic: isSet(object.bqUploadTopic) ? globalThis.String(object.bqUploadTopic) : "",
      includeChalkNodeSelector: isSet(object.includeChalkNodeSelector)
        ? globalThis.Boolean(object.includeChalkNodeSelector)
        : false,
      busWriterImageRust: isSet(object.busWriterImageRust) ? globalThis.String(object.busWriterImageRust) : "",
    };
  },

  toJSON(message: BackgroundPersistenceCommonSpecs): unknown {
    const obj: any = {};
    if (message.namespace !== "") {
      obj.namespace = message.namespace;
    }
    if (message.busWriterImageGo !== "") {
      obj.busWriterImageGo = message.busWriterImageGo;
    }
    if (message.busWriterImagePython !== "") {
      obj.busWriterImagePython = message.busWriterImagePython;
    }
    if (message.busWriterImageBswl !== "") {
      obj.busWriterImageBswl = message.busWriterImageBswl;
    }
    if (message.serviceAccountName !== "") {
      obj.serviceAccountName = message.serviceAccountName;
    }
    if (message.busBackend !== "") {
      obj.busBackend = message.busBackend;
    }
    if (message.secretClient !== "") {
      obj.secretClient = message.secretClient;
    }
    if (message.bigqueryParquetUploadSubscriptionId !== "") {
      obj.bigqueryParquetUploadSubscriptionId = message.bigqueryParquetUploadSubscriptionId;
    }
    if (message.bigqueryStreamingWriteSubscriptionId !== "") {
      obj.bigqueryStreamingWriteSubscriptionId = message.bigqueryStreamingWriteSubscriptionId;
    }
    if (message.bigqueryStreamingWriteTopic !== "") {
      obj.bigqueryStreamingWriteTopic = message.bigqueryStreamingWriteTopic;
    }
    if (message.bigqueryUploadBucket !== "") {
      obj.bigqueryUploadBucket = message.bigqueryUploadBucket;
    }
    if (message.bigqueryUploadTopic !== "") {
      obj.bigqueryUploadTopic = message.bigqueryUploadTopic;
    }
    if (message.googleCloudProject !== "") {
      obj.googleCloudProject = message.googleCloudProject;
    }
    if (message.kafkaDlqTopic !== "") {
      obj.kafkaDlqTopic = message.kafkaDlqTopic;
    }
    if (message.metricsBusSubscriptionId !== "") {
      obj.metricsBusSubscriptionId = message.metricsBusSubscriptionId;
    }
    if (message.metricsBusTopicId !== "") {
      obj.metricsBusTopicId = message.metricsBusTopicId;
    }
    if (message.operationSubscriptionId !== "") {
      obj.operationSubscriptionId = message.operationSubscriptionId;
    }
    if (message.queryLogResultTopic !== "") {
      obj.queryLogResultTopic = message.queryLogResultTopic;
    }
    if (message.queryLogSubscriptionId !== "") {
      obj.queryLogSubscriptionId = message.queryLogSubscriptionId;
    }
    if (message.resultBusMetricsSubscriptionId !== "") {
      obj.resultBusMetricsSubscriptionId = message.resultBusMetricsSubscriptionId;
    }
    if (message.resultBusOfflineStoreSubscriptionId !== "") {
      obj.resultBusOfflineStoreSubscriptionId = message.resultBusOfflineStoreSubscriptionId;
    }
    if (message.resultBusOnlineStoreSubscriptionId !== "") {
      obj.resultBusOnlineStoreSubscriptionId = message.resultBusOnlineStoreSubscriptionId;
    }
    if (message.resultBusTopicId !== "") {
      obj.resultBusTopicId = message.resultBusTopicId;
    }
    if (message.usageBusTopicId !== "") {
      obj.usageBusTopicId = message.usageBusTopicId;
    }
    if (message.usageEventsSubscriptionId !== "") {
      obj.usageEventsSubscriptionId = message.usageEventsSubscriptionId;
    }
    if (message.bqUploadBucket !== "") {
      obj.bqUploadBucket = message.bqUploadBucket;
    }
    if (message.bqUploadTopic !== "") {
      obj.bqUploadTopic = message.bqUploadTopic;
    }
    if (message.includeChalkNodeSelector !== false) {
      obj.includeChalkNodeSelector = message.includeChalkNodeSelector;
    }
    if (message.busWriterImageRust !== "") {
      obj.busWriterImageRust = message.busWriterImageRust;
    }
    return obj;
  },
};

function createBaseBackgroundPersistenceWriterHpaSpecs(): BackgroundPersistenceWriterHpaSpecs {
  return {
    hpaPubsubSubscriptionId: "",
    hpaMinReplicas: undefined,
    hpaMaxReplicas: undefined,
    hpaTargetAverageValue: undefined,
  };
}

export const BackgroundPersistenceWriterHpaSpecs: MessageFns<BackgroundPersistenceWriterHpaSpecs> = {
  encode(message: BackgroundPersistenceWriterHpaSpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hpaPubsubSubscriptionId !== "") {
      writer.uint32(10).string(message.hpaPubsubSubscriptionId);
    }
    if (message.hpaMinReplicas !== undefined) {
      writer.uint32(16).int32(message.hpaMinReplicas);
    }
    if (message.hpaMaxReplicas !== undefined) {
      writer.uint32(24).int32(message.hpaMaxReplicas);
    }
    if (message.hpaTargetAverageValue !== undefined) {
      writer.uint32(32).int32(message.hpaTargetAverageValue);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackgroundPersistenceWriterHpaSpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackgroundPersistenceWriterHpaSpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.hpaPubsubSubscriptionId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.hpaMinReplicas = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.hpaMaxReplicas = reader.int32();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.hpaTargetAverageValue = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackgroundPersistenceWriterHpaSpecs {
    return {
      hpaPubsubSubscriptionId: isSet(object.hpaPubsubSubscriptionId)
        ? globalThis.String(object.hpaPubsubSubscriptionId)
        : "",
      hpaMinReplicas: isSet(object.hpaMinReplicas) ? globalThis.Number(object.hpaMinReplicas) : undefined,
      hpaMaxReplicas: isSet(object.hpaMaxReplicas) ? globalThis.Number(object.hpaMaxReplicas) : undefined,
      hpaTargetAverageValue: isSet(object.hpaTargetAverageValue)
        ? globalThis.Number(object.hpaTargetAverageValue)
        : undefined,
    };
  },

  toJSON(message: BackgroundPersistenceWriterHpaSpecs): unknown {
    const obj: any = {};
    if (message.hpaPubsubSubscriptionId !== "") {
      obj.hpaPubsubSubscriptionId = message.hpaPubsubSubscriptionId;
    }
    if (message.hpaMinReplicas !== undefined) {
      obj.hpaMinReplicas = Math.round(message.hpaMinReplicas);
    }
    if (message.hpaMaxReplicas !== undefined) {
      obj.hpaMaxReplicas = Math.round(message.hpaMaxReplicas);
    }
    if (message.hpaTargetAverageValue !== undefined) {
      obj.hpaTargetAverageValue = Math.round(message.hpaTargetAverageValue);
    }
    return obj;
  },
};

function createBaseBackgroundPersistenceWriterSpecs(): BackgroundPersistenceWriterSpecs {
  return {
    name: "",
    imageOverride: "",
    hpaSpecs: undefined,
    gkeSpot: undefined,
    loadWriterConfigmap: undefined,
    version: "",
    request: undefined,
    limit: undefined,
    busSubscriberType: "",
    defaultReplicaCount: 0,
    kafkaConsumerGroupOverride: "",
    maxBatchSize: undefined,
    messageProcessingConcurrency: undefined,
    metadataSqlSslCaCertSecret: "",
    metadataSqlSslClientCertSecret: "",
    metadataSqlSslClientKeySecret: "",
    metadataSqlUriSecret: "",
    offlineStoreInserterDbType: "",
    storageCachePrefix: "",
    usageStoreUri: "",
    resultsWriterSkipProducingFeatureMetrics: undefined,
    queryTableWriteDropRatio: "",
  };
}

export const BackgroundPersistenceWriterSpecs: MessageFns<BackgroundPersistenceWriterSpecs> = {
  encode(message: BackgroundPersistenceWriterSpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.imageOverride !== "") {
      writer.uint32(18).string(message.imageOverride);
    }
    if (message.hpaSpecs !== undefined) {
      BackgroundPersistenceWriterHpaSpecs.encode(message.hpaSpecs, writer.uint32(26).fork()).join();
    }
    if (message.gkeSpot !== undefined) {
      writer.uint32(32).bool(message.gkeSpot);
    }
    if (message.loadWriterConfigmap !== undefined) {
      writer.uint32(40).bool(message.loadWriterConfigmap);
    }
    if (message.version !== "") {
      writer.uint32(50).string(message.version);
    }
    if (message.request !== undefined) {
      KubeResourceConfig.encode(message.request, writer.uint32(58).fork()).join();
    }
    if (message.limit !== undefined) {
      KubeResourceConfig.encode(message.limit, writer.uint32(66).fork()).join();
    }
    if (message.busSubscriberType !== "") {
      writer.uint32(74).string(message.busSubscriberType);
    }
    if (message.defaultReplicaCount !== 0) {
      writer.uint32(80).int32(message.defaultReplicaCount);
    }
    if (message.kafkaConsumerGroupOverride !== "") {
      writer.uint32(90).string(message.kafkaConsumerGroupOverride);
    }
    if (message.maxBatchSize !== undefined) {
      writer.uint32(96).int32(message.maxBatchSize);
    }
    if (message.messageProcessingConcurrency !== undefined) {
      writer.uint32(104).int32(message.messageProcessingConcurrency);
    }
    if (message.metadataSqlSslCaCertSecret !== "") {
      writer.uint32(114).string(message.metadataSqlSslCaCertSecret);
    }
    if (message.metadataSqlSslClientCertSecret !== "") {
      writer.uint32(122).string(message.metadataSqlSslClientCertSecret);
    }
    if (message.metadataSqlSslClientKeySecret !== "") {
      writer.uint32(130).string(message.metadataSqlSslClientKeySecret);
    }
    if (message.metadataSqlUriSecret !== "") {
      writer.uint32(138).string(message.metadataSqlUriSecret);
    }
    if (message.offlineStoreInserterDbType !== "") {
      writer.uint32(146).string(message.offlineStoreInserterDbType);
    }
    if (message.storageCachePrefix !== "") {
      writer.uint32(154).string(message.storageCachePrefix);
    }
    if (message.usageStoreUri !== "") {
      writer.uint32(162).string(message.usageStoreUri);
    }
    if (message.resultsWriterSkipProducingFeatureMetrics !== undefined) {
      writer.uint32(168).bool(message.resultsWriterSkipProducingFeatureMetrics);
    }
    if (message.queryTableWriteDropRatio !== "") {
      writer.uint32(178).string(message.queryTableWriteDropRatio);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackgroundPersistenceWriterSpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackgroundPersistenceWriterSpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.imageOverride = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.hpaSpecs = BackgroundPersistenceWriterHpaSpecs.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.gkeSpot = reader.bool();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.loadWriterConfigmap = reader.bool();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.request = KubeResourceConfig.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.limit = KubeResourceConfig.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.busSubscriberType = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.defaultReplicaCount = reader.int32();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.kafkaConsumerGroupOverride = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.maxBatchSize = reader.int32();
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.messageProcessingConcurrency = reader.int32();
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.metadataSqlSslCaCertSecret = reader.string();
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.metadataSqlSslClientCertSecret = reader.string();
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.metadataSqlSslClientKeySecret = reader.string();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.metadataSqlUriSecret = reader.string();
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.offlineStoreInserterDbType = reader.string();
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.storageCachePrefix = reader.string();
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.usageStoreUri = reader.string();
          continue;
        }
        case 21: {
          if (tag !== 168) {
            break;
          }

          message.resultsWriterSkipProducingFeatureMetrics = reader.bool();
          continue;
        }
        case 22: {
          if (tag !== 178) {
            break;
          }

          message.queryTableWriteDropRatio = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackgroundPersistenceWriterSpecs {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      imageOverride: isSet(object.imageOverride) ? globalThis.String(object.imageOverride) : "",
      hpaSpecs: isSet(object.hpaSpecs) ? BackgroundPersistenceWriterHpaSpecs.fromJSON(object.hpaSpecs) : undefined,
      gkeSpot: isSet(object.gkeSpot) ? globalThis.Boolean(object.gkeSpot) : undefined,
      loadWriterConfigmap: isSet(object.loadWriterConfigmap)
        ? globalThis.Boolean(object.loadWriterConfigmap)
        : undefined,
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      request: isSet(object.request) ? KubeResourceConfig.fromJSON(object.request) : undefined,
      limit: isSet(object.limit) ? KubeResourceConfig.fromJSON(object.limit) : undefined,
      busSubscriberType: isSet(object.busSubscriberType) ? globalThis.String(object.busSubscriberType) : "",
      defaultReplicaCount: isSet(object.defaultReplicaCount) ? globalThis.Number(object.defaultReplicaCount) : 0,
      kafkaConsumerGroupOverride: isSet(object.kafkaConsumerGroupOverride)
        ? globalThis.String(object.kafkaConsumerGroupOverride)
        : "",
      maxBatchSize: isSet(object.maxBatchSize) ? globalThis.Number(object.maxBatchSize) : undefined,
      messageProcessingConcurrency: isSet(object.messageProcessingConcurrency)
        ? globalThis.Number(object.messageProcessingConcurrency)
        : undefined,
      metadataSqlSslCaCertSecret: isSet(object.metadataSqlSslCaCertSecret)
        ? globalThis.String(object.metadataSqlSslCaCertSecret)
        : "",
      metadataSqlSslClientCertSecret: isSet(object.metadataSqlSslClientCertSecret)
        ? globalThis.String(object.metadataSqlSslClientCertSecret)
        : "",
      metadataSqlSslClientKeySecret: isSet(object.metadataSqlSslClientKeySecret)
        ? globalThis.String(object.metadataSqlSslClientKeySecret)
        : "",
      metadataSqlUriSecret: isSet(object.metadataSqlUriSecret) ? globalThis.String(object.metadataSqlUriSecret) : "",
      offlineStoreInserterDbType: isSet(object.offlineStoreInserterDbType)
        ? globalThis.String(object.offlineStoreInserterDbType)
        : "",
      storageCachePrefix: isSet(object.storageCachePrefix) ? globalThis.String(object.storageCachePrefix) : "",
      usageStoreUri: isSet(object.usageStoreUri) ? globalThis.String(object.usageStoreUri) : "",
      resultsWriterSkipProducingFeatureMetrics: isSet(object.resultsWriterSkipProducingFeatureMetrics)
        ? globalThis.Boolean(object.resultsWriterSkipProducingFeatureMetrics)
        : undefined,
      queryTableWriteDropRatio: isSet(object.queryTableWriteDropRatio)
        ? globalThis.String(object.queryTableWriteDropRatio)
        : "",
    };
  },

  toJSON(message: BackgroundPersistenceWriterSpecs): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.imageOverride !== "") {
      obj.imageOverride = message.imageOverride;
    }
    if (message.hpaSpecs !== undefined) {
      obj.hpaSpecs = BackgroundPersistenceWriterHpaSpecs.toJSON(message.hpaSpecs);
    }
    if (message.gkeSpot !== undefined) {
      obj.gkeSpot = message.gkeSpot;
    }
    if (message.loadWriterConfigmap !== undefined) {
      obj.loadWriterConfigmap = message.loadWriterConfigmap;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.request !== undefined) {
      obj.request = KubeResourceConfig.toJSON(message.request);
    }
    if (message.limit !== undefined) {
      obj.limit = KubeResourceConfig.toJSON(message.limit);
    }
    if (message.busSubscriberType !== "") {
      obj.busSubscriberType = message.busSubscriberType;
    }
    if (message.defaultReplicaCount !== 0) {
      obj.defaultReplicaCount = Math.round(message.defaultReplicaCount);
    }
    if (message.kafkaConsumerGroupOverride !== "") {
      obj.kafkaConsumerGroupOverride = message.kafkaConsumerGroupOverride;
    }
    if (message.maxBatchSize !== undefined) {
      obj.maxBatchSize = Math.round(message.maxBatchSize);
    }
    if (message.messageProcessingConcurrency !== undefined) {
      obj.messageProcessingConcurrency = Math.round(message.messageProcessingConcurrency);
    }
    if (message.metadataSqlSslCaCertSecret !== "") {
      obj.metadataSqlSslCaCertSecret = message.metadataSqlSslCaCertSecret;
    }
    if (message.metadataSqlSslClientCertSecret !== "") {
      obj.metadataSqlSslClientCertSecret = message.metadataSqlSslClientCertSecret;
    }
    if (message.metadataSqlSslClientKeySecret !== "") {
      obj.metadataSqlSslClientKeySecret = message.metadataSqlSslClientKeySecret;
    }
    if (message.metadataSqlUriSecret !== "") {
      obj.metadataSqlUriSecret = message.metadataSqlUriSecret;
    }
    if (message.offlineStoreInserterDbType !== "") {
      obj.offlineStoreInserterDbType = message.offlineStoreInserterDbType;
    }
    if (message.storageCachePrefix !== "") {
      obj.storageCachePrefix = message.storageCachePrefix;
    }
    if (message.usageStoreUri !== "") {
      obj.usageStoreUri = message.usageStoreUri;
    }
    if (message.resultsWriterSkipProducingFeatureMetrics !== undefined) {
      obj.resultsWriterSkipProducingFeatureMetrics = message.resultsWriterSkipProducingFeatureMetrics;
    }
    if (message.queryTableWriteDropRatio !== "") {
      obj.queryTableWriteDropRatio = message.queryTableWriteDropRatio;
    }
    return obj;
  },
};

function createBaseBackgroundPersistenceDeploymentSpecs(): BackgroundPersistenceDeploymentSpecs {
  return {
    commonPersistenceSpecs: undefined,
    apiServerHost: "",
    kafkaSaslSecret: "",
    metadataProvider: "",
    kafkaBootstrapServers: "",
    kafkaSecurityProtocol: "",
    kafkaSaslMechanism: "",
    redisIsClustered: "",
    snowflakeStorageIntegrationName: "",
    redisLightningSupportsHasMany: false,
    insecure: false,
    writers: [],
  };
}

export const BackgroundPersistenceDeploymentSpecs: MessageFns<BackgroundPersistenceDeploymentSpecs> = {
  encode(message: BackgroundPersistenceDeploymentSpecs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.commonPersistenceSpecs !== undefined) {
      BackgroundPersistenceCommonSpecs.encode(message.commonPersistenceSpecs, writer.uint32(10).fork()).join();
    }
    if (message.apiServerHost !== "") {
      writer.uint32(18).string(message.apiServerHost);
    }
    if (message.kafkaSaslSecret !== "") {
      writer.uint32(26).string(message.kafkaSaslSecret);
    }
    if (message.metadataProvider !== "") {
      writer.uint32(34).string(message.metadataProvider);
    }
    if (message.kafkaBootstrapServers !== "") {
      writer.uint32(42).string(message.kafkaBootstrapServers);
    }
    if (message.kafkaSecurityProtocol !== "") {
      writer.uint32(50).string(message.kafkaSecurityProtocol);
    }
    if (message.kafkaSaslMechanism !== "") {
      writer.uint32(58).string(message.kafkaSaslMechanism);
    }
    if (message.redisIsClustered !== "") {
      writer.uint32(66).string(message.redisIsClustered);
    }
    if (message.snowflakeStorageIntegrationName !== "") {
      writer.uint32(74).string(message.snowflakeStorageIntegrationName);
    }
    if (message.redisLightningSupportsHasMany !== false) {
      writer.uint32(80).bool(message.redisLightningSupportsHasMany);
    }
    if (message.insecure !== false) {
      writer.uint32(88).bool(message.insecure);
    }
    for (const v of message.writers) {
      BackgroundPersistenceWriterSpecs.encode(v!, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackgroundPersistenceDeploymentSpecs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackgroundPersistenceDeploymentSpecs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.commonPersistenceSpecs = BackgroundPersistenceCommonSpecs.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.apiServerHost = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.kafkaSaslSecret = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.metadataProvider = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.kafkaBootstrapServers = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.kafkaSecurityProtocol = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.kafkaSaslMechanism = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.redisIsClustered = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.snowflakeStorageIntegrationName = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.redisLightningSupportsHasMany = reader.bool();
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.insecure = reader.bool();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.writers.push(BackgroundPersistenceWriterSpecs.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackgroundPersistenceDeploymentSpecs {
    return {
      commonPersistenceSpecs: isSet(object.commonPersistenceSpecs)
        ? BackgroundPersistenceCommonSpecs.fromJSON(object.commonPersistenceSpecs)
        : undefined,
      apiServerHost: isSet(object.apiServerHost) ? globalThis.String(object.apiServerHost) : "",
      kafkaSaslSecret: isSet(object.kafkaSaslSecret) ? globalThis.String(object.kafkaSaslSecret) : "",
      metadataProvider: isSet(object.metadataProvider) ? globalThis.String(object.metadataProvider) : "",
      kafkaBootstrapServers: isSet(object.kafkaBootstrapServers) ? globalThis.String(object.kafkaBootstrapServers) : "",
      kafkaSecurityProtocol: isSet(object.kafkaSecurityProtocol) ? globalThis.String(object.kafkaSecurityProtocol) : "",
      kafkaSaslMechanism: isSet(object.kafkaSaslMechanism) ? globalThis.String(object.kafkaSaslMechanism) : "",
      redisIsClustered: isSet(object.redisIsClustered) ? globalThis.String(object.redisIsClustered) : "",
      snowflakeStorageIntegrationName: isSet(object.snowflakeStorageIntegrationName)
        ? globalThis.String(object.snowflakeStorageIntegrationName)
        : "",
      redisLightningSupportsHasMany: isSet(object.redisLightningSupportsHasMany)
        ? globalThis.Boolean(object.redisLightningSupportsHasMany)
        : false,
      insecure: isSet(object.insecure) ? globalThis.Boolean(object.insecure) : false,
      writers: globalThis.Array.isArray(object?.writers)
        ? object.writers.map((e: any) => BackgroundPersistenceWriterSpecs.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BackgroundPersistenceDeploymentSpecs): unknown {
    const obj: any = {};
    if (message.commonPersistenceSpecs !== undefined) {
      obj.commonPersistenceSpecs = BackgroundPersistenceCommonSpecs.toJSON(message.commonPersistenceSpecs);
    }
    if (message.apiServerHost !== "") {
      obj.apiServerHost = message.apiServerHost;
    }
    if (message.kafkaSaslSecret !== "") {
      obj.kafkaSaslSecret = message.kafkaSaslSecret;
    }
    if (message.metadataProvider !== "") {
      obj.metadataProvider = message.metadataProvider;
    }
    if (message.kafkaBootstrapServers !== "") {
      obj.kafkaBootstrapServers = message.kafkaBootstrapServers;
    }
    if (message.kafkaSecurityProtocol !== "") {
      obj.kafkaSecurityProtocol = message.kafkaSecurityProtocol;
    }
    if (message.kafkaSaslMechanism !== "") {
      obj.kafkaSaslMechanism = message.kafkaSaslMechanism;
    }
    if (message.redisIsClustered !== "") {
      obj.redisIsClustered = message.redisIsClustered;
    }
    if (message.snowflakeStorageIntegrationName !== "") {
      obj.snowflakeStorageIntegrationName = message.snowflakeStorageIntegrationName;
    }
    if (message.redisLightningSupportsHasMany !== false) {
      obj.redisLightningSupportsHasMany = message.redisLightningSupportsHasMany;
    }
    if (message.insecure !== false) {
      obj.insecure = message.insecure;
    }
    if (message.writers?.length) {
      obj.writers = message.writers.map((e) => BackgroundPersistenceWriterSpecs.toJSON(e));
    }
    return obj;
  },
};

function createBaseCreateClusterBackgroundPersistenceResponse(): CreateClusterBackgroundPersistenceResponse {
  return {};
}

export const CreateClusterBackgroundPersistenceResponse: MessageFns<CreateClusterBackgroundPersistenceResponse> = {
  encode(_: CreateClusterBackgroundPersistenceResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateClusterBackgroundPersistenceResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateClusterBackgroundPersistenceResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CreateClusterBackgroundPersistenceResponse {
    return {};
  },

  toJSON(_: CreateClusterBackgroundPersistenceResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetSearchConfigRequest(): GetSearchConfigRequest {
  return {};
}

export const GetSearchConfigRequest: MessageFns<GetSearchConfigRequest> = {
  encode(_: GetSearchConfigRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetSearchConfigRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetSearchConfigRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): GetSearchConfigRequest {
    return {};
  },

  toJSON(_: GetSearchConfigRequest): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetSearchConfigResponse(): GetSearchConfigResponse {
  return { teamId: "", teamApiKey: "" };
}

export const GetSearchConfigResponse: MessageFns<GetSearchConfigResponse> = {
  encode(message: GetSearchConfigResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.teamId !== "") {
      writer.uint32(10).string(message.teamId);
    }
    if (message.teamApiKey !== "") {
      writer.uint32(18).string(message.teamApiKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetSearchConfigResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetSearchConfigResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.teamId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.teamApiKey = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetSearchConfigResponse {
    return {
      teamId: isSet(object.teamId) ? globalThis.String(object.teamId) : "",
      teamApiKey: isSet(object.teamApiKey) ? globalThis.String(object.teamApiKey) : "",
    };
  },

  toJSON(message: GetSearchConfigResponse): unknown {
    const obj: any = {};
    if (message.teamId !== "") {
      obj.teamId = message.teamId;
    }
    if (message.teamApiKey !== "") {
      obj.teamApiKey = message.teamApiKey;
    }
    return obj;
  },
};

function createBaseUpdateEnvironmentVariablesRequest(): UpdateEnvironmentVariablesRequest {
  return { environmentVariables: {} };
}

export const UpdateEnvironmentVariablesRequest: MessageFns<UpdateEnvironmentVariablesRequest> = {
  encode(message: UpdateEnvironmentVariablesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.environmentVariables).forEach(([key, value]) => {
      UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry.encode(
        { key: key as any, value },
        writer.uint32(10).fork(),
      ).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateEnvironmentVariablesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateEnvironmentVariablesRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          const entry1 = UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.environmentVariables[entry1.key] = entry1.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateEnvironmentVariablesRequest {
    return {
      environmentVariables: isObject(object.environmentVariables)
        ? Object.entries(object.environmentVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: UpdateEnvironmentVariablesRequest): unknown {
    const obj: any = {};
    if (message.environmentVariables) {
      const entries = Object.entries(message.environmentVariables);
      if (entries.length > 0) {
        obj.environmentVariables = {};
        entries.forEach(([k, v]) => {
          obj.environmentVariables[k] = v;
        });
      }
    }
    return obj;
  },
};

function createBaseUpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry(): UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry {
  return { key: "", value: "" };
}

export const UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry: MessageFns<
  UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry
> = {
  encode(
    message: UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: UpdateEnvironmentVariablesRequest_EnvironmentVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },
};

function createBaseUpdateEnvironmentVariablesResponse(): UpdateEnvironmentVariablesResponse {
  return {};
}

export const UpdateEnvironmentVariablesResponse: MessageFns<UpdateEnvironmentVariablesResponse> = {
  encode(_: UpdateEnvironmentVariablesResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateEnvironmentVariablesResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateEnvironmentVariablesResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): UpdateEnvironmentVariablesResponse {
    return {};
  },

  toJSON(_: UpdateEnvironmentVariablesResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseStartBranchRequest(): StartBranchRequest {
  return {};
}

export const StartBranchRequest: MessageFns<StartBranchRequest> = {
  encode(_: StartBranchRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StartBranchRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStartBranchRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): StartBranchRequest {
    return {};
  },

  toJSON(_: StartBranchRequest): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseStartBranchResponse(): StartBranchResponse {
  return { state: 0 };
}

export const StartBranchResponse: MessageFns<StartBranchResponse> = {
  encode(message: StartBranchResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StartBranchResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStartBranchResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StartBranchResponse {
    return { state: isSet(object.state) ? branchScalingStateFromJSON(object.state) : 0 };
  },

  toJSON(message: StartBranchResponse): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = branchScalingStateToJSON(message.state);
    }
    return obj;
  },
};

function createBaseScaleBranchRequest(): ScaleBranchRequest {
  return { replicas: 0 };
}

export const ScaleBranchRequest: MessageFns<ScaleBranchRequest> = {
  encode(message: ScaleBranchRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.replicas !== 0) {
      writer.uint32(8).int32(message.replicas);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScaleBranchRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScaleBranchRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.replicas = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScaleBranchRequest {
    return { replicas: isSet(object.replicas) ? globalThis.Number(object.replicas) : 0 };
  },

  toJSON(message: ScaleBranchRequest): unknown {
    const obj: any = {};
    if (message.replicas !== 0) {
      obj.replicas = Math.round(message.replicas);
    }
    return obj;
  },
};

function createBaseScaleBranchResponse(): ScaleBranchResponse {
  return { state: 0 };
}

export const ScaleBranchResponse: MessageFns<ScaleBranchResponse> = {
  encode(message: ScaleBranchResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScaleBranchResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScaleBranchResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScaleBranchResponse {
    return { state: isSet(object.state) ? branchScalingStateFromJSON(object.state) : 0 };
  },

  toJSON(message: ScaleBranchResponse): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = branchScalingStateToJSON(message.state);
    }
    return obj;
  },
};

function createBaseKafkaTopic(): KafkaTopic {
  return { name: "", partitions: 0, replication: undefined, retentionMs: 0 };
}

export const KafkaTopic: MessageFns<KafkaTopic> = {
  encode(message: KafkaTopic, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.partitions !== 0) {
      writer.uint32(16).int32(message.partitions);
    }
    if (message.replication !== undefined) {
      writer.uint32(24).int32(message.replication);
    }
    if (message.retentionMs !== 0) {
      writer.uint32(32).int32(message.retentionMs);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KafkaTopic {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKafkaTopic();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.partitions = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.replication = reader.int32();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.retentionMs = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KafkaTopic {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      partitions: isSet(object.partitions) ? globalThis.Number(object.partitions) : 0,
      replication: isSet(object.replication) ? globalThis.Number(object.replication) : undefined,
      retentionMs: isSet(object.retentionMs) ? globalThis.Number(object.retentionMs) : 0,
    };
  },

  toJSON(message: KafkaTopic): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.partitions !== 0) {
      obj.partitions = Math.round(message.partitions);
    }
    if (message.replication !== undefined) {
      obj.replication = Math.round(message.replication);
    }
    if (message.retentionMs !== 0) {
      obj.retentionMs = Math.round(message.retentionMs);
    }
    return obj;
  },
};

function createBaseCreateKafkaTopicsRequest(): CreateKafkaTopicsRequest {
  return { topics: [] };
}

export const CreateKafkaTopicsRequest: MessageFns<CreateKafkaTopicsRequest> = {
  encode(message: CreateKafkaTopicsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.topics) {
      KafkaTopic.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateKafkaTopicsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateKafkaTopicsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.topics.push(KafkaTopic.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateKafkaTopicsRequest {
    return {
      topics: globalThis.Array.isArray(object?.topics) ? object.topics.map((e: any) => KafkaTopic.fromJSON(e)) : [],
    };
  },

  toJSON(message: CreateKafkaTopicsRequest): unknown {
    const obj: any = {};
    if (message.topics?.length) {
      obj.topics = message.topics.map((e) => KafkaTopic.toJSON(e));
    }
    return obj;
  },
};

function createBaseCreateKafkaTopicsResponse(): CreateKafkaTopicsResponse {
  return {};
}

export const CreateKafkaTopicsResponse: MessageFns<CreateKafkaTopicsResponse> = {
  encode(_: CreateKafkaTopicsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateKafkaTopicsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateKafkaTopicsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CreateKafkaTopicsResponse {
    return {};
  },

  toJSON(_: CreateKafkaTopicsResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetKafkaTopicsRequest(): GetKafkaTopicsRequest {
  return {};
}

export const GetKafkaTopicsRequest: MessageFns<GetKafkaTopicsRequest> = {
  encode(_: GetKafkaTopicsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetKafkaTopicsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetKafkaTopicsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): GetKafkaTopicsRequest {
    return {};
  },

  toJSON(_: GetKafkaTopicsRequest): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetKafkaTopicsResponse(): GetKafkaTopicsResponse {
  return { topics: [] };
}

export const GetKafkaTopicsResponse: MessageFns<GetKafkaTopicsResponse> = {
  encode(message: GetKafkaTopicsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.topics) {
      KafkaTopic.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetKafkaTopicsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetKafkaTopicsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.topics.push(KafkaTopic.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetKafkaTopicsResponse {
    return {
      topics: globalThis.Array.isArray(object?.topics) ? object.topics.map((e: any) => KafkaTopic.fromJSON(e)) : [],
    };
  },

  toJSON(message: GetKafkaTopicsResponse): unknown {
    const obj: any = {};
    if (message.topics?.length) {
      obj.topics = message.topics.map((e) => KafkaTopic.toJSON(e));
    }
    return obj;
  },
};

function createBaseGetNodepoolsRequest(): GetNodepoolsRequest {
  return {};
}

export const GetNodepoolsRequest: MessageFns<GetNodepoolsRequest> = {
  encode(_: GetNodepoolsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetNodepoolsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetNodepoolsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): GetNodepoolsRequest {
    return {};
  },

  toJSON(_: GetNodepoolsRequest): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetNodepoolsResponse(): GetNodepoolsResponse {
  return { karpenterNodepools: [], gkeNodepools: [] };
}

export const GetNodepoolsResponse: MessageFns<GetNodepoolsResponse> = {
  encode(message: GetNodepoolsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.karpenterNodepools) {
      KarpenterNodepool.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.gkeNodepools) {
      GKENodePool.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetNodepoolsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetNodepoolsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.karpenterNodepools.push(KarpenterNodepool.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gkeNodepools.push(GKENodePool.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetNodepoolsResponse {
    return {
      karpenterNodepools: globalThis.Array.isArray(object?.karpenterNodepools)
        ? object.karpenterNodepools.map((e: any) => KarpenterNodepool.fromJSON(e))
        : [],
      gkeNodepools: globalThis.Array.isArray(object?.gkeNodepools)
        ? object.gkeNodepools.map((e: any) => GKENodePool.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GetNodepoolsResponse): unknown {
    const obj: any = {};
    if (message.karpenterNodepools?.length) {
      obj.karpenterNodepools = message.karpenterNodepools.map((e) => KarpenterNodepool.toJSON(e));
    }
    if (message.gkeNodepools?.length) {
      obj.gkeNodepools = message.gkeNodepools.map((e) => GKENodePool.toJSON(e));
    }
    return obj;
  },
};

function createBaseAddNodepoolRequest(): AddNodepoolRequest {
  return { karpenterNodepool: undefined, gkeNodepool: undefined };
}

export const AddNodepoolRequest: MessageFns<AddNodepoolRequest> = {
  encode(message: AddNodepoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.karpenterNodepool !== undefined) {
      KarpenterNodepool.encode(message.karpenterNodepool, writer.uint32(10).fork()).join();
    }
    if (message.gkeNodepool !== undefined) {
      GKENodePool.encode(message.gkeNodepool, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AddNodepoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAddNodepoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.karpenterNodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gkeNodepool = GKENodePool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AddNodepoolRequest {
    return {
      karpenterNodepool: isSet(object.karpenterNodepool)
        ? KarpenterNodepool.fromJSON(object.karpenterNodepool)
        : undefined,
      gkeNodepool: isSet(object.gkeNodepool) ? GKENodePool.fromJSON(object.gkeNodepool) : undefined,
    };
  },

  toJSON(message: AddNodepoolRequest): unknown {
    const obj: any = {};
    if (message.karpenterNodepool !== undefined) {
      obj.karpenterNodepool = KarpenterNodepool.toJSON(message.karpenterNodepool);
    }
    if (message.gkeNodepool !== undefined) {
      obj.gkeNodepool = GKENodePool.toJSON(message.gkeNodepool);
    }
    return obj;
  },
};

function createBaseAddNodepoolResponse(): AddNodepoolResponse {
  return { karpenterNodepool: undefined, gkeNodepool: undefined };
}

export const AddNodepoolResponse: MessageFns<AddNodepoolResponse> = {
  encode(message: AddNodepoolResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.karpenterNodepool !== undefined) {
      KarpenterNodepool.encode(message.karpenterNodepool, writer.uint32(10).fork()).join();
    }
    if (message.gkeNodepool !== undefined) {
      GKENodePool.encode(message.gkeNodepool, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AddNodepoolResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAddNodepoolResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.karpenterNodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gkeNodepool = GKENodePool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AddNodepoolResponse {
    return {
      karpenterNodepool: isSet(object.karpenterNodepool)
        ? KarpenterNodepool.fromJSON(object.karpenterNodepool)
        : undefined,
      gkeNodepool: isSet(object.gkeNodepool) ? GKENodePool.fromJSON(object.gkeNodepool) : undefined,
    };
  },

  toJSON(message: AddNodepoolResponse): unknown {
    const obj: any = {};
    if (message.karpenterNodepool !== undefined) {
      obj.karpenterNodepool = KarpenterNodepool.toJSON(message.karpenterNodepool);
    }
    if (message.gkeNodepool !== undefined) {
      obj.gkeNodepool = GKENodePool.toJSON(message.gkeNodepool);
    }
    return obj;
  },
};

function createBaseUpdateNodepoolRequest(): UpdateNodepoolRequest {
  return { name: "", gkeNodepool: undefined, karpenterNodepool: undefined };
}

export const UpdateNodepoolRequest: MessageFns<UpdateNodepoolRequest> = {
  encode(message: UpdateNodepoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.gkeNodepool !== undefined) {
      GKENodePool.encode(message.gkeNodepool, writer.uint32(18).fork()).join();
    }
    if (message.karpenterNodepool !== undefined) {
      KarpenterNodepool.encode(message.karpenterNodepool, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateNodepoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateNodepoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gkeNodepool = GKENodePool.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.karpenterNodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateNodepoolRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      gkeNodepool: isSet(object.gkeNodepool) ? GKENodePool.fromJSON(object.gkeNodepool) : undefined,
      karpenterNodepool: isSet(object.karpenterNodepool)
        ? KarpenterNodepool.fromJSON(object.karpenterNodepool)
        : undefined,
    };
  },

  toJSON(message: UpdateNodepoolRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.gkeNodepool !== undefined) {
      obj.gkeNodepool = GKENodePool.toJSON(message.gkeNodepool);
    }
    if (message.karpenterNodepool !== undefined) {
      obj.karpenterNodepool = KarpenterNodepool.toJSON(message.karpenterNodepool);
    }
    return obj;
  },
};

function createBaseUpdateNodepoolResponse(): UpdateNodepoolResponse {
  return { karpenterNodepool: undefined, gkeNodepool: undefined };
}

export const UpdateNodepoolResponse: MessageFns<UpdateNodepoolResponse> = {
  encode(message: UpdateNodepoolResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.karpenterNodepool !== undefined) {
      KarpenterNodepool.encode(message.karpenterNodepool, writer.uint32(10).fork()).join();
    }
    if (message.gkeNodepool !== undefined) {
      GKENodePool.encode(message.gkeNodepool, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateNodepoolResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateNodepoolResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.karpenterNodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gkeNodepool = GKENodePool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateNodepoolResponse {
    return {
      karpenterNodepool: isSet(object.karpenterNodepool)
        ? KarpenterNodepool.fromJSON(object.karpenterNodepool)
        : undefined,
      gkeNodepool: isSet(object.gkeNodepool) ? GKENodePool.fromJSON(object.gkeNodepool) : undefined,
    };
  },

  toJSON(message: UpdateNodepoolResponse): unknown {
    const obj: any = {};
    if (message.karpenterNodepool !== undefined) {
      obj.karpenterNodepool = KarpenterNodepool.toJSON(message.karpenterNodepool);
    }
    if (message.gkeNodepool !== undefined) {
      obj.gkeNodepool = GKENodePool.toJSON(message.gkeNodepool);
    }
    return obj;
  },
};

function createBaseDeleteNodepoolRequest(): DeleteNodepoolRequest {
  return { name: "" };
}

export const DeleteNodepoolRequest: MessageFns<DeleteNodepoolRequest> = {
  encode(message: DeleteNodepoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteNodepoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteNodepoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteNodepoolRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteNodepoolRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },
};

function createBaseDeleteNodepoolResponse(): DeleteNodepoolResponse {
  return {};
}

export const DeleteNodepoolResponse: MessageFns<DeleteNodepoolResponse> = {
  encode(_: DeleteNodepoolResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteNodepoolResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteNodepoolResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DeleteNodepoolResponse {
    return {};
  },

  toJSON(_: DeleteNodepoolResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetKarpenterNodepoolsRequest(): GetKarpenterNodepoolsRequest {
  return {};
}

export const GetKarpenterNodepoolsRequest: MessageFns<GetKarpenterNodepoolsRequest> = {
  encode(_: GetKarpenterNodepoolsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetKarpenterNodepoolsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetKarpenterNodepoolsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): GetKarpenterNodepoolsRequest {
    return {};
  },

  toJSON(_: GetKarpenterNodepoolsRequest): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetKarpenterNodepoolsResponse(): GetKarpenterNodepoolsResponse {
  return { nodepools: [] };
}

export const GetKarpenterNodepoolsResponse: MessageFns<GetKarpenterNodepoolsResponse> = {
  encode(message: GetKarpenterNodepoolsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.nodepools) {
      KarpenterNodepool.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetKarpenterNodepoolsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetKarpenterNodepoolsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nodepools.push(KarpenterNodepool.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetKarpenterNodepoolsResponse {
    return {
      nodepools: globalThis.Array.isArray(object?.nodepools)
        ? object.nodepools.map((e: any) => KarpenterNodepool.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GetKarpenterNodepoolsResponse): unknown {
    const obj: any = {};
    if (message.nodepools?.length) {
      obj.nodepools = message.nodepools.map((e) => KarpenterNodepool.toJSON(e));
    }
    return obj;
  },
};

function createBaseAddKarpenterNodepoolRequest(): AddKarpenterNodepoolRequest {
  return { nodepool: undefined };
}

export const AddKarpenterNodepoolRequest: MessageFns<AddKarpenterNodepoolRequest> = {
  encode(message: AddKarpenterNodepoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.nodepool !== undefined) {
      KarpenterNodepool.encode(message.nodepool, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AddKarpenterNodepoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAddKarpenterNodepoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AddKarpenterNodepoolRequest {
    return { nodepool: isSet(object.nodepool) ? KarpenterNodepool.fromJSON(object.nodepool) : undefined };
  },

  toJSON(message: AddKarpenterNodepoolRequest): unknown {
    const obj: any = {};
    if (message.nodepool !== undefined) {
      obj.nodepool = KarpenterNodepool.toJSON(message.nodepool);
    }
    return obj;
  },
};

function createBaseAddKarpenterNodepoolResponse(): AddKarpenterNodepoolResponse {
  return { nodepool: undefined };
}

export const AddKarpenterNodepoolResponse: MessageFns<AddKarpenterNodepoolResponse> = {
  encode(message: AddKarpenterNodepoolResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.nodepool !== undefined) {
      KarpenterNodepool.encode(message.nodepool, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AddKarpenterNodepoolResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAddKarpenterNodepoolResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AddKarpenterNodepoolResponse {
    return { nodepool: isSet(object.nodepool) ? KarpenterNodepool.fromJSON(object.nodepool) : undefined };
  },

  toJSON(message: AddKarpenterNodepoolResponse): unknown {
    const obj: any = {};
    if (message.nodepool !== undefined) {
      obj.nodepool = KarpenterNodepool.toJSON(message.nodepool);
    }
    return obj;
  },
};

function createBaseUpdateKarpenterNodepoolRequest(): UpdateKarpenterNodepoolRequest {
  return { name: "", nodepool: undefined };
}

export const UpdateKarpenterNodepoolRequest: MessageFns<UpdateKarpenterNodepoolRequest> = {
  encode(message: UpdateKarpenterNodepoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.nodepool !== undefined) {
      KarpenterNodepool.encode(message.nodepool, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateKarpenterNodepoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateKarpenterNodepoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.nodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateKarpenterNodepoolRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      nodepool: isSet(object.nodepool) ? KarpenterNodepool.fromJSON(object.nodepool) : undefined,
    };
  },

  toJSON(message: UpdateKarpenterNodepoolRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.nodepool !== undefined) {
      obj.nodepool = KarpenterNodepool.toJSON(message.nodepool);
    }
    return obj;
  },
};

function createBaseUpdateKarpenterNodepoolResponse(): UpdateKarpenterNodepoolResponse {
  return { nodepool: undefined };
}

export const UpdateKarpenterNodepoolResponse: MessageFns<UpdateKarpenterNodepoolResponse> = {
  encode(message: UpdateKarpenterNodepoolResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.nodepool !== undefined) {
      KarpenterNodepool.encode(message.nodepool, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpdateKarpenterNodepoolResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpdateKarpenterNodepoolResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nodepool = KarpenterNodepool.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpdateKarpenterNodepoolResponse {
    return { nodepool: isSet(object.nodepool) ? KarpenterNodepool.fromJSON(object.nodepool) : undefined };
  },

  toJSON(message: UpdateKarpenterNodepoolResponse): unknown {
    const obj: any = {};
    if (message.nodepool !== undefined) {
      obj.nodepool = KarpenterNodepool.toJSON(message.nodepool);
    }
    return obj;
  },
};

function createBaseDeleteKarpenterNodepoolRequest(): DeleteKarpenterNodepoolRequest {
  return { name: "" };
}

export const DeleteKarpenterNodepoolRequest: MessageFns<DeleteKarpenterNodepoolRequest> = {
  encode(message: DeleteKarpenterNodepoolRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteKarpenterNodepoolRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteKarpenterNodepoolRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeleteKarpenterNodepoolRequest {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: DeleteKarpenterNodepoolRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },
};

function createBaseDeleteKarpenterNodepoolResponse(): DeleteKarpenterNodepoolResponse {
  return {};
}

export const DeleteKarpenterNodepoolResponse: MessageFns<DeleteKarpenterNodepoolResponse> = {
  encode(_: DeleteKarpenterNodepoolResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeleteKarpenterNodepoolResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeleteKarpenterNodepoolResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DeleteKarpenterNodepoolResponse {
    return {};
  },

  toJSON(_: DeleteKarpenterNodepoolResponse): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetKarpenterInstallationMetadataRequest(): GetKarpenterInstallationMetadataRequest {
  return {};
}

export const GetKarpenterInstallationMetadataRequest: MessageFns<GetKarpenterInstallationMetadataRequest> = {
  encode(_: GetKarpenterInstallationMetadataRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetKarpenterInstallationMetadataRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetKarpenterInstallationMetadataRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): GetKarpenterInstallationMetadataRequest {
    return {};
  },

  toJSON(_: GetKarpenterInstallationMetadataRequest): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetKarpenterInstallationMetadataResponse(): GetKarpenterInstallationMetadataResponse {
  return { deploymentLabels: {} };
}

export const GetKarpenterInstallationMetadataResponse: MessageFns<GetKarpenterInstallationMetadataResponse> = {
  encode(message: GetKarpenterInstallationMetadataResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.deploymentLabels).forEach(([key, value]) => {
      GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry.encode(
        { key: key as any, value },
        writer.uint32(10).fork(),
      ).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetKarpenterInstallationMetadataResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetKarpenterInstallationMetadataResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          const entry1 = GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.deploymentLabels[entry1.key] = entry1.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetKarpenterInstallationMetadataResponse {
    return {
      deploymentLabels: isObject(object.deploymentLabels)
        ? Object.entries(object.deploymentLabels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: GetKarpenterInstallationMetadataResponse): unknown {
    const obj: any = {};
    if (message.deploymentLabels) {
      const entries = Object.entries(message.deploymentLabels);
      if (entries.length > 0) {
        obj.deploymentLabels = {};
        entries.forEach(([k, v]) => {
          obj.deploymentLabels[k] = v;
        });
      }
    }
    return obj;
  },
};

function createBaseGetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry(): GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry {
  return { key: "", value: "" };
}

export const GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry: MessageFns<
  GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry
> = {
  encode(
    message: GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: GetKarpenterInstallationMetadataResponse_DeploymentLabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },
};

function createBaseDeploymentTag(): DeploymentTag {
  return { tag: "", weight: undefined, deploymentId: undefined, mirrorWeight: undefined };
}

export const DeploymentTag: MessageFns<DeploymentTag> = {
  encode(message: DeploymentTag, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.tag !== "") {
      writer.uint32(10).string(message.tag);
    }
    if (message.weight !== undefined) {
      writer.uint32(16).int32(message.weight);
    }
    if (message.deploymentId !== undefined) {
      writer.uint32(26).string(message.deploymentId);
    }
    if (message.mirrorWeight !== undefined) {
      writer.uint32(32).int32(message.mirrorWeight);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeploymentTag {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeploymentTag();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.tag = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.weight = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.deploymentId = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.mirrorWeight = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeploymentTag {
    return {
      tag: isSet(object.tag) ? globalThis.String(object.tag) : "",
      weight: isSet(object.weight) ? globalThis.Number(object.weight) : undefined,
      deploymentId: isSet(object.deploymentId) ? globalThis.String(object.deploymentId) : undefined,
      mirrorWeight: isSet(object.mirrorWeight) ? globalThis.Number(object.mirrorWeight) : undefined,
    };
  },

  toJSON(message: DeploymentTag): unknown {
    const obj: any = {};
    if (message.tag !== "") {
      obj.tag = message.tag;
    }
    if (message.weight !== undefined) {
      obj.weight = Math.round(message.weight);
    }
    if (message.deploymentId !== undefined) {
      obj.deploymentId = message.deploymentId;
    }
    if (message.mirrorWeight !== undefined) {
      obj.mirrorWeight = Math.round(message.mirrorWeight);
    }
    return obj;
  },
};

function createBaseGetTagWeightsRequest(): GetTagWeightsRequest {
  return {};
}

export const GetTagWeightsRequest: MessageFns<GetTagWeightsRequest> = {
  encode(_: GetTagWeightsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetTagWeightsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetTagWeightsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): GetTagWeightsRequest {
    return {};
  },

  toJSON(_: GetTagWeightsRequest): unknown {
    const obj: any = {};
    return obj;
  },
};

function createBaseGetTagWeightsResponse(): GetTagWeightsResponse {
  return { tags: [] };
}

export const GetTagWeightsResponse: MessageFns<GetTagWeightsResponse> = {
  encode(message: GetTagWeightsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.tags) {
      DeploymentTag.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetTagWeightsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetTagWeightsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.tags.push(DeploymentTag.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetTagWeightsResponse {
    return {
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => DeploymentTag.fromJSON(e)) : [],
    };
  },

  toJSON(message: GetTagWeightsResponse): unknown {
    const obj: any = {};
    if (message.tags?.length) {
      obj.tags = message.tags.map((e) => DeploymentTag.toJSON(e));
    }
    return obj;
  },
};

function createBaseSetTagWeightsRequest(): SetTagWeightsRequest {
  return { tags: [] };
}

export const SetTagWeightsRequest: MessageFns<SetTagWeightsRequest> = {
  encode(message: SetTagWeightsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.tags) {
      DeploymentTag.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SetTagWeightsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSetTagWeightsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.tags.push(DeploymentTag.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SetTagWeightsRequest {
    return {
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => DeploymentTag.fromJSON(e)) : [],
    };
  },

  toJSON(message: SetTagWeightsRequest): unknown {
    const obj: any = {};
    if (message.tags?.length) {
      obj.tags = message.tags.map((e) => DeploymentTag.toJSON(e));
    }
    return obj;
  },
};

function createBaseSetTagWeightsResponse(): SetTagWeightsResponse {
  return { tags: [] };
}

export const SetTagWeightsResponse: MessageFns<SetTagWeightsResponse> = {
  encode(message: SetTagWeightsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.tags) {
      DeploymentTag.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SetTagWeightsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSetTagWeightsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.tags.push(DeploymentTag.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SetTagWeightsResponse {
    return {
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => DeploymentTag.fromJSON(e)) : [],
    };
  },

  toJSON(message: SetTagWeightsResponse): unknown {
    const obj: any = {};
    if (message.tags?.length) {
      obj.tags = message.tags.map((e) => DeploymentTag.toJSON(e));
    }
    return obj;
  },
};

export type BuilderServiceService = typeof BuilderServiceService;
export const BuilderServiceService = {
  getSearchConfig: {
    path: "/chalk.server.v1.BuilderService/GetSearchConfig",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetSearchConfigRequest) => Buffer.from(GetSearchConfigRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetSearchConfigRequest.decode(value),
    responseSerialize: (value: GetSearchConfigResponse) => Buffer.from(GetSearchConfigResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetSearchConfigResponse.decode(value),
  },
  /**
   * Takes an existing (past) deployment and promotes the k8s resources / other things associated with it.
   * Useful for debugging in local development where the auto activation doesn't work b/c no pubsub.
   */
  activateDeployment: {
    path: "/chalk.server.v1.BuilderService/ActivateDeployment",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ActivateDeploymentRequest) =>
      Buffer.from(ActivateDeploymentRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ActivateDeploymentRequest.decode(value),
    responseSerialize: (value: ActivateDeploymentResponse) =>
      Buffer.from(ActivateDeploymentResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ActivateDeploymentResponse.decode(value),
  },
  indexDeployment: {
    path: "/chalk.server.v1.BuilderService/IndexDeployment",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: IndexDeploymentRequest) => Buffer.from(IndexDeploymentRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => IndexDeploymentRequest.decode(value),
    responseSerialize: (value: IndexDeploymentResponse) => Buffer.from(IndexDeploymentResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => IndexDeploymentResponse.decode(value),
  },
  /**
   * Intermediate step in the deployment activation process. Allows for partial migration to the new
   * go-api-server builder service.
   */
  deployKubeComponents: {
    path: "/chalk.server.v1.BuilderService/DeployKubeComponents",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: DeployKubeComponentsRequest) =>
      Buffer.from(DeployKubeComponentsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => DeployKubeComponentsRequest.decode(value),
    responseSerialize: (value: DeployKubeComponentsResponse) =>
      Buffer.from(DeployKubeComponentsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => DeployKubeComponentsResponse.decode(value),
  },
  /**
   * Takes an existing (past) deployment and re-creates the image associated with it,
   * publishing the image as 'new_image_tag'.
   */
  rebuildDeployment: {
    path: "/chalk.server.v1.BuilderService/RebuildDeployment",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: RebuildDeploymentRequest) => Buffer.from(RebuildDeploymentRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => RebuildDeploymentRequest.decode(value),
    responseSerialize: (value: RebuildDeploymentResponse) =>
      Buffer.from(RebuildDeploymentResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => RebuildDeploymentResponse.decode(value),
  },
  /** Triggers a new build with the source code from this deployment and deploys the result */
  redeployDeployment: {
    path: "/chalk.server.v1.BuilderService/RedeployDeployment",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: RedeployDeploymentRequest) =>
      Buffer.from(RedeployDeploymentRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => RedeployDeploymentRequest.decode(value),
    responseSerialize: (value: RedeployDeploymentResponse) =>
      Buffer.from(RedeployDeploymentResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => RedeployDeploymentResponse.decode(value),
  },
  /** Triggers a new build with the provided source code archive and deploys the result */
  uploadSource: {
    path: "/chalk.server.v1.BuilderService/UploadSource",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UploadSourceRequest) => Buffer.from(UploadSourceRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UploadSourceRequest.decode(value),
    responseSerialize: (value: UploadSourceResponse) => Buffer.from(UploadSourceResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UploadSourceResponse.decode(value),
  },
  lintSource: {
    path: "/chalk.server.v1.BuilderService/LintSource",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: LintSourceRequest) => Buffer.from(LintSourceRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => LintSourceRequest.decode(value),
    responseSerialize: (value: LintSourceResponse) => Buffer.from(LintSourceResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => LintSourceResponse.decode(value),
  },
  getDeploymentSteps: {
    path: "/chalk.server.v1.BuilderService/GetDeploymentSteps",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetDeploymentStepsRequest) =>
      Buffer.from(GetDeploymentStepsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetDeploymentStepsRequest.decode(value),
    responseSerialize: (value: GetDeploymentStepsResponse) =>
      Buffer.from(GetDeploymentStepsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetDeploymentStepsResponse.decode(value),
  },
  getDeploymentLogs: {
    path: "/chalk.server.v1.BuilderService/GetDeploymentLogs",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetDeploymentLogsRequest) => Buffer.from(GetDeploymentLogsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetDeploymentLogsRequest.decode(value),
    responseSerialize: (value: GetDeploymentLogsResponse) =>
      Buffer.from(GetDeploymentLogsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetDeploymentLogsResponse.decode(value),
  },
  getClusterTimescaleDb: {
    path: "/chalk.server.v1.BuilderService/GetClusterTimescaleDB",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetClusterTimescaleDBRequest) =>
      Buffer.from(GetClusterTimescaleDBRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetClusterTimescaleDBRequest.decode(value),
    responseSerialize: (value: GetClusterTimescaleDBResponse) =>
      Buffer.from(GetClusterTimescaleDBResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetClusterTimescaleDBResponse.decode(value),
  },
  getClusterGateway: {
    path: "/chalk.server.v1.BuilderService/GetClusterGateway",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetClusterGatewayRequest) => Buffer.from(GetClusterGatewayRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetClusterGatewayRequest.decode(value),
    responseSerialize: (value: GetClusterGatewayResponse) =>
      Buffer.from(GetClusterGatewayResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetClusterGatewayResponse.decode(value),
  },
  getClusterBackgroundPersistence: {
    path: "/chalk.server.v1.BuilderService/GetClusterBackgroundPersistence",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetClusterBackgroundPersistenceRequest) =>
      Buffer.from(GetClusterBackgroundPersistenceRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetClusterBackgroundPersistenceRequest.decode(value),
    responseSerialize: (value: GetClusterBackgroundPersistenceResponse) =>
      Buffer.from(GetClusterBackgroundPersistenceResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetClusterBackgroundPersistenceResponse.decode(value),
  },
  createClusterTimescaleDb: {
    path: "/chalk.server.v1.BuilderService/CreateClusterTimescaleDB",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CreateClusterTimescaleDBRequest) =>
      Buffer.from(CreateClusterTimescaleDBRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => CreateClusterTimescaleDBRequest.decode(value),
    responseSerialize: (value: CreateClusterTimescaleDBResponse) =>
      Buffer.from(CreateClusterTimescaleDBResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => CreateClusterTimescaleDBResponse.decode(value),
  },
  migrateClusterTimescaleDb: {
    path: "/chalk.server.v1.BuilderService/MigrateClusterTimescaleDB",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: MigrateClusterTimescaleDBRequest) =>
      Buffer.from(MigrateClusterTimescaleDBRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => MigrateClusterTimescaleDBRequest.decode(value),
    responseSerialize: (value: MigrateClusterTimescaleDBResponse) =>
      Buffer.from(MigrateClusterTimescaleDBResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => MigrateClusterTimescaleDBResponse.decode(value),
  },
  createClusterGateway: {
    path: "/chalk.server.v1.BuilderService/CreateClusterGateway",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CreateClusterGatewayRequest) =>
      Buffer.from(CreateClusterGatewayRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => CreateClusterGatewayRequest.decode(value),
    responseSerialize: (value: CreateClusterGatewayResponse) =>
      Buffer.from(CreateClusterGatewayResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => CreateClusterGatewayResponse.decode(value),
  },
  createClusterBackgroundPersistence: {
    path: "/chalk.server.v1.BuilderService/CreateClusterBackgroundPersistence",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CreateClusterBackgroundPersistenceRequest) =>
      Buffer.from(CreateClusterBackgroundPersistenceRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => CreateClusterBackgroundPersistenceRequest.decode(value),
    responseSerialize: (value: CreateClusterBackgroundPersistenceResponse) =>
      Buffer.from(CreateClusterBackgroundPersistenceResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => CreateClusterBackgroundPersistenceResponse.decode(value),
  },
  updateEnvironmentVariables: {
    path: "/chalk.server.v1.BuilderService/UpdateEnvironmentVariables",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpdateEnvironmentVariablesRequest) =>
      Buffer.from(UpdateEnvironmentVariablesRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UpdateEnvironmentVariablesRequest.decode(value),
    responseSerialize: (value: UpdateEnvironmentVariablesResponse) =>
      Buffer.from(UpdateEnvironmentVariablesResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpdateEnvironmentVariablesResponse.decode(value),
  },
  startBranch: {
    path: "/chalk.server.v1.BuilderService/StartBranch",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: StartBranchRequest) => Buffer.from(StartBranchRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => StartBranchRequest.decode(value),
    responseSerialize: (value: StartBranchResponse) => Buffer.from(StartBranchResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => StartBranchResponse.decode(value),
  },
  scaleBranch: {
    path: "/chalk.server.v1.BuilderService/ScaleBranch",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ScaleBranchRequest) => Buffer.from(ScaleBranchRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ScaleBranchRequest.decode(value),
    responseSerialize: (value: ScaleBranchResponse) => Buffer.from(ScaleBranchResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ScaleBranchResponse.decode(value),
  },
  getNodepools: {
    path: "/chalk.server.v1.BuilderService/GetNodepools",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetNodepoolsRequest) => Buffer.from(GetNodepoolsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetNodepoolsRequest.decode(value),
    responseSerialize: (value: GetNodepoolsResponse) => Buffer.from(GetNodepoolsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetNodepoolsResponse.decode(value),
  },
  addNodepool: {
    path: "/chalk.server.v1.BuilderService/AddNodepool",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AddNodepoolRequest) => Buffer.from(AddNodepoolRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => AddNodepoolRequest.decode(value),
    responseSerialize: (value: AddNodepoolResponse) => Buffer.from(AddNodepoolResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => AddNodepoolResponse.decode(value),
  },
  updateNodepool: {
    path: "/chalk.server.v1.BuilderService/UpdateNodepool",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpdateNodepoolRequest) => Buffer.from(UpdateNodepoolRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UpdateNodepoolRequest.decode(value),
    responseSerialize: (value: UpdateNodepoolResponse) => Buffer.from(UpdateNodepoolResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpdateNodepoolResponse.decode(value),
  },
  deleteNodepool: {
    path: "/chalk.server.v1.BuilderService/DeleteNodepool",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: DeleteNodepoolRequest) => Buffer.from(DeleteNodepoolRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => DeleteNodepoolRequest.decode(value),
    responseSerialize: (value: DeleteNodepoolResponse) => Buffer.from(DeleteNodepoolResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => DeleteNodepoolResponse.decode(value),
  },
  /** to be deprecated */
  getKarpenterNodepools: {
    path: "/chalk.server.v1.BuilderService/GetKarpenterNodepools",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetKarpenterNodepoolsRequest) =>
      Buffer.from(GetKarpenterNodepoolsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetKarpenterNodepoolsRequest.decode(value),
    responseSerialize: (value: GetKarpenterNodepoolsResponse) =>
      Buffer.from(GetKarpenterNodepoolsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetKarpenterNodepoolsResponse.decode(value),
  },
  /** to be deprecated */
  addKarpenterNodepool: {
    path: "/chalk.server.v1.BuilderService/AddKarpenterNodepool",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AddKarpenterNodepoolRequest) =>
      Buffer.from(AddKarpenterNodepoolRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => AddKarpenterNodepoolRequest.decode(value),
    responseSerialize: (value: AddKarpenterNodepoolResponse) =>
      Buffer.from(AddKarpenterNodepoolResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => AddKarpenterNodepoolResponse.decode(value),
  },
  /** to be deprecated */
  updateKarpenterNodepool: {
    path: "/chalk.server.v1.BuilderService/UpdateKarpenterNodepool",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpdateKarpenterNodepoolRequest) =>
      Buffer.from(UpdateKarpenterNodepoolRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UpdateKarpenterNodepoolRequest.decode(value),
    responseSerialize: (value: UpdateKarpenterNodepoolResponse) =>
      Buffer.from(UpdateKarpenterNodepoolResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpdateKarpenterNodepoolResponse.decode(value),
  },
  /** to be deprecated */
  deleteKarpenterNodepool: {
    path: "/chalk.server.v1.BuilderService/DeleteKarpenterNodepool",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: DeleteKarpenterNodepoolRequest) =>
      Buffer.from(DeleteKarpenterNodepoolRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => DeleteKarpenterNodepoolRequest.decode(value),
    responseSerialize: (value: DeleteKarpenterNodepoolResponse) =>
      Buffer.from(DeleteKarpenterNodepoolResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => DeleteKarpenterNodepoolResponse.decode(value),
  },
  getKarpenterInstallationMetadata: {
    path: "/chalk.server.v1.BuilderService/GetKarpenterInstallationMetadata",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetKarpenterInstallationMetadataRequest) =>
      Buffer.from(GetKarpenterInstallationMetadataRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetKarpenterInstallationMetadataRequest.decode(value),
    responseSerialize: (value: GetKarpenterInstallationMetadataResponse) =>
      Buffer.from(GetKarpenterInstallationMetadataResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetKarpenterInstallationMetadataResponse.decode(value),
  },
  getTagWeights: {
    path: "/chalk.server.v1.BuilderService/GetTagWeights",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetTagWeightsRequest) => Buffer.from(GetTagWeightsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetTagWeightsRequest.decode(value),
    responseSerialize: (value: GetTagWeightsResponse) => Buffer.from(GetTagWeightsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetTagWeightsResponse.decode(value),
  },
  setTagWeights: {
    path: "/chalk.server.v1.BuilderService/SetTagWeights",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: SetTagWeightsRequest) => Buffer.from(SetTagWeightsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => SetTagWeightsRequest.decode(value),
    responseSerialize: (value: SetTagWeightsResponse) => Buffer.from(SetTagWeightsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => SetTagWeightsResponse.decode(value),
  },
} as const;

export interface BuilderServiceServer extends UntypedServiceImplementation {
  getSearchConfig: handleUnaryCall<GetSearchConfigRequest, GetSearchConfigResponse>;
  /**
   * Takes an existing (past) deployment and promotes the k8s resources / other things associated with it.
   * Useful for debugging in local development where the auto activation doesn't work b/c no pubsub.
   */
  activateDeployment: handleUnaryCall<ActivateDeploymentRequest, ActivateDeploymentResponse>;
  indexDeployment: handleUnaryCall<IndexDeploymentRequest, IndexDeploymentResponse>;
  /**
   * Intermediate step in the deployment activation process. Allows for partial migration to the new
   * go-api-server builder service.
   */
  deployKubeComponents: handleUnaryCall<DeployKubeComponentsRequest, DeployKubeComponentsResponse>;
  /**
   * Takes an existing (past) deployment and re-creates the image associated with it,
   * publishing the image as 'new_image_tag'.
   */
  rebuildDeployment: handleUnaryCall<RebuildDeploymentRequest, RebuildDeploymentResponse>;
  /** Triggers a new build with the source code from this deployment and deploys the result */
  redeployDeployment: handleUnaryCall<RedeployDeploymentRequest, RedeployDeploymentResponse>;
  /** Triggers a new build with the provided source code archive and deploys the result */
  uploadSource: handleUnaryCall<UploadSourceRequest, UploadSourceResponse>;
  lintSource: handleUnaryCall<LintSourceRequest, LintSourceResponse>;
  getDeploymentSteps: handleUnaryCall<GetDeploymentStepsRequest, GetDeploymentStepsResponse>;
  getDeploymentLogs: handleUnaryCall<GetDeploymentLogsRequest, GetDeploymentLogsResponse>;
  getClusterTimescaleDb: handleUnaryCall<GetClusterTimescaleDBRequest, GetClusterTimescaleDBResponse>;
  getClusterGateway: handleUnaryCall<GetClusterGatewayRequest, GetClusterGatewayResponse>;
  getClusterBackgroundPersistence: handleUnaryCall<
    GetClusterBackgroundPersistenceRequest,
    GetClusterBackgroundPersistenceResponse
  >;
  createClusterTimescaleDb: handleUnaryCall<CreateClusterTimescaleDBRequest, CreateClusterTimescaleDBResponse>;
  migrateClusterTimescaleDb: handleUnaryCall<MigrateClusterTimescaleDBRequest, MigrateClusterTimescaleDBResponse>;
  createClusterGateway: handleUnaryCall<CreateClusterGatewayRequest, CreateClusterGatewayResponse>;
  createClusterBackgroundPersistence: handleUnaryCall<
    CreateClusterBackgroundPersistenceRequest,
    CreateClusterBackgroundPersistenceResponse
  >;
  updateEnvironmentVariables: handleUnaryCall<UpdateEnvironmentVariablesRequest, UpdateEnvironmentVariablesResponse>;
  startBranch: handleUnaryCall<StartBranchRequest, StartBranchResponse>;
  scaleBranch: handleUnaryCall<ScaleBranchRequest, ScaleBranchResponse>;
  getNodepools: handleUnaryCall<GetNodepoolsRequest, GetNodepoolsResponse>;
  addNodepool: handleUnaryCall<AddNodepoolRequest, AddNodepoolResponse>;
  updateNodepool: handleUnaryCall<UpdateNodepoolRequest, UpdateNodepoolResponse>;
  deleteNodepool: handleUnaryCall<DeleteNodepoolRequest, DeleteNodepoolResponse>;
  /** to be deprecated */
  getKarpenterNodepools: handleUnaryCall<GetKarpenterNodepoolsRequest, GetKarpenterNodepoolsResponse>;
  /** to be deprecated */
  addKarpenterNodepool: handleUnaryCall<AddKarpenterNodepoolRequest, AddKarpenterNodepoolResponse>;
  /** to be deprecated */
  updateKarpenterNodepool: handleUnaryCall<UpdateKarpenterNodepoolRequest, UpdateKarpenterNodepoolResponse>;
  /** to be deprecated */
  deleteKarpenterNodepool: handleUnaryCall<DeleteKarpenterNodepoolRequest, DeleteKarpenterNodepoolResponse>;
  getKarpenterInstallationMetadata: handleUnaryCall<
    GetKarpenterInstallationMetadataRequest,
    GetKarpenterInstallationMetadataResponse
  >;
  getTagWeights: handleUnaryCall<GetTagWeightsRequest, GetTagWeightsResponse>;
  setTagWeights: handleUnaryCall<SetTagWeightsRequest, SetTagWeightsResponse>;
}

export interface BuilderServiceClient extends Client {
  getSearchConfig(
    request: GetSearchConfigRequest,
    callback: (error: ServiceError | null, response: GetSearchConfigResponse) => void,
  ): ClientUnaryCall;
  getSearchConfig(
    request: GetSearchConfigRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetSearchConfigResponse) => void,
  ): ClientUnaryCall;
  getSearchConfig(
    request: GetSearchConfigRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetSearchConfigResponse) => void,
  ): ClientUnaryCall;
  /**
   * Takes an existing (past) deployment and promotes the k8s resources / other things associated with it.
   * Useful for debugging in local development where the auto activation doesn't work b/c no pubsub.
   */
  activateDeployment(
    request: ActivateDeploymentRequest,
    callback: (error: ServiceError | null, response: ActivateDeploymentResponse) => void,
  ): ClientUnaryCall;
  activateDeployment(
    request: ActivateDeploymentRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ActivateDeploymentResponse) => void,
  ): ClientUnaryCall;
  activateDeployment(
    request: ActivateDeploymentRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ActivateDeploymentResponse) => void,
  ): ClientUnaryCall;
  indexDeployment(
    request: IndexDeploymentRequest,
    callback: (error: ServiceError | null, response: IndexDeploymentResponse) => void,
  ): ClientUnaryCall;
  indexDeployment(
    request: IndexDeploymentRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: IndexDeploymentResponse) => void,
  ): ClientUnaryCall;
  indexDeployment(
    request: IndexDeploymentRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: IndexDeploymentResponse) => void,
  ): ClientUnaryCall;
  /**
   * Intermediate step in the deployment activation process. Allows for partial migration to the new
   * go-api-server builder service.
   */
  deployKubeComponents(
    request: DeployKubeComponentsRequest,
    callback: (error: ServiceError | null, response: DeployKubeComponentsResponse) => void,
  ): ClientUnaryCall;
  deployKubeComponents(
    request: DeployKubeComponentsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: DeployKubeComponentsResponse) => void,
  ): ClientUnaryCall;
  deployKubeComponents(
    request: DeployKubeComponentsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: DeployKubeComponentsResponse) => void,
  ): ClientUnaryCall;
  /**
   * Takes an existing (past) deployment and re-creates the image associated with it,
   * publishing the image as 'new_image_tag'.
   */
  rebuildDeployment(
    request: RebuildDeploymentRequest,
    callback: (error: ServiceError | null, response: RebuildDeploymentResponse) => void,
  ): ClientUnaryCall;
  rebuildDeployment(
    request: RebuildDeploymentRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: RebuildDeploymentResponse) => void,
  ): ClientUnaryCall;
  rebuildDeployment(
    request: RebuildDeploymentRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: RebuildDeploymentResponse) => void,
  ): ClientUnaryCall;
  /** Triggers a new build with the source code from this deployment and deploys the result */
  redeployDeployment(
    request: RedeployDeploymentRequest,
    callback: (error: ServiceError | null, response: RedeployDeploymentResponse) => void,
  ): ClientUnaryCall;
  redeployDeployment(
    request: RedeployDeploymentRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: RedeployDeploymentResponse) => void,
  ): ClientUnaryCall;
  redeployDeployment(
    request: RedeployDeploymentRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: RedeployDeploymentResponse) => void,
  ): ClientUnaryCall;
  /** Triggers a new build with the provided source code archive and deploys the result */
  uploadSource(
    request: UploadSourceRequest,
    callback: (error: ServiceError | null, response: UploadSourceResponse) => void,
  ): ClientUnaryCall;
  uploadSource(
    request: UploadSourceRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UploadSourceResponse) => void,
  ): ClientUnaryCall;
  uploadSource(
    request: UploadSourceRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UploadSourceResponse) => void,
  ): ClientUnaryCall;
  lintSource(
    request: LintSourceRequest,
    callback: (error: ServiceError | null, response: LintSourceResponse) => void,
  ): ClientUnaryCall;
  lintSource(
    request: LintSourceRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: LintSourceResponse) => void,
  ): ClientUnaryCall;
  lintSource(
    request: LintSourceRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: LintSourceResponse) => void,
  ): ClientUnaryCall;
  getDeploymentSteps(
    request: GetDeploymentStepsRequest,
    callback: (error: ServiceError | null, response: GetDeploymentStepsResponse) => void,
  ): ClientUnaryCall;
  getDeploymentSteps(
    request: GetDeploymentStepsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetDeploymentStepsResponse) => void,
  ): ClientUnaryCall;
  getDeploymentSteps(
    request: GetDeploymentStepsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetDeploymentStepsResponse) => void,
  ): ClientUnaryCall;
  getDeploymentLogs(
    request: GetDeploymentLogsRequest,
    callback: (error: ServiceError | null, response: GetDeploymentLogsResponse) => void,
  ): ClientUnaryCall;
  getDeploymentLogs(
    request: GetDeploymentLogsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetDeploymentLogsResponse) => void,
  ): ClientUnaryCall;
  getDeploymentLogs(
    request: GetDeploymentLogsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetDeploymentLogsResponse) => void,
  ): ClientUnaryCall;
  getClusterTimescaleDb(
    request: GetClusterTimescaleDBRequest,
    callback: (error: ServiceError | null, response: GetClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  getClusterTimescaleDb(
    request: GetClusterTimescaleDBRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  getClusterTimescaleDb(
    request: GetClusterTimescaleDBRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  getClusterGateway(
    request: GetClusterGatewayRequest,
    callback: (error: ServiceError | null, response: GetClusterGatewayResponse) => void,
  ): ClientUnaryCall;
  getClusterGateway(
    request: GetClusterGatewayRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetClusterGatewayResponse) => void,
  ): ClientUnaryCall;
  getClusterGateway(
    request: GetClusterGatewayRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetClusterGatewayResponse) => void,
  ): ClientUnaryCall;
  getClusterBackgroundPersistence(
    request: GetClusterBackgroundPersistenceRequest,
    callback: (error: ServiceError | null, response: GetClusterBackgroundPersistenceResponse) => void,
  ): ClientUnaryCall;
  getClusterBackgroundPersistence(
    request: GetClusterBackgroundPersistenceRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetClusterBackgroundPersistenceResponse) => void,
  ): ClientUnaryCall;
  getClusterBackgroundPersistence(
    request: GetClusterBackgroundPersistenceRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetClusterBackgroundPersistenceResponse) => void,
  ): ClientUnaryCall;
  createClusterTimescaleDb(
    request: CreateClusterTimescaleDBRequest,
    callback: (error: ServiceError | null, response: CreateClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  createClusterTimescaleDb(
    request: CreateClusterTimescaleDBRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: CreateClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  createClusterTimescaleDb(
    request: CreateClusterTimescaleDBRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: CreateClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  migrateClusterTimescaleDb(
    request: MigrateClusterTimescaleDBRequest,
    callback: (error: ServiceError | null, response: MigrateClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  migrateClusterTimescaleDb(
    request: MigrateClusterTimescaleDBRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: MigrateClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  migrateClusterTimescaleDb(
    request: MigrateClusterTimescaleDBRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: MigrateClusterTimescaleDBResponse) => void,
  ): ClientUnaryCall;
  createClusterGateway(
    request: CreateClusterGatewayRequest,
    callback: (error: ServiceError | null, response: CreateClusterGatewayResponse) => void,
  ): ClientUnaryCall;
  createClusterGateway(
    request: CreateClusterGatewayRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: CreateClusterGatewayResponse) => void,
  ): ClientUnaryCall;
  createClusterGateway(
    request: CreateClusterGatewayRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: CreateClusterGatewayResponse) => void,
  ): ClientUnaryCall;
  createClusterBackgroundPersistence(
    request: CreateClusterBackgroundPersistenceRequest,
    callback: (error: ServiceError | null, response: CreateClusterBackgroundPersistenceResponse) => void,
  ): ClientUnaryCall;
  createClusterBackgroundPersistence(
    request: CreateClusterBackgroundPersistenceRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: CreateClusterBackgroundPersistenceResponse) => void,
  ): ClientUnaryCall;
  createClusterBackgroundPersistence(
    request: CreateClusterBackgroundPersistenceRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: CreateClusterBackgroundPersistenceResponse) => void,
  ): ClientUnaryCall;
  updateEnvironmentVariables(
    request: UpdateEnvironmentVariablesRequest,
    callback: (error: ServiceError | null, response: UpdateEnvironmentVariablesResponse) => void,
  ): ClientUnaryCall;
  updateEnvironmentVariables(
    request: UpdateEnvironmentVariablesRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpdateEnvironmentVariablesResponse) => void,
  ): ClientUnaryCall;
  updateEnvironmentVariables(
    request: UpdateEnvironmentVariablesRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpdateEnvironmentVariablesResponse) => void,
  ): ClientUnaryCall;
  startBranch(
    request: StartBranchRequest,
    callback: (error: ServiceError | null, response: StartBranchResponse) => void,
  ): ClientUnaryCall;
  startBranch(
    request: StartBranchRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: StartBranchResponse) => void,
  ): ClientUnaryCall;
  startBranch(
    request: StartBranchRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: StartBranchResponse) => void,
  ): ClientUnaryCall;
  scaleBranch(
    request: ScaleBranchRequest,
    callback: (error: ServiceError | null, response: ScaleBranchResponse) => void,
  ): ClientUnaryCall;
  scaleBranch(
    request: ScaleBranchRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ScaleBranchResponse) => void,
  ): ClientUnaryCall;
  scaleBranch(
    request: ScaleBranchRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ScaleBranchResponse) => void,
  ): ClientUnaryCall;
  getNodepools(
    request: GetNodepoolsRequest,
    callback: (error: ServiceError | null, response: GetNodepoolsResponse) => void,
  ): ClientUnaryCall;
  getNodepools(
    request: GetNodepoolsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetNodepoolsResponse) => void,
  ): ClientUnaryCall;
  getNodepools(
    request: GetNodepoolsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetNodepoolsResponse) => void,
  ): ClientUnaryCall;
  addNodepool(
    request: AddNodepoolRequest,
    callback: (error: ServiceError | null, response: AddNodepoolResponse) => void,
  ): ClientUnaryCall;
  addNodepool(
    request: AddNodepoolRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: AddNodepoolResponse) => void,
  ): ClientUnaryCall;
  addNodepool(
    request: AddNodepoolRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: AddNodepoolResponse) => void,
  ): ClientUnaryCall;
  updateNodepool(
    request: UpdateNodepoolRequest,
    callback: (error: ServiceError | null, response: UpdateNodepoolResponse) => void,
  ): ClientUnaryCall;
  updateNodepool(
    request: UpdateNodepoolRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpdateNodepoolResponse) => void,
  ): ClientUnaryCall;
  updateNodepool(
    request: UpdateNodepoolRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpdateNodepoolResponse) => void,
  ): ClientUnaryCall;
  deleteNodepool(
    request: DeleteNodepoolRequest,
    callback: (error: ServiceError | null, response: DeleteNodepoolResponse) => void,
  ): ClientUnaryCall;
  deleteNodepool(
    request: DeleteNodepoolRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: DeleteNodepoolResponse) => void,
  ): ClientUnaryCall;
  deleteNodepool(
    request: DeleteNodepoolRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: DeleteNodepoolResponse) => void,
  ): ClientUnaryCall;
  /** to be deprecated */
  getKarpenterNodepools(
    request: GetKarpenterNodepoolsRequest,
    callback: (error: ServiceError | null, response: GetKarpenterNodepoolsResponse) => void,
  ): ClientUnaryCall;
  getKarpenterNodepools(
    request: GetKarpenterNodepoolsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetKarpenterNodepoolsResponse) => void,
  ): ClientUnaryCall;
  getKarpenterNodepools(
    request: GetKarpenterNodepoolsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetKarpenterNodepoolsResponse) => void,
  ): ClientUnaryCall;
  /** to be deprecated */
  addKarpenterNodepool(
    request: AddKarpenterNodepoolRequest,
    callback: (error: ServiceError | null, response: AddKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  addKarpenterNodepool(
    request: AddKarpenterNodepoolRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: AddKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  addKarpenterNodepool(
    request: AddKarpenterNodepoolRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: AddKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  /** to be deprecated */
  updateKarpenterNodepool(
    request: UpdateKarpenterNodepoolRequest,
    callback: (error: ServiceError | null, response: UpdateKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  updateKarpenterNodepool(
    request: UpdateKarpenterNodepoolRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpdateKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  updateKarpenterNodepool(
    request: UpdateKarpenterNodepoolRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpdateKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  /** to be deprecated */
  deleteKarpenterNodepool(
    request: DeleteKarpenterNodepoolRequest,
    callback: (error: ServiceError | null, response: DeleteKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  deleteKarpenterNodepool(
    request: DeleteKarpenterNodepoolRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: DeleteKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  deleteKarpenterNodepool(
    request: DeleteKarpenterNodepoolRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: DeleteKarpenterNodepoolResponse) => void,
  ): ClientUnaryCall;
  getKarpenterInstallationMetadata(
    request: GetKarpenterInstallationMetadataRequest,
    callback: (error: ServiceError | null, response: GetKarpenterInstallationMetadataResponse) => void,
  ): ClientUnaryCall;
  getKarpenterInstallationMetadata(
    request: GetKarpenterInstallationMetadataRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetKarpenterInstallationMetadataResponse) => void,
  ): ClientUnaryCall;
  getKarpenterInstallationMetadata(
    request: GetKarpenterInstallationMetadataRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetKarpenterInstallationMetadataResponse) => void,
  ): ClientUnaryCall;
  getTagWeights(
    request: GetTagWeightsRequest,
    callback: (error: ServiceError | null, response: GetTagWeightsResponse) => void,
  ): ClientUnaryCall;
  getTagWeights(
    request: GetTagWeightsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetTagWeightsResponse) => void,
  ): ClientUnaryCall;
  getTagWeights(
    request: GetTagWeightsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetTagWeightsResponse) => void,
  ): ClientUnaryCall;
  setTagWeights(
    request: SetTagWeightsRequest,
    callback: (error: ServiceError | null, response: SetTagWeightsResponse) => void,
  ): ClientUnaryCall;
  setTagWeights(
    request: SetTagWeightsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: SetTagWeightsResponse) => void,
  ): ClientUnaryCall;
  setTagWeights(
    request: SetTagWeightsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: SetTagWeightsResponse) => void,
  ): ClientUnaryCall;
}

export const BuilderServiceClient = makeGenericClientConstructor(
  BuilderServiceService,
  "chalk.server.v1.BuilderService",
) as unknown as {
  new (address: string, credentials: ChannelCredentials, options?: Partial<ClientOptions>): BuilderServiceClient;
  service: typeof BuilderServiceService;
  serviceName: string;
};

export type ClusterBuilderServiceService = typeof ClusterBuilderServiceService;
export const ClusterBuilderServiceService = {
  createKafkaTopics: {
    path: "/chalk.server.v1.ClusterBuilderService/CreateKafkaTopics",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CreateKafkaTopicsRequest) => Buffer.from(CreateKafkaTopicsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => CreateKafkaTopicsRequest.decode(value),
    responseSerialize: (value: CreateKafkaTopicsResponse) =>
      Buffer.from(CreateKafkaTopicsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => CreateKafkaTopicsResponse.decode(value),
  },
  getKafkaTopics: {
    path: "/chalk.server.v1.ClusterBuilderService/GetKafkaTopics",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetKafkaTopicsRequest) => Buffer.from(GetKafkaTopicsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetKafkaTopicsRequest.decode(value),
    responseSerialize: (value: GetKafkaTopicsResponse) => Buffer.from(GetKafkaTopicsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetKafkaTopicsResponse.decode(value),
  },
} as const;

export interface ClusterBuilderServiceServer extends UntypedServiceImplementation {
  createKafkaTopics: handleUnaryCall<CreateKafkaTopicsRequest, CreateKafkaTopicsResponse>;
  getKafkaTopics: handleUnaryCall<GetKafkaTopicsRequest, GetKafkaTopicsResponse>;
}

export interface ClusterBuilderServiceClient extends Client {
  createKafkaTopics(
    request: CreateKafkaTopicsRequest,
    callback: (error: ServiceError | null, response: CreateKafkaTopicsResponse) => void,
  ): ClientUnaryCall;
  createKafkaTopics(
    request: CreateKafkaTopicsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: CreateKafkaTopicsResponse) => void,
  ): ClientUnaryCall;
  createKafkaTopics(
    request: CreateKafkaTopicsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: CreateKafkaTopicsResponse) => void,
  ): ClientUnaryCall;
  getKafkaTopics(
    request: GetKafkaTopicsRequest,
    callback: (error: ServiceError | null, response: GetKafkaTopicsResponse) => void,
  ): ClientUnaryCall;
  getKafkaTopics(
    request: GetKafkaTopicsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetKafkaTopicsResponse) => void,
  ): ClientUnaryCall;
  getKafkaTopics(
    request: GetKafkaTopicsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetKafkaTopicsResponse) => void,
  ): ClientUnaryCall;
}

export const ClusterBuilderServiceClient = makeGenericClientConstructor(
  ClusterBuilderServiceService,
  "chalk.server.v1.ClusterBuilderService",
) as unknown as {
  new (address: string, credentials: ChannelCredentials, options?: Partial<ClientOptions>): ClusterBuilderServiceClient;
  service: typeof ClusterBuilderServiceService;
  serviceName: string;
};

function bytesFromBase64(b64: string): Uint8Array {
  if ((globalThis as any).Buffer) {
    return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
  } else {
    const bin = globalThis.atob(b64);
    const arr = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; ++i) {
      arr[i] = bin.charCodeAt(i);
    }
    return arr;
  }
}

function base64FromBytes(arr: Uint8Array): string {
  if ((globalThis as any).Buffer) {
    return globalThis.Buffer.from(arr).toString("base64");
  } else {
    const bin: string[] = [];
    arr.forEach((byte) => {
      bin.push(globalThis.String.fromCharCode(byte));
    });
    return globalThis.btoa(bin.join(""));
  }
}

function toTimestamp(date: Date): Timestamp {
  const seconds = Math.trunc(date.getTime() / 1_000);
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
}
