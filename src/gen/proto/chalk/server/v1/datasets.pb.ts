// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.6.1
//   protoc               unknown
// source: chalk/server/v1/datasets.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import {
  type CallOptions,
  ChannelCredentials,
  Client,
  type ClientOptions,
  type ClientUnaryCall,
  type handleUnaryCall,
  makeGenericClientConstructor,
  Metadata,
  type ServiceError,
  type UntypedServiceImplementation,
} from "@grpc/grpc-js";
import { Value } from "../../../google/protobuf/struct.pb";
import { Timestamp } from "../../../google/protobuf/timestamp.pb";

export const protobufPackage = "chalk.server.v1";

export enum DatasetRevisionStatus {
  DATASET_REVISION_STATUS_UNSPECIFIED = 0,
  DATASET_REVISION_STATUS_UNKNOWN = 1,
  DATASET_REVISION_STATUS_WORKING = 2,
  DATASET_REVISION_STATUS_COMPLETED = 3,
  DATASET_REVISION_STATUS_FAILED = 4,
  DATASET_REVISION_STATUS_CANCELED = 5,
  DATASET_REVISION_STATUS_QUEUED = 6,
  UNRECOGNIZED = -1,
}

export function datasetRevisionStatusFromJSON(object: any): DatasetRevisionStatus {
  switch (object) {
    case 0:
    case "DATASET_REVISION_STATUS_UNSPECIFIED":
      return DatasetRevisionStatus.DATASET_REVISION_STATUS_UNSPECIFIED;
    case 1:
    case "DATASET_REVISION_STATUS_UNKNOWN":
      return DatasetRevisionStatus.DATASET_REVISION_STATUS_UNKNOWN;
    case 2:
    case "DATASET_REVISION_STATUS_WORKING":
      return DatasetRevisionStatus.DATASET_REVISION_STATUS_WORKING;
    case 3:
    case "DATASET_REVISION_STATUS_COMPLETED":
      return DatasetRevisionStatus.DATASET_REVISION_STATUS_COMPLETED;
    case 4:
    case "DATASET_REVISION_STATUS_FAILED":
      return DatasetRevisionStatus.DATASET_REVISION_STATUS_FAILED;
    case 5:
    case "DATASET_REVISION_STATUS_CANCELED":
      return DatasetRevisionStatus.DATASET_REVISION_STATUS_CANCELED;
    case 6:
    case "DATASET_REVISION_STATUS_QUEUED":
      return DatasetRevisionStatus.DATASET_REVISION_STATUS_QUEUED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatasetRevisionStatus.UNRECOGNIZED;
  }
}

export function datasetRevisionStatusToJSON(object: DatasetRevisionStatus): string {
  switch (object) {
    case DatasetRevisionStatus.DATASET_REVISION_STATUS_UNSPECIFIED:
      return "DATASET_REVISION_STATUS_UNSPECIFIED";
    case DatasetRevisionStatus.DATASET_REVISION_STATUS_UNKNOWN:
      return "DATASET_REVISION_STATUS_UNKNOWN";
    case DatasetRevisionStatus.DATASET_REVISION_STATUS_WORKING:
      return "DATASET_REVISION_STATUS_WORKING";
    case DatasetRevisionStatus.DATASET_REVISION_STATUS_COMPLETED:
      return "DATASET_REVISION_STATUS_COMPLETED";
    case DatasetRevisionStatus.DATASET_REVISION_STATUS_FAILED:
      return "DATASET_REVISION_STATUS_FAILED";
    case DatasetRevisionStatus.DATASET_REVISION_STATUS_CANCELED:
      return "DATASET_REVISION_STATUS_CANCELED";
    case DatasetRevisionStatus.DATASET_REVISION_STATUS_QUEUED:
      return "DATASET_REVISION_STATUS_QUEUED";
    case DatasetRevisionStatus.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum DatasetVersion {
  DATASET_VERSION_UNSPECIFIED = 0,
  DATASET_VERSION_UNKNOWN = 1,
  DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES = 2,
  DATASET_VERSION_DATASET_WRITER = 3,
  DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES_V2 = 4,
  DATASET_VERSION_COMPUTE_RESOLVER_OUTPUT_V1 = 5,
  DATASET_VERSION_NATIVE_DTYPES = 6,
  DATASET_VERSION_NATIVE_COLUMN_NAMES = 7,
  UNRECOGNIZED = -1,
}

export function datasetVersionFromJSON(object: any): DatasetVersion {
  switch (object) {
    case 0:
    case "DATASET_VERSION_UNSPECIFIED":
      return DatasetVersion.DATASET_VERSION_UNSPECIFIED;
    case 1:
    case "DATASET_VERSION_UNKNOWN":
      return DatasetVersion.DATASET_VERSION_UNKNOWN;
    case 2:
    case "DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES":
      return DatasetVersion.DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES;
    case 3:
    case "DATASET_VERSION_DATASET_WRITER":
      return DatasetVersion.DATASET_VERSION_DATASET_WRITER;
    case 4:
    case "DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES_V2":
      return DatasetVersion.DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES_V2;
    case 5:
    case "DATASET_VERSION_COMPUTE_RESOLVER_OUTPUT_V1":
      return DatasetVersion.DATASET_VERSION_COMPUTE_RESOLVER_OUTPUT_V1;
    case 6:
    case "DATASET_VERSION_NATIVE_DTYPES":
      return DatasetVersion.DATASET_VERSION_NATIVE_DTYPES;
    case 7:
    case "DATASET_VERSION_NATIVE_COLUMN_NAMES":
      return DatasetVersion.DATASET_VERSION_NATIVE_COLUMN_NAMES;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatasetVersion.UNRECOGNIZED;
  }
}

export function datasetVersionToJSON(object: DatasetVersion): string {
  switch (object) {
    case DatasetVersion.DATASET_VERSION_UNSPECIFIED:
      return "DATASET_VERSION_UNSPECIFIED";
    case DatasetVersion.DATASET_VERSION_UNKNOWN:
      return "DATASET_VERSION_UNKNOWN";
    case DatasetVersion.DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES:
      return "DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES";
    case DatasetVersion.DATASET_VERSION_DATASET_WRITER:
      return "DATASET_VERSION_DATASET_WRITER";
    case DatasetVersion.DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES_V2:
      return "DATASET_VERSION_BIGQUERY_JOB_WITH_B32_ENCODED_COLNAMES_V2";
    case DatasetVersion.DATASET_VERSION_COMPUTE_RESOLVER_OUTPUT_V1:
      return "DATASET_VERSION_COMPUTE_RESOLVER_OUTPUT_V1";
    case DatasetVersion.DATASET_VERSION_NATIVE_DTYPES:
      return "DATASET_VERSION_NATIVE_DTYPES";
    case DatasetVersion.DATASET_VERSION_NATIVE_COLUMN_NAMES:
      return "DATASET_VERSION_NATIVE_COLUMN_NAMES";
    case DatasetVersion.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum OfflineQueryGivensVersion {
  OFFLINE_QUERY_GIVENS_VERSION_UNSPECIFIED = 0,
  OFFLINE_QUERY_GIVENS_VERSION_UNKNOWN = 1,
  OFFLINE_QUERY_GIVENS_VERSION_NATIVE_TS_FEATURE_FOR_ROOT_NS = 2,
  OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME = 3,
  OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME_WITH_URI_PREFIX = 4,
  UNRECOGNIZED = -1,
}

export function offlineQueryGivensVersionFromJSON(object: any): OfflineQueryGivensVersion {
  switch (object) {
    case 0:
    case "OFFLINE_QUERY_GIVENS_VERSION_UNSPECIFIED":
      return OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_UNSPECIFIED;
    case 1:
    case "OFFLINE_QUERY_GIVENS_VERSION_UNKNOWN":
      return OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_UNKNOWN;
    case 2:
    case "OFFLINE_QUERY_GIVENS_VERSION_NATIVE_TS_FEATURE_FOR_ROOT_NS":
      return OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_NATIVE_TS_FEATURE_FOR_ROOT_NS;
    case 3:
    case "OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME":
      return OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME;
    case 4:
    case "OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME_WITH_URI_PREFIX":
      return OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME_WITH_URI_PREFIX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return OfflineQueryGivensVersion.UNRECOGNIZED;
  }
}

export function offlineQueryGivensVersionToJSON(object: OfflineQueryGivensVersion): string {
  switch (object) {
    case OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_UNSPECIFIED:
      return "OFFLINE_QUERY_GIVENS_VERSION_UNSPECIFIED";
    case OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_UNKNOWN:
      return "OFFLINE_QUERY_GIVENS_VERSION_UNKNOWN";
    case OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_NATIVE_TS_FEATURE_FOR_ROOT_NS:
      return "OFFLINE_QUERY_GIVENS_VERSION_NATIVE_TS_FEATURE_FOR_ROOT_NS";
    case OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME:
      return "OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME";
    case OfflineQueryGivensVersion.OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME_WITH_URI_PREFIX:
      return "OFFLINE_QUERY_GIVENS_VERSION_SINGLE_TS_COL_NAME_WITH_URI_PREFIX";
    case OfflineQueryGivensVersion.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface DatasetRevisionMeta {
  numericId: number;
  offlineQueryId: string;
  datasetId: string;
  givensUri?: string | undefined;
  givensVersion?: OfflineQueryGivensVersion | undefined;
  outputUri?: string | undefined;
  outputVersion?: DatasetVersion | undefined;
  branchName?: string | undefined;
  numRows?: number | undefined;
  physicalSizeBytes?: number | undefined;
  outputColumns: string[];
  outputFqns: string[];
  agentId?: string | undefined;
  completedAt?: Date | undefined;
  numShards?: number | undefined;
  numComputers?: number | undefined;
  metadata?:
    | any
    | undefined;
  /** possibly deprecated? */
  status?: DatasetRevisionStatus | undefined;
  numRowsCalculated?: number | undefined;
  physicalSizeBytesCalculated?: number | undefined;
  createdAt?: Date | undefined;
}

export interface DatasetMeta {
  id: string;
  environmentId: string;
  datasetName?: string | undefined;
  createdAt: Date | undefined;
  mostRecentRevision?: DatasetRevisionMeta | undefined;
}

export interface ListDatasetsRequest {
  cursor?: string | undefined;
  limit?: number | undefined;
  search?: string | undefined;
}

export interface ListDatasetsResponse {
  datasets: DatasetMeta[];
  cursor?: string | undefined;
}

export interface GetDatasetRequest {
  id: string;
}

export interface GetDatasetResponse {
  dataset: DatasetMeta | undefined;
}

export interface ListDatasetRevisionsRequest {
  datasetId: string;
  cursor?: string | undefined;
  limit?: number | undefined;
}

export interface ListDatasetRevisionsResponse {
  revisions: DatasetRevisionMeta[];
  cursor?: string | undefined;
}

export interface GetDatasetRevisionRequest {
  id: string;
}

export interface GetDatasetRevisionResponse {
  revision: DatasetRevisionMeta | undefined;
}

function createBaseDatasetRevisionMeta(): DatasetRevisionMeta {
  return {
    numericId: 0,
    offlineQueryId: "",
    datasetId: "",
    givensUri: undefined,
    givensVersion: undefined,
    outputUri: undefined,
    outputVersion: undefined,
    branchName: undefined,
    numRows: undefined,
    physicalSizeBytes: undefined,
    outputColumns: [],
    outputFqns: [],
    agentId: undefined,
    completedAt: undefined,
    numShards: undefined,
    numComputers: undefined,
    metadata: undefined,
    status: undefined,
    numRowsCalculated: undefined,
    physicalSizeBytesCalculated: undefined,
    createdAt: undefined,
  };
}

export const DatasetRevisionMeta: MessageFns<DatasetRevisionMeta> = {
  encode(message: DatasetRevisionMeta, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.numericId !== 0) {
      writer.uint32(8).int64(message.numericId);
    }
    if (message.offlineQueryId !== "") {
      writer.uint32(18).string(message.offlineQueryId);
    }
    if (message.datasetId !== "") {
      writer.uint32(26).string(message.datasetId);
    }
    if (message.givensUri !== undefined) {
      writer.uint32(34).string(message.givensUri);
    }
    if (message.givensVersion !== undefined) {
      writer.uint32(40).int32(message.givensVersion);
    }
    if (message.outputUri !== undefined) {
      writer.uint32(50).string(message.outputUri);
    }
    if (message.outputVersion !== undefined) {
      writer.uint32(56).int32(message.outputVersion);
    }
    if (message.branchName !== undefined) {
      writer.uint32(66).string(message.branchName);
    }
    if (message.numRows !== undefined) {
      writer.uint32(72).int64(message.numRows);
    }
    if (message.physicalSizeBytes !== undefined) {
      writer.uint32(80).int64(message.physicalSizeBytes);
    }
    for (const v of message.outputColumns) {
      writer.uint32(90).string(v!);
    }
    for (const v of message.outputFqns) {
      writer.uint32(98).string(v!);
    }
    if (message.agentId !== undefined) {
      writer.uint32(106).string(message.agentId);
    }
    if (message.completedAt !== undefined) {
      Timestamp.encode(toTimestamp(message.completedAt), writer.uint32(114).fork()).join();
    }
    if (message.numShards !== undefined) {
      writer.uint32(120).int64(message.numShards);
    }
    if (message.numComputers !== undefined) {
      writer.uint32(128).int64(message.numComputers);
    }
    if (message.metadata !== undefined) {
      Value.encode(Value.wrap(message.metadata), writer.uint32(138).fork()).join();
    }
    if (message.status !== undefined) {
      writer.uint32(144).int32(message.status);
    }
    if (message.numRowsCalculated !== undefined) {
      writer.uint32(152).int64(message.numRowsCalculated);
    }
    if (message.physicalSizeBytesCalculated !== undefined) {
      writer.uint32(160).int64(message.physicalSizeBytesCalculated);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAt), writer.uint32(170).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetRevisionMeta {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetRevisionMeta();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.numericId = longToNumber(reader.int64());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.offlineQueryId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.givensUri = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.givensVersion = reader.int32() as any;
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.outputUri = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.outputVersion = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.branchName = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.numRows = longToNumber(reader.int64());
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.physicalSizeBytes = longToNumber(reader.int64());
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.outputColumns.push(reader.string());
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.outputFqns.push(reader.string());
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.agentId = reader.string();
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.completedAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 15: {
          if (tag !== 120) {
            break;
          }

          message.numShards = longToNumber(reader.int64());
          continue;
        }
        case 16: {
          if (tag !== 128) {
            break;
          }

          message.numComputers = longToNumber(reader.int64());
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.metadata = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        }
        case 18: {
          if (tag !== 144) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
        case 19: {
          if (tag !== 152) {
            break;
          }

          message.numRowsCalculated = longToNumber(reader.int64());
          continue;
        }
        case 20: {
          if (tag !== 160) {
            break;
          }

          message.physicalSizeBytesCalculated = longToNumber(reader.int64());
          continue;
        }
        case 21: {
          if (tag !== 170) {
            break;
          }

          message.createdAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetRevisionMeta {
    return {
      numericId: isSet(object.numericId) ? globalThis.Number(object.numericId) : 0,
      offlineQueryId: isSet(object.offlineQueryId) ? globalThis.String(object.offlineQueryId) : "",
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      givensUri: isSet(object.givensUri) ? globalThis.String(object.givensUri) : undefined,
      givensVersion: isSet(object.givensVersion) ? offlineQueryGivensVersionFromJSON(object.givensVersion) : undefined,
      outputUri: isSet(object.outputUri) ? globalThis.String(object.outputUri) : undefined,
      outputVersion: isSet(object.outputVersion) ? datasetVersionFromJSON(object.outputVersion) : undefined,
      branchName: isSet(object.branchName) ? globalThis.String(object.branchName) : undefined,
      numRows: isSet(object.numRows) ? globalThis.Number(object.numRows) : undefined,
      physicalSizeBytes: isSet(object.physicalSizeBytes) ? globalThis.Number(object.physicalSizeBytes) : undefined,
      outputColumns: globalThis.Array.isArray(object?.outputColumns)
        ? object.outputColumns.map((e: any) => globalThis.String(e))
        : [],
      outputFqns: globalThis.Array.isArray(object?.outputFqns)
        ? object.outputFqns.map((e: any) => globalThis.String(e))
        : [],
      agentId: isSet(object.agentId) ? globalThis.String(object.agentId) : undefined,
      completedAt: isSet(object.completedAt) ? fromJsonTimestamp(object.completedAt) : undefined,
      numShards: isSet(object.numShards) ? globalThis.Number(object.numShards) : undefined,
      numComputers: isSet(object.numComputers) ? globalThis.Number(object.numComputers) : undefined,
      metadata: isSet(object?.metadata) ? object.metadata : undefined,
      status: isSet(object.status) ? datasetRevisionStatusFromJSON(object.status) : undefined,
      numRowsCalculated: isSet(object.numRowsCalculated) ? globalThis.Number(object.numRowsCalculated) : undefined,
      physicalSizeBytesCalculated: isSet(object.physicalSizeBytesCalculated)
        ? globalThis.Number(object.physicalSizeBytesCalculated)
        : undefined,
      createdAt: isSet(object.createdAt) ? fromJsonTimestamp(object.createdAt) : undefined,
    };
  },

  toJSON(message: DatasetRevisionMeta): unknown {
    const obj: any = {};
    if (message.numericId !== 0) {
      obj.numericId = Math.round(message.numericId);
    }
    if (message.offlineQueryId !== "") {
      obj.offlineQueryId = message.offlineQueryId;
    }
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.givensUri !== undefined) {
      obj.givensUri = message.givensUri;
    }
    if (message.givensVersion !== undefined) {
      obj.givensVersion = offlineQueryGivensVersionToJSON(message.givensVersion);
    }
    if (message.outputUri !== undefined) {
      obj.outputUri = message.outputUri;
    }
    if (message.outputVersion !== undefined) {
      obj.outputVersion = datasetVersionToJSON(message.outputVersion);
    }
    if (message.branchName !== undefined) {
      obj.branchName = message.branchName;
    }
    if (message.numRows !== undefined) {
      obj.numRows = Math.round(message.numRows);
    }
    if (message.physicalSizeBytes !== undefined) {
      obj.physicalSizeBytes = Math.round(message.physicalSizeBytes);
    }
    if (message.outputColumns?.length) {
      obj.outputColumns = message.outputColumns;
    }
    if (message.outputFqns?.length) {
      obj.outputFqns = message.outputFqns;
    }
    if (message.agentId !== undefined) {
      obj.agentId = message.agentId;
    }
    if (message.completedAt !== undefined) {
      obj.completedAt = message.completedAt.toISOString();
    }
    if (message.numShards !== undefined) {
      obj.numShards = Math.round(message.numShards);
    }
    if (message.numComputers !== undefined) {
      obj.numComputers = Math.round(message.numComputers);
    }
    if (message.metadata !== undefined) {
      obj.metadata = message.metadata;
    }
    if (message.status !== undefined) {
      obj.status = datasetRevisionStatusToJSON(message.status);
    }
    if (message.numRowsCalculated !== undefined) {
      obj.numRowsCalculated = Math.round(message.numRowsCalculated);
    }
    if (message.physicalSizeBytesCalculated !== undefined) {
      obj.physicalSizeBytesCalculated = Math.round(message.physicalSizeBytesCalculated);
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    return obj;
  },
};

function createBaseDatasetMeta(): DatasetMeta {
  return { id: "", environmentId: "", datasetName: undefined, createdAt: undefined, mostRecentRevision: undefined };
}

export const DatasetMeta: MessageFns<DatasetMeta> = {
  encode(message: DatasetMeta, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.environmentId !== "") {
      writer.uint32(18).string(message.environmentId);
    }
    if (message.datasetName !== undefined) {
      writer.uint32(26).string(message.datasetName);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAt), writer.uint32(42).fork()).join();
    }
    if (message.mostRecentRevision !== undefined) {
      DatasetRevisionMeta.encode(message.mostRecentRevision, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetMeta {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetMeta();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.environmentId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.datasetName = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.createdAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.mostRecentRevision = DatasetRevisionMeta.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetMeta {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      environmentId: isSet(object.environmentId) ? globalThis.String(object.environmentId) : "",
      datasetName: isSet(object.datasetName) ? globalThis.String(object.datasetName) : undefined,
      createdAt: isSet(object.createdAt) ? fromJsonTimestamp(object.createdAt) : undefined,
      mostRecentRevision: isSet(object.mostRecentRevision)
        ? DatasetRevisionMeta.fromJSON(object.mostRecentRevision)
        : undefined,
    };
  },

  toJSON(message: DatasetMeta): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.environmentId !== "") {
      obj.environmentId = message.environmentId;
    }
    if (message.datasetName !== undefined) {
      obj.datasetName = message.datasetName;
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    if (message.mostRecentRevision !== undefined) {
      obj.mostRecentRevision = DatasetRevisionMeta.toJSON(message.mostRecentRevision);
    }
    return obj;
  },
};

function createBaseListDatasetsRequest(): ListDatasetsRequest {
  return { cursor: undefined, limit: undefined, search: undefined };
}

export const ListDatasetsRequest: MessageFns<ListDatasetsRequest> = {
  encode(message: ListDatasetsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cursor !== undefined) {
      writer.uint32(10).string(message.cursor);
    }
    if (message.limit !== undefined) {
      writer.uint32(16).int32(message.limit);
    }
    if (message.search !== undefined) {
      writer.uint32(26).string(message.search);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatasetsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatasetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cursor = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.limit = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.search = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatasetsRequest {
    return {
      cursor: isSet(object.cursor) ? globalThis.String(object.cursor) : undefined,
      limit: isSet(object.limit) ? globalThis.Number(object.limit) : undefined,
      search: isSet(object.search) ? globalThis.String(object.search) : undefined,
    };
  },

  toJSON(message: ListDatasetsRequest): unknown {
    const obj: any = {};
    if (message.cursor !== undefined) {
      obj.cursor = message.cursor;
    }
    if (message.limit !== undefined) {
      obj.limit = Math.round(message.limit);
    }
    if (message.search !== undefined) {
      obj.search = message.search;
    }
    return obj;
  },
};

function createBaseListDatasetsResponse(): ListDatasetsResponse {
  return { datasets: [], cursor: undefined };
}

export const ListDatasetsResponse: MessageFns<ListDatasetsResponse> = {
  encode(message: ListDatasetsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.datasets) {
      DatasetMeta.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.cursor !== undefined) {
      writer.uint32(18).string(message.cursor);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatasetsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatasetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasets.push(DatasetMeta.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cursor = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatasetsResponse {
    return {
      datasets: globalThis.Array.isArray(object?.datasets)
        ? object.datasets.map((e: any) => DatasetMeta.fromJSON(e))
        : [],
      cursor: isSet(object.cursor) ? globalThis.String(object.cursor) : undefined,
    };
  },

  toJSON(message: ListDatasetsResponse): unknown {
    const obj: any = {};
    if (message.datasets?.length) {
      obj.datasets = message.datasets.map((e) => DatasetMeta.toJSON(e));
    }
    if (message.cursor !== undefined) {
      obj.cursor = message.cursor;
    }
    return obj;
  },
};

function createBaseGetDatasetRequest(): GetDatasetRequest {
  return { id: "" };
}

export const GetDatasetRequest: MessageFns<GetDatasetRequest> = {
  encode(message: GetDatasetRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatasetRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatasetRequest {
    return { id: isSet(object.id) ? globalThis.String(object.id) : "" };
  },

  toJSON(message: GetDatasetRequest): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    return obj;
  },
};

function createBaseGetDatasetResponse(): GetDatasetResponse {
  return { dataset: undefined };
}

export const GetDatasetResponse: MessageFns<GetDatasetResponse> = {
  encode(message: GetDatasetResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dataset !== undefined) {
      DatasetMeta.encode(message.dataset, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatasetResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatasetResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.dataset = DatasetMeta.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatasetResponse {
    return { dataset: isSet(object.dataset) ? DatasetMeta.fromJSON(object.dataset) : undefined };
  },

  toJSON(message: GetDatasetResponse): unknown {
    const obj: any = {};
    if (message.dataset !== undefined) {
      obj.dataset = DatasetMeta.toJSON(message.dataset);
    }
    return obj;
  },
};

function createBaseListDatasetRevisionsRequest(): ListDatasetRevisionsRequest {
  return { datasetId: "", cursor: undefined, limit: undefined };
}

export const ListDatasetRevisionsRequest: MessageFns<ListDatasetRevisionsRequest> = {
  encode(message: ListDatasetRevisionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    if (message.cursor !== undefined) {
      writer.uint32(18).string(message.cursor);
    }
    if (message.limit !== undefined) {
      writer.uint32(24).int32(message.limit);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatasetRevisionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatasetRevisionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cursor = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.limit = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatasetRevisionsRequest {
    return {
      datasetId: isSet(object.datasetId) ? globalThis.String(object.datasetId) : "",
      cursor: isSet(object.cursor) ? globalThis.String(object.cursor) : undefined,
      limit: isSet(object.limit) ? globalThis.Number(object.limit) : undefined,
    };
  },

  toJSON(message: ListDatasetRevisionsRequest): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.cursor !== undefined) {
      obj.cursor = message.cursor;
    }
    if (message.limit !== undefined) {
      obj.limit = Math.round(message.limit);
    }
    return obj;
  },
};

function createBaseListDatasetRevisionsResponse(): ListDatasetRevisionsResponse {
  return { revisions: [], cursor: undefined };
}

export const ListDatasetRevisionsResponse: MessageFns<ListDatasetRevisionsResponse> = {
  encode(message: ListDatasetRevisionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.revisions) {
      DatasetRevisionMeta.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.cursor !== undefined) {
      writer.uint32(18).string(message.cursor);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ListDatasetRevisionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseListDatasetRevisionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.revisions.push(DatasetRevisionMeta.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cursor = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ListDatasetRevisionsResponse {
    return {
      revisions: globalThis.Array.isArray(object?.revisions)
        ? object.revisions.map((e: any) => DatasetRevisionMeta.fromJSON(e))
        : [],
      cursor: isSet(object.cursor) ? globalThis.String(object.cursor) : undefined,
    };
  },

  toJSON(message: ListDatasetRevisionsResponse): unknown {
    const obj: any = {};
    if (message.revisions?.length) {
      obj.revisions = message.revisions.map((e) => DatasetRevisionMeta.toJSON(e));
    }
    if (message.cursor !== undefined) {
      obj.cursor = message.cursor;
    }
    return obj;
  },
};

function createBaseGetDatasetRevisionRequest(): GetDatasetRevisionRequest {
  return { id: "" };
}

export const GetDatasetRevisionRequest: MessageFns<GetDatasetRevisionRequest> = {
  encode(message: GetDatasetRevisionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatasetRevisionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatasetRevisionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatasetRevisionRequest {
    return { id: isSet(object.id) ? globalThis.String(object.id) : "" };
  },

  toJSON(message: GetDatasetRevisionRequest): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    return obj;
  },
};

function createBaseGetDatasetRevisionResponse(): GetDatasetRevisionResponse {
  return { revision: undefined };
}

export const GetDatasetRevisionResponse: MessageFns<GetDatasetRevisionResponse> = {
  encode(message: GetDatasetRevisionResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.revision !== undefined) {
      DatasetRevisionMeta.encode(message.revision, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatasetRevisionResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatasetRevisionResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.revision = DatasetRevisionMeta.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatasetRevisionResponse {
    return { revision: isSet(object.revision) ? DatasetRevisionMeta.fromJSON(object.revision) : undefined };
  },

  toJSON(message: GetDatasetRevisionResponse): unknown {
    const obj: any = {};
    if (message.revision !== undefined) {
      obj.revision = DatasetRevisionMeta.toJSON(message.revision);
    }
    return obj;
  },
};

export type DatasetMetadataServiceService = typeof DatasetMetadataServiceService;
export const DatasetMetadataServiceService = {
  listDatasets: {
    path: "/chalk.server.v1.DatasetMetadataService/ListDatasets",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ListDatasetsRequest) => Buffer.from(ListDatasetsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ListDatasetsRequest.decode(value),
    responseSerialize: (value: ListDatasetsResponse) => Buffer.from(ListDatasetsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ListDatasetsResponse.decode(value),
  },
  getDataset: {
    path: "/chalk.server.v1.DatasetMetadataService/GetDataset",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetDatasetRequest) => Buffer.from(GetDatasetRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetDatasetRequest.decode(value),
    responseSerialize: (value: GetDatasetResponse) => Buffer.from(GetDatasetResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetDatasetResponse.decode(value),
  },
  listDatasetRevisions: {
    path: "/chalk.server.v1.DatasetMetadataService/ListDatasetRevisions",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ListDatasetRevisionsRequest) =>
      Buffer.from(ListDatasetRevisionsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ListDatasetRevisionsRequest.decode(value),
    responseSerialize: (value: ListDatasetRevisionsResponse) =>
      Buffer.from(ListDatasetRevisionsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ListDatasetRevisionsResponse.decode(value),
  },
  getDatasetRevision: {
    path: "/chalk.server.v1.DatasetMetadataService/GetDatasetRevision",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetDatasetRevisionRequest) =>
      Buffer.from(GetDatasetRevisionRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetDatasetRevisionRequest.decode(value),
    responseSerialize: (value: GetDatasetRevisionResponse) =>
      Buffer.from(GetDatasetRevisionResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetDatasetRevisionResponse.decode(value),
  },
} as const;

export interface DatasetMetadataServiceServer extends UntypedServiceImplementation {
  listDatasets: handleUnaryCall<ListDatasetsRequest, ListDatasetsResponse>;
  getDataset: handleUnaryCall<GetDatasetRequest, GetDatasetResponse>;
  listDatasetRevisions: handleUnaryCall<ListDatasetRevisionsRequest, ListDatasetRevisionsResponse>;
  getDatasetRevision: handleUnaryCall<GetDatasetRevisionRequest, GetDatasetRevisionResponse>;
}

export interface DatasetMetadataServiceClient extends Client {
  listDatasets(
    request: ListDatasetsRequest,
    callback: (error: ServiceError | null, response: ListDatasetsResponse) => void,
  ): ClientUnaryCall;
  listDatasets(
    request: ListDatasetsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ListDatasetsResponse) => void,
  ): ClientUnaryCall;
  listDatasets(
    request: ListDatasetsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ListDatasetsResponse) => void,
  ): ClientUnaryCall;
  getDataset(
    request: GetDatasetRequest,
    callback: (error: ServiceError | null, response: GetDatasetResponse) => void,
  ): ClientUnaryCall;
  getDataset(
    request: GetDatasetRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetDatasetResponse) => void,
  ): ClientUnaryCall;
  getDataset(
    request: GetDatasetRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetDatasetResponse) => void,
  ): ClientUnaryCall;
  listDatasetRevisions(
    request: ListDatasetRevisionsRequest,
    callback: (error: ServiceError | null, response: ListDatasetRevisionsResponse) => void,
  ): ClientUnaryCall;
  listDatasetRevisions(
    request: ListDatasetRevisionsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ListDatasetRevisionsResponse) => void,
  ): ClientUnaryCall;
  listDatasetRevisions(
    request: ListDatasetRevisionsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ListDatasetRevisionsResponse) => void,
  ): ClientUnaryCall;
  getDatasetRevision(
    request: GetDatasetRevisionRequest,
    callback: (error: ServiceError | null, response: GetDatasetRevisionResponse) => void,
  ): ClientUnaryCall;
  getDatasetRevision(
    request: GetDatasetRevisionRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: GetDatasetRevisionResponse) => void,
  ): ClientUnaryCall;
  getDatasetRevision(
    request: GetDatasetRevisionRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: GetDatasetRevisionResponse) => void,
  ): ClientUnaryCall;
}

export const DatasetMetadataServiceClient = makeGenericClientConstructor(
  DatasetMetadataServiceService,
  "chalk.server.v1.DatasetMetadataService",
) as unknown as {
  new (
    address: string,
    credentials: ChannelCredentials,
    options?: Partial<ClientOptions>,
  ): DatasetMetadataServiceClient;
  service: typeof DatasetMetadataServiceService;
  serviceName: string;
};

function toTimestamp(date: Date): Timestamp {
  const seconds = Math.trunc(date.getTime() / 1_000);
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function longToNumber(int64: { toString(): string }): number {
  const num = globalThis.Number(int64.toString());
  if (num > globalThis.Number.MAX_SAFE_INTEGER) {
    throw new globalThis.Error("Value is larger than Number.MAX_SAFE_INTEGER");
  }
  if (num < globalThis.Number.MIN_SAFE_INTEGER) {
    throw new globalThis.Error("Value is smaller than Number.MIN_SAFE_INTEGER");
  }
  return num;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
}
