// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.6.1
//   protoc               unknown
// source: chalk/aggregate/v1/timeseries.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Duration } from "../../../google/protobuf/duration";

export const protobufPackage = "chalk.aggregate.v1";

export interface AggregateTimeSeriesRule {
  aggregation: string;
  bucketDuration:
    | Duration
    | undefined;
  /** The features which depend on this rule. */
  dependentFeatures: string[];
  retention: Duration | undefined;
  datetimeFeature: string;
}

export interface AggregateTimeSeries {
  namespace: string;
  aggregateOn: string;
  groupBy: string[];
  rules: AggregateTimeSeriesRule[];
  filtersDescription: string;
  bucketFeature: string;
}

function createBaseAggregateTimeSeriesRule(): AggregateTimeSeriesRule {
  return {
    aggregation: "",
    bucketDuration: undefined,
    dependentFeatures: [],
    retention: undefined,
    datetimeFeature: "",
  };
}

export const AggregateTimeSeriesRule: MessageFns<AggregateTimeSeriesRule> = {
  encode(message: AggregateTimeSeriesRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.aggregation !== "") {
      writer.uint32(10).string(message.aggregation);
    }
    if (message.bucketDuration !== undefined) {
      Duration.encode(message.bucketDuration, writer.uint32(18).fork()).join();
    }
    for (const v of message.dependentFeatures) {
      writer.uint32(26).string(v!);
    }
    if (message.retention !== undefined) {
      Duration.encode(message.retention, writer.uint32(34).fork()).join();
    }
    if (message.datetimeFeature !== "") {
      writer.uint32(42).string(message.datetimeFeature);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregateTimeSeriesRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregateTimeSeriesRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.aggregation = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.bucketDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.dependentFeatures.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.retention = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.datetimeFeature = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregateTimeSeriesRule {
    return {
      aggregation: isSet(object.aggregation) ? globalThis.String(object.aggregation) : "",
      bucketDuration: isSet(object.bucketDuration) ? Duration.fromJSON(object.bucketDuration) : undefined,
      dependentFeatures: globalThis.Array.isArray(object?.dependentFeatures)
        ? object.dependentFeatures.map((e: any) => globalThis.String(e))
        : [],
      retention: isSet(object.retention) ? Duration.fromJSON(object.retention) : undefined,
      datetimeFeature: isSet(object.datetimeFeature) ? globalThis.String(object.datetimeFeature) : "",
    };
  },

  toJSON(message: AggregateTimeSeriesRule): unknown {
    const obj: any = {};
    if (message.aggregation !== "") {
      obj.aggregation = message.aggregation;
    }
    if (message.bucketDuration !== undefined) {
      obj.bucketDuration = Duration.toJSON(message.bucketDuration);
    }
    if (message.dependentFeatures?.length) {
      obj.dependentFeatures = message.dependentFeatures;
    }
    if (message.retention !== undefined) {
      obj.retention = Duration.toJSON(message.retention);
    }
    if (message.datetimeFeature !== "") {
      obj.datetimeFeature = message.datetimeFeature;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AggregateTimeSeriesRule>, I>>(base?: I): AggregateTimeSeriesRule {
    return AggregateTimeSeriesRule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AggregateTimeSeriesRule>, I>>(object: I): AggregateTimeSeriesRule {
    const message = createBaseAggregateTimeSeriesRule();
    message.aggregation = object.aggregation ?? "";
    message.bucketDuration = (object.bucketDuration !== undefined && object.bucketDuration !== null)
      ? Duration.fromPartial(object.bucketDuration)
      : undefined;
    message.dependentFeatures = object.dependentFeatures?.map((e) => e) || [];
    message.retention = (object.retention !== undefined && object.retention !== null)
      ? Duration.fromPartial(object.retention)
      : undefined;
    message.datetimeFeature = object.datetimeFeature ?? "";
    return message;
  },
};

function createBaseAggregateTimeSeries(): AggregateTimeSeries {
  return { namespace: "", aggregateOn: "", groupBy: [], rules: [], filtersDescription: "", bucketFeature: "" };
}

export const AggregateTimeSeries: MessageFns<AggregateTimeSeries> = {
  encode(message: AggregateTimeSeries, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.namespace !== "") {
      writer.uint32(10).string(message.namespace);
    }
    if (message.aggregateOn !== "") {
      writer.uint32(18).string(message.aggregateOn);
    }
    for (const v of message.groupBy) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.rules) {
      AggregateTimeSeriesRule.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.filtersDescription !== "") {
      writer.uint32(50).string(message.filtersDescription);
    }
    if (message.bucketFeature !== "") {
      writer.uint32(58).string(message.bucketFeature);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregateTimeSeries {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregateTimeSeries();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.namespace = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.aggregateOn = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.groupBy.push(reader.string());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.rules.push(AggregateTimeSeriesRule.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.filtersDescription = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.bucketFeature = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregateTimeSeries {
    return {
      namespace: isSet(object.namespace) ? globalThis.String(object.namespace) : "",
      aggregateOn: isSet(object.aggregateOn) ? globalThis.String(object.aggregateOn) : "",
      groupBy: globalThis.Array.isArray(object?.groupBy) ? object.groupBy.map((e: any) => globalThis.String(e)) : [],
      rules: globalThis.Array.isArray(object?.rules)
        ? object.rules.map((e: any) => AggregateTimeSeriesRule.fromJSON(e))
        : [],
      filtersDescription: isSet(object.filtersDescription) ? globalThis.String(object.filtersDescription) : "",
      bucketFeature: isSet(object.bucketFeature) ? globalThis.String(object.bucketFeature) : "",
    };
  },

  toJSON(message: AggregateTimeSeries): unknown {
    const obj: any = {};
    if (message.namespace !== "") {
      obj.namespace = message.namespace;
    }
    if (message.aggregateOn !== "") {
      obj.aggregateOn = message.aggregateOn;
    }
    if (message.groupBy?.length) {
      obj.groupBy = message.groupBy;
    }
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => AggregateTimeSeriesRule.toJSON(e));
    }
    if (message.filtersDescription !== "") {
      obj.filtersDescription = message.filtersDescription;
    }
    if (message.bucketFeature !== "") {
      obj.bucketFeature = message.bucketFeature;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AggregateTimeSeries>, I>>(base?: I): AggregateTimeSeries {
    return AggregateTimeSeries.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AggregateTimeSeries>, I>>(object: I): AggregateTimeSeries {
    const message = createBaseAggregateTimeSeries();
    message.namespace = object.namespace ?? "";
    message.aggregateOn = object.aggregateOn ?? "";
    message.groupBy = object.groupBy?.map((e) => e) || [];
    message.rules = object.rules?.map((e) => AggregateTimeSeriesRule.fromPartial(e)) || [];
    message.filtersDescription = object.filtersDescription ?? "";
    message.bucketFeature = object.bucketFeature ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
