// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.6.1
//   protoc               unknown
// source: chalk/aggregate/v1/backfill.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Duration } from "../../../google/protobuf/duration.pb";
import { Timestamp } from "../../../google/protobuf/timestamp.pb";
import { AggregateTimeSeries } from "./timeseries.pb";

export const protobufPackage = "chalk.aggregate.v1";

export interface AggregateBackfillCostEstimate {
  maxBuckets: number;
  expectedBuckets: number;
  expectedBytes: number;
  expectedStorageCost: number;
  expectedRuntime: Duration | undefined;
}

export interface AggregateBackfillUserParams {
  features: string[];
  resolver?:
    | string
    | undefined;
  /** @deprecated */
  timestampColumnName?: string | undefined;
  lowerBound?: Date | undefined;
  upperBound?: Date | undefined;
  exact: boolean;
}

export interface AggregateBackfill {
  series: AggregateTimeSeries[];
  resolver: string;
  datetimeFeature: string;
  bucketDuration: Duration | undefined;
  filtersDescription: string;
  groupBy: string[];
  maxRetention: Duration | undefined;
  lowerBound: Date | undefined;
  upperBound: Date | undefined;
}

export interface AggregateBackfillWithCostEstimate {
  backfill: AggregateBackfill | undefined;
  estimate: AggregateBackfillCostEstimate | undefined;
}

export interface AggregateBackfillJob {
  id: string;
  environmentId: string;
  resolver?: string | undefined;
  features: string[];
  agentId?: string | undefined;
  deploymentId?: string | undefined;
  createdAt: Date | undefined;
  updatedAt: Date | undefined;
  resolvers: string[];
  cronAggregateBackfillId?: string | undefined;
  planHash?: string | undefined;
}

export interface CronAggregateBackfill {
  id: string;
  environmentId: string;
  deploymentId: string;
  schedule: string;
  planHash: string;
  features: string[];
  resolvers: string[];
  createdAt: Date | undefined;
  updatedAt: Date | undefined;
}

function createBaseAggregateBackfillCostEstimate(): AggregateBackfillCostEstimate {
  return { maxBuckets: 0, expectedBuckets: 0, expectedBytes: 0, expectedStorageCost: 0, expectedRuntime: undefined };
}

export const AggregateBackfillCostEstimate: MessageFns<AggregateBackfillCostEstimate> = {
  encode(message: AggregateBackfillCostEstimate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxBuckets !== 0) {
      writer.uint32(8).int64(message.maxBuckets);
    }
    if (message.expectedBuckets !== 0) {
      writer.uint32(16).int64(message.expectedBuckets);
    }
    if (message.expectedBytes !== 0) {
      writer.uint32(24).int64(message.expectedBytes);
    }
    if (message.expectedStorageCost !== 0) {
      writer.uint32(33).double(message.expectedStorageCost);
    }
    if (message.expectedRuntime !== undefined) {
      Duration.encode(message.expectedRuntime, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregateBackfillCostEstimate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregateBackfillCostEstimate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.maxBuckets = longToNumber(reader.int64());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.expectedBuckets = longToNumber(reader.int64());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.expectedBytes = longToNumber(reader.int64());
          continue;
        }
        case 4: {
          if (tag !== 33) {
            break;
          }

          message.expectedStorageCost = reader.double();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.expectedRuntime = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregateBackfillCostEstimate {
    return {
      maxBuckets: isSet(object.maxBuckets) ? globalThis.Number(object.maxBuckets) : 0,
      expectedBuckets: isSet(object.expectedBuckets) ? globalThis.Number(object.expectedBuckets) : 0,
      expectedBytes: isSet(object.expectedBytes) ? globalThis.Number(object.expectedBytes) : 0,
      expectedStorageCost: isSet(object.expectedStorageCost) ? globalThis.Number(object.expectedStorageCost) : 0,
      expectedRuntime: isSet(object.expectedRuntime) ? Duration.fromJSON(object.expectedRuntime) : undefined,
    };
  },

  toJSON(message: AggregateBackfillCostEstimate): unknown {
    const obj: any = {};
    if (message.maxBuckets !== 0) {
      obj.maxBuckets = Math.round(message.maxBuckets);
    }
    if (message.expectedBuckets !== 0) {
      obj.expectedBuckets = Math.round(message.expectedBuckets);
    }
    if (message.expectedBytes !== 0) {
      obj.expectedBytes = Math.round(message.expectedBytes);
    }
    if (message.expectedStorageCost !== 0) {
      obj.expectedStorageCost = message.expectedStorageCost;
    }
    if (message.expectedRuntime !== undefined) {
      obj.expectedRuntime = Duration.toJSON(message.expectedRuntime);
    }
    return obj;
  },
};

function createBaseAggregateBackfillUserParams(): AggregateBackfillUserParams {
  return {
    features: [],
    resolver: undefined,
    timestampColumnName: undefined,
    lowerBound: undefined,
    upperBound: undefined,
    exact: false,
  };
}

export const AggregateBackfillUserParams: MessageFns<AggregateBackfillUserParams> = {
  encode(message: AggregateBackfillUserParams, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.features) {
      writer.uint32(10).string(v!);
    }
    if (message.resolver !== undefined) {
      writer.uint32(18).string(message.resolver);
    }
    if (message.timestampColumnName !== undefined) {
      writer.uint32(26).string(message.timestampColumnName);
    }
    if (message.lowerBound !== undefined) {
      Timestamp.encode(toTimestamp(message.lowerBound), writer.uint32(34).fork()).join();
    }
    if (message.upperBound !== undefined) {
      Timestamp.encode(toTimestamp(message.upperBound), writer.uint32(42).fork()).join();
    }
    if (message.exact !== false) {
      writer.uint32(48).bool(message.exact);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregateBackfillUserParams {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregateBackfillUserParams();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.features.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.resolver = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.timestampColumnName = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.lowerBound = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.upperBound = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.exact = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregateBackfillUserParams {
    return {
      features: globalThis.Array.isArray(object?.features) ? object.features.map((e: any) => globalThis.String(e)) : [],
      resolver: isSet(object.resolver) ? globalThis.String(object.resolver) : undefined,
      timestampColumnName: isSet(object.timestampColumnName)
        ? globalThis.String(object.timestampColumnName)
        : undefined,
      lowerBound: isSet(object.lowerBound) ? fromJsonTimestamp(object.lowerBound) : undefined,
      upperBound: isSet(object.upperBound) ? fromJsonTimestamp(object.upperBound) : undefined,
      exact: isSet(object.exact) ? globalThis.Boolean(object.exact) : false,
    };
  },

  toJSON(message: AggregateBackfillUserParams): unknown {
    const obj: any = {};
    if (message.features?.length) {
      obj.features = message.features;
    }
    if (message.resolver !== undefined) {
      obj.resolver = message.resolver;
    }
    if (message.timestampColumnName !== undefined) {
      obj.timestampColumnName = message.timestampColumnName;
    }
    if (message.lowerBound !== undefined) {
      obj.lowerBound = message.lowerBound.toISOString();
    }
    if (message.upperBound !== undefined) {
      obj.upperBound = message.upperBound.toISOString();
    }
    if (message.exact !== false) {
      obj.exact = message.exact;
    }
    return obj;
  },
};

function createBaseAggregateBackfill(): AggregateBackfill {
  return {
    series: [],
    resolver: "",
    datetimeFeature: "",
    bucketDuration: undefined,
    filtersDescription: "",
    groupBy: [],
    maxRetention: undefined,
    lowerBound: undefined,
    upperBound: undefined,
  };
}

export const AggregateBackfill: MessageFns<AggregateBackfill> = {
  encode(message: AggregateBackfill, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.series) {
      AggregateTimeSeries.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.resolver !== "") {
      writer.uint32(18).string(message.resolver);
    }
    if (message.datetimeFeature !== "") {
      writer.uint32(26).string(message.datetimeFeature);
    }
    if (message.bucketDuration !== undefined) {
      Duration.encode(message.bucketDuration, writer.uint32(34).fork()).join();
    }
    if (message.filtersDescription !== "") {
      writer.uint32(42).string(message.filtersDescription);
    }
    for (const v of message.groupBy) {
      writer.uint32(50).string(v!);
    }
    if (message.maxRetention !== undefined) {
      Duration.encode(message.maxRetention, writer.uint32(58).fork()).join();
    }
    if (message.lowerBound !== undefined) {
      Timestamp.encode(toTimestamp(message.lowerBound), writer.uint32(66).fork()).join();
    }
    if (message.upperBound !== undefined) {
      Timestamp.encode(toTimestamp(message.upperBound), writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregateBackfill {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregateBackfill();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.series.push(AggregateTimeSeries.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.resolver = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.datetimeFeature = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.bucketDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.filtersDescription = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.groupBy.push(reader.string());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.maxRetention = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.lowerBound = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.upperBound = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregateBackfill {
    return {
      series: globalThis.Array.isArray(object?.series)
        ? object.series.map((e: any) => AggregateTimeSeries.fromJSON(e))
        : [],
      resolver: isSet(object.resolver) ? globalThis.String(object.resolver) : "",
      datetimeFeature: isSet(object.datetimeFeature) ? globalThis.String(object.datetimeFeature) : "",
      bucketDuration: isSet(object.bucketDuration) ? Duration.fromJSON(object.bucketDuration) : undefined,
      filtersDescription: isSet(object.filtersDescription) ? globalThis.String(object.filtersDescription) : "",
      groupBy: globalThis.Array.isArray(object?.groupBy) ? object.groupBy.map((e: any) => globalThis.String(e)) : [],
      maxRetention: isSet(object.maxRetention) ? Duration.fromJSON(object.maxRetention) : undefined,
      lowerBound: isSet(object.lowerBound) ? fromJsonTimestamp(object.lowerBound) : undefined,
      upperBound: isSet(object.upperBound) ? fromJsonTimestamp(object.upperBound) : undefined,
    };
  },

  toJSON(message: AggregateBackfill): unknown {
    const obj: any = {};
    if (message.series?.length) {
      obj.series = message.series.map((e) => AggregateTimeSeries.toJSON(e));
    }
    if (message.resolver !== "") {
      obj.resolver = message.resolver;
    }
    if (message.datetimeFeature !== "") {
      obj.datetimeFeature = message.datetimeFeature;
    }
    if (message.bucketDuration !== undefined) {
      obj.bucketDuration = Duration.toJSON(message.bucketDuration);
    }
    if (message.filtersDescription !== "") {
      obj.filtersDescription = message.filtersDescription;
    }
    if (message.groupBy?.length) {
      obj.groupBy = message.groupBy;
    }
    if (message.maxRetention !== undefined) {
      obj.maxRetention = Duration.toJSON(message.maxRetention);
    }
    if (message.lowerBound !== undefined) {
      obj.lowerBound = message.lowerBound.toISOString();
    }
    if (message.upperBound !== undefined) {
      obj.upperBound = message.upperBound.toISOString();
    }
    return obj;
  },
};

function createBaseAggregateBackfillWithCostEstimate(): AggregateBackfillWithCostEstimate {
  return { backfill: undefined, estimate: undefined };
}

export const AggregateBackfillWithCostEstimate: MessageFns<AggregateBackfillWithCostEstimate> = {
  encode(message: AggregateBackfillWithCostEstimate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.backfill !== undefined) {
      AggregateBackfill.encode(message.backfill, writer.uint32(10).fork()).join();
    }
    if (message.estimate !== undefined) {
      AggregateBackfillCostEstimate.encode(message.estimate, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregateBackfillWithCostEstimate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregateBackfillWithCostEstimate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.backfill = AggregateBackfill.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.estimate = AggregateBackfillCostEstimate.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregateBackfillWithCostEstimate {
    return {
      backfill: isSet(object.backfill) ? AggregateBackfill.fromJSON(object.backfill) : undefined,
      estimate: isSet(object.estimate) ? AggregateBackfillCostEstimate.fromJSON(object.estimate) : undefined,
    };
  },

  toJSON(message: AggregateBackfillWithCostEstimate): unknown {
    const obj: any = {};
    if (message.backfill !== undefined) {
      obj.backfill = AggregateBackfill.toJSON(message.backfill);
    }
    if (message.estimate !== undefined) {
      obj.estimate = AggregateBackfillCostEstimate.toJSON(message.estimate);
    }
    return obj;
  },
};

function createBaseAggregateBackfillJob(): AggregateBackfillJob {
  return {
    id: "",
    environmentId: "",
    resolver: undefined,
    features: [],
    agentId: undefined,
    deploymentId: undefined,
    createdAt: undefined,
    updatedAt: undefined,
    resolvers: [],
    cronAggregateBackfillId: undefined,
    planHash: undefined,
  };
}

export const AggregateBackfillJob: MessageFns<AggregateBackfillJob> = {
  encode(message: AggregateBackfillJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.environmentId !== "") {
      writer.uint32(18).string(message.environmentId);
    }
    if (message.resolver !== undefined) {
      writer.uint32(26).string(message.resolver);
    }
    for (const v of message.features) {
      writer.uint32(34).string(v!);
    }
    if (message.agentId !== undefined) {
      writer.uint32(42).string(message.agentId);
    }
    if (message.deploymentId !== undefined) {
      writer.uint32(50).string(message.deploymentId);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAt), writer.uint32(58).fork()).join();
    }
    if (message.updatedAt !== undefined) {
      Timestamp.encode(toTimestamp(message.updatedAt), writer.uint32(66).fork()).join();
    }
    for (const v of message.resolvers) {
      writer.uint32(74).string(v!);
    }
    if (message.cronAggregateBackfillId !== undefined) {
      writer.uint32(82).string(message.cronAggregateBackfillId);
    }
    if (message.planHash !== undefined) {
      writer.uint32(90).string(message.planHash);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AggregateBackfillJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAggregateBackfillJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.environmentId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.resolver = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.features.push(reader.string());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.agentId = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.deploymentId = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.createdAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.updatedAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.resolvers.push(reader.string());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.cronAggregateBackfillId = reader.string();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.planHash = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AggregateBackfillJob {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      environmentId: isSet(object.environmentId) ? globalThis.String(object.environmentId) : "",
      resolver: isSet(object.resolver) ? globalThis.String(object.resolver) : undefined,
      features: globalThis.Array.isArray(object?.features) ? object.features.map((e: any) => globalThis.String(e)) : [],
      agentId: isSet(object.agentId) ? globalThis.String(object.agentId) : undefined,
      deploymentId: isSet(object.deploymentId) ? globalThis.String(object.deploymentId) : undefined,
      createdAt: isSet(object.createdAt) ? fromJsonTimestamp(object.createdAt) : undefined,
      updatedAt: isSet(object.updatedAt) ? fromJsonTimestamp(object.updatedAt) : undefined,
      resolvers: globalThis.Array.isArray(object?.resolvers)
        ? object.resolvers.map((e: any) => globalThis.String(e))
        : [],
      cronAggregateBackfillId: isSet(object.cronAggregateBackfillId)
        ? globalThis.String(object.cronAggregateBackfillId)
        : undefined,
      planHash: isSet(object.planHash) ? globalThis.String(object.planHash) : undefined,
    };
  },

  toJSON(message: AggregateBackfillJob): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.environmentId !== "") {
      obj.environmentId = message.environmentId;
    }
    if (message.resolver !== undefined) {
      obj.resolver = message.resolver;
    }
    if (message.features?.length) {
      obj.features = message.features;
    }
    if (message.agentId !== undefined) {
      obj.agentId = message.agentId;
    }
    if (message.deploymentId !== undefined) {
      obj.deploymentId = message.deploymentId;
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    if (message.updatedAt !== undefined) {
      obj.updatedAt = message.updatedAt.toISOString();
    }
    if (message.resolvers?.length) {
      obj.resolvers = message.resolvers;
    }
    if (message.cronAggregateBackfillId !== undefined) {
      obj.cronAggregateBackfillId = message.cronAggregateBackfillId;
    }
    if (message.planHash !== undefined) {
      obj.planHash = message.planHash;
    }
    return obj;
  },
};

function createBaseCronAggregateBackfill(): CronAggregateBackfill {
  return {
    id: "",
    environmentId: "",
    deploymentId: "",
    schedule: "",
    planHash: "",
    features: [],
    resolvers: [],
    createdAt: undefined,
    updatedAt: undefined,
  };
}

export const CronAggregateBackfill: MessageFns<CronAggregateBackfill> = {
  encode(message: CronAggregateBackfill, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.environmentId !== "") {
      writer.uint32(18).string(message.environmentId);
    }
    if (message.deploymentId !== "") {
      writer.uint32(26).string(message.deploymentId);
    }
    if (message.schedule !== "") {
      writer.uint32(34).string(message.schedule);
    }
    if (message.planHash !== "") {
      writer.uint32(42).string(message.planHash);
    }
    for (const v of message.features) {
      writer.uint32(66).string(v!);
    }
    for (const v of message.resolvers) {
      writer.uint32(74).string(v!);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(toTimestamp(message.createdAt), writer.uint32(50).fork()).join();
    }
    if (message.updatedAt !== undefined) {
      Timestamp.encode(toTimestamp(message.updatedAt), writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CronAggregateBackfill {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCronAggregateBackfill();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.environmentId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.deploymentId = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.schedule = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.planHash = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.features.push(reader.string());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.resolvers.push(reader.string());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.createdAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.updatedAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CronAggregateBackfill {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      environmentId: isSet(object.environmentId) ? globalThis.String(object.environmentId) : "",
      deploymentId: isSet(object.deploymentId) ? globalThis.String(object.deploymentId) : "",
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : "",
      planHash: isSet(object.planHash) ? globalThis.String(object.planHash) : "",
      features: globalThis.Array.isArray(object?.features) ? object.features.map((e: any) => globalThis.String(e)) : [],
      resolvers: globalThis.Array.isArray(object?.resolvers)
        ? object.resolvers.map((e: any) => globalThis.String(e))
        : [],
      createdAt: isSet(object.createdAt) ? fromJsonTimestamp(object.createdAt) : undefined,
      updatedAt: isSet(object.updatedAt) ? fromJsonTimestamp(object.updatedAt) : undefined,
    };
  },

  toJSON(message: CronAggregateBackfill): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.environmentId !== "") {
      obj.environmentId = message.environmentId;
    }
    if (message.deploymentId !== "") {
      obj.deploymentId = message.deploymentId;
    }
    if (message.schedule !== "") {
      obj.schedule = message.schedule;
    }
    if (message.planHash !== "") {
      obj.planHash = message.planHash;
    }
    if (message.features?.length) {
      obj.features = message.features;
    }
    if (message.resolvers?.length) {
      obj.resolvers = message.resolvers;
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    if (message.updatedAt !== undefined) {
      obj.updatedAt = message.updatedAt.toISOString();
    }
    return obj;
  },
};

function toTimestamp(date: Date): Timestamp {
  const seconds = Math.trunc(date.getTime() / 1_000);
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function longToNumber(int64: { toString(): string }): number {
  const num = globalThis.Number(int64.toString());
  if (num > globalThis.Number.MAX_SAFE_INTEGER) {
    throw new globalThis.Error("Value is larger than Number.MAX_SAFE_INTEGER");
  }
  if (num < globalThis.Number.MIN_SAFE_INTEGER) {
    throw new globalThis.Error("Value is smaller than Number.MIN_SAFE_INTEGER");
  }
  return num;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
}
